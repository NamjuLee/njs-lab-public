{"version":3,"file":"static/js/6371.d8e42058.chunk.js","mappings":"m/DAyBA,SAASA,EAAyBC,GAChC,IAAMC,EAAWD,EAAkBE,MAAM,GACnCC,GAAmBC,EAAAA,EAAAA,QAAUJ,EAAmB,GAEhDK,GAAmBC,EAAAA,EAAAA,SAAWH,EAAAA,EAAoB,IAExD,OAAOI,EAAAA,EAAAA,QAAUF,EAAkBJ,EAAAA,CAoBrC,SAAgBO,EACZC,EAA4BC,GAC9B,OAAOC,EAAAA,EAAAA,OACH,WACI,OAACC,EAAAA,EAAAA,OAAQC,EAAAA,EAAAA,SACLJ,GAAeK,EAAAA,EAAAA,QAAUJ,IAAa,YAkBpD,SAAgBK,EACZC,EACAhB,GACI,MAA0CA,EAAkBE,MAA3De,EAAAA,EAAAA,GAAeC,EAAAA,EAAAA,GAAcjB,EAAAA,EAAAA,GACpC,OAAOU,EAAAA,EAAAA,OAAQ,WACb,IAAMQ,EAAepB,EAAyBC,GACxCoB,GAAcC,EAAAA,EAAAA,aAAcC,EAAAA,EAAAA,OAAS,EAAGrB,EAAU,EAAG,SAAU,GAE/DI,GACFO,EAAAA,EAAAA,OAAQW,EAAAA,EAAAA,QAAUJ,EAAcC,GAA6B,SAE3DI,GAAUlB,EAAAA,EAAAA,SAAWD,EAAAA,CAAmBY,EAAeC,IAEvDO,GAA8BC,EAAAA,EAAAA,KAAOF,GAASV,EAAAA,EAAAA,QAAU,EAAG,UAEjE,OAAOa,EAAAA,EAAAA,KAvDX,SAAsBC,EAAoBC,GACxC,OAAOC,EAAAA,EAAAA,KAAOF,EAAOC,EAAAA,CAsDLE,CACHN,EAA4CT,IACjDF,EAAAA,EAAAA,QAAU,EAAG,aAIvB,SAAgBkB,EAA2BhC,GAEnC,MAA0CA,EAAkBE,MAA3De,EAAAA,EAAAA,GAAeC,EAAAA,EAAAA,GAAcjB,EAAAA,EAAAA,GACpC,OAAOU,EAAAA,EAAAA,OAAQ,WACb,IAAMQ,EAAepB,EAAyBC,GACxCoB,GAAcC,EAAAA,EAAAA,aAAcC,EAAAA,EAAAA,OAAS,EAAGrB,EAAU,EAAG,SAAU,GAE/DI,GACFO,EAAAA,EAAAA,OAAQW,EAAAA,EAAAA,QAAUJ,EAAcC,GAA6B,SAEjE,OAAOd,EAAAA,EAAAA,SAAWD,EAAAA,CAAmBY,EAAeC,GAAAA,GAAAA,CC1ExD,iBACE,WACuBe,EACHC,GADGC,KAAAA,MAAAA,EACHA,KAAAA,aAAAA,EAClB,IAAMC,EACFD,KAAKF,MAAMI,OAAO,GAAGnC,MACzBoC,EAAAA,KAAAA,QACwB,IAAnBF,EAAW,KAAkC,IAAnBA,EAAW,IACtC,WAAM,sBAAgBA,EAAW,QAAOA,EAAW,sCAyE3D,OAjDEG,EAAAA,UAAAA,QAAAA,SAAQC,GAAR,WAUE,OAAO7B,EAAAA,EAAAA,OAAQ,WACb,IAAM8B,EAAUC,EAAKC,iBAAgB/B,EAAAA,EAAAA,MAAQ4B,EAAO,YAC9CI,GAAUvB,EAAAA,EAAAA,YAAcoB,EAAS,GAEjCI,EADUH,EAAKT,MAAMa,QAAQF,GACMG,KAAI,YAAK,oBAAWC,EAAAA,CAAI,OAC3DC,EAAeP,EAAKQ,kBAAkBL,GAE5C,MAAO,CACLM,eAAeC,EAAAA,EAAAA,SAAWH,EAAaI,SACvCC,QAASL,EAAaK,QACtBC,gBAAiBN,EAAaM,gBAC9BC,gBAAiBP,EAAaO,gBAC9BC,aAAcR,EAAaQ,aAC3BC,aAAcT,EAAaS,aAC3BC,YAAaV,EAAaU,YAC1BC,YAAaX,EAAaW,YAAAA,GAAAA,EAqBhCrB,EAAAA,UAAAA,QAAAA,WACEJ,KAAKF,MAAM4B,SAAAA,EAAAA,CAAAA,CA/Ef,GA+EeA,EAAAA,SAAAA,GCzFf,2BAAAC,GAAAA,EAAA,4BA4BA,OA5B+BC,EAAAA,EAAAA,GAC7BC,EAAAA,UAAAA,gBAAAA,SAAgBxB,GAEd,OAAO7B,EAAAA,EAAAA,OAAQ,WAAM,iBAAOsD,EAAAA,EAAAA,KAAOzB,EAAO,OAAQ,OAGpDwB,EAAAA,UAAAA,kBAAAA,SAAkBE,GAWhB,MAAO,CACLZ,QAFAY,EAAAA,GAGAT,aAHAS,EAAAA,GAIAR,aAJAQ,EAAAA,GAKAP,YALAO,EAAAA,GAMAb,QANAa,EAAAA,GAOAX,gBAPAW,EAAAA,GAQAV,gBARAU,EAAAA,GASAN,YATAM,EAAAA,GAAAA,EAAAA,CAAAA,CDyESL,CCzFgBtB,GCAlB4B,EAAa,CACxB,OAAQ,UAAW,WAAY,UAAW,WAAY,eACtD,gBAAiB,YAAa,aAAc,YAAa,aACzD,UAAW,WAAY,WAAY,YAAa,YAAa,cAGlDC,EAAgBD,EAAWE,OAM3BC,EACTH,EAAWI,QAAO,SAACC,EAAoBC,EAAWC,GAEhD,OADAF,EAAOC,GAAaC,EACbF,CAAAA,GAAAA,CAAAA,GAGPG,CAAAA,CACH,UAAW,iBAAkB,YAAa,iBAC1C,YAAa,cAAe,UAAW,aACvC,WAAY,cAAe,WAAY,kBACvC,aAAc,kBAAmB,aAAc,eAC/C,WAAY,cAAe,YAAa,eACxC,eAAgB,kBAAmB,UAAW,aAoBU5B,KACvD,SAAC6B,GAAAA,IAACC,EAAAA,EAAAA,GAAYC,EAAAA,EAAAA,GACV,OAAER,EAASO,GAAaP,EAASQ,GAAAA,IClDzC,SAGgBC,EACZH,EACAI,EACAC,GAAAA,IAFCC,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GACRC,EAAAA,EAAAA,GAAkBC,EAAAA,EAAAA,GAETC,EAA+CL,EAAAA,IAAjCM,EAAiCN,EAAAA,OAG3D,MAAO,CADQI,GAF4CJ,EAAAA,KAAAA,EAAAA,MAEVE,GADlCC,GAAoBE,EAAOC,EAAOL,GAAAA,CAKnD,SAAgBM,EACZxC,EAAWyC,EAAWC,EAAkBpC,GAC1C,MAAO,CACLN,EAAGM,EAAQqC,IAAI3C,EAAGyC,EAAGC,GACrBD,EAAGnC,EAAQqC,IAAI3C,EAAGyC,EAAGC,EAAWtB,GAAAA,CAIpC,SAAgBwB,EACZC,EAAY3D,EAAsBoB,GAC7B,IACDsB,EAASY,EAD4BK,EAAAA,SAAAA,EAAAA,SAAAA,EAAAA,GACiBvC,GAArDN,EAAAA,EAAAA,EAAGyC,EAAAA,EAAAA,EACV,MAAO,CACLA,EAAGI,EAAKC,SAAW5D,EAAeuD,EAClCzC,EAAG6C,EAAKE,SAAW7D,EAAec,EAAAA,CAItC,SAUgBgD,EAAMC,EAAWC,EAAaC,GAC5C,OAAIF,EAAIC,EACCA,EAELD,EAAIE,EACCA,EAEFF,CAAAA,CAUT,SAAgBG,EAAWH,EAAaI,GACtC,MAAO,CAACZ,EAAGQ,EAAER,EAAIY,EAAEZ,EAAGzC,EAAGiD,EAAEjD,EAAIqD,EAAErD,EAAAA,CC3DnC,SAUSsD,EAAgBC,EAAmBC,EAAYC,QAAAA,IAAAA,IAAAA,EAAAA,IAGtD,IAFA,IAAIC,EAAW,EACXC,EAAS,EACJC,EAAI,EAAGA,EAAIL,EAAUlC,OAAQuC,IAChCJ,EAAKK,UAAUD,GAAGE,MAAQL,IAC5BE,GAAU,EACVD,GAAYK,KAAAA,IAACR,EAAUK,GAAGnB,EAAIe,EAAKK,UAAUD,GAAGI,SAASvB,EAAM,GAC3DsB,KAAAA,IAACR,EAAUK,GAAG5D,EAAIwD,EAAKK,UAAUD,GAAGI,SAAShE,EAAM,IAQ3D,OALe,IAAX2D,EACFD,EAAWO,IAEXP,GAAsBC,EAEjBD,CAAAA,CAWT,SAASQ,EACLC,EAAgBC,EAChBC,EAAyCC,EACzC3D,EAA2B4D,EAC3B3C,GAQF,IAAK,IARFM,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GACLqC,EAAcH,EAAkBF,GAEhCM,EAAKD,EAAYxE,EAAIsE,EAAoBE,EAAY/B,EACvDiC,EAAK/D,EAAYS,GAAiB,EAAIqD,GAAML,GAC5CO,EAAKhE,EAAYS,GAAiB,EAAIqD,EAAK,GAAKL,GAChDpE,EAAImE,EAASnE,EAAI0E,EACjBjC,EAAI0B,EAAS1B,EAAIkC,EACZC,EAAI,EAAGA,EAAIL,EAAaK,IAAK,CACpC5E,EAAI+D,KAAKb,IAAIlD,EAAGkC,EAAS,GAEzB,IAAM2C,EAASR,EAAAA,CAAmB5B,EADlCA,EAAIsB,KAAKb,IAAIT,EAAGN,EAAQ,GACanC,EAAAA,IAC/B8E,EAAKD,EAAO7E,EAAIsE,EAAoBO,EAAOpC,EAGjDzC,GAFA0E,EAAK/D,EAAYS,GAAiB,EAAI0D,GAAMV,GAG5C3B,GAFAkC,EAAKhE,EAAYS,GAAiB,EAAI0D,EAAK,GAAKV,EAAAA,CAKlD,MAAO,CAAC3B,EAAAA,EAAGzC,EAAAA,EAAAA,CAGb,SAAS+E,EACLZ,EAAgBxD,EAA2BqE,EAC3CC,EAA2BrD,EAC3BI,EAAoCsC,EACpCY,EAAmCC,EACnCZ,GAKF,IAAK,IARyBjC,EAAAA,EAAAA,GAAM8C,EAAAA,EAAAA,GACjCC,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GACRpD,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GAELoD,EAAAA,GACAlB,EAAoB,SAACmB,GACvB,OA1CN,SACIxB,EAAgBpC,EAChBI,EAAoCmD,GAAAA,IADnB7C,EAAAA,EAAAA,GAAM8C,EAAAA,EAAAA,GACtBC,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GACLtF,EAAI+D,KAAK0B,QAAQnD,EAAO0B,EAAShE,EAAI,GAAOsF,EAAS,GAAOH,GAElE,MAAO,CAAC1C,EADEsB,KAAK0B,QAAQL,EAAOpB,EAASvB,EAAI,GAAO4C,EAAS,GAAOF,GACvDnF,EAAAA,EAAAA,CAqCP0F,CAAyBF,EAAAA,CAAOlD,EAAM8C,GAAAA,CAAQC,EAAQC,GAASH,EAAAA,EAE1DQ,EAAiB,EAAGA,EAAiBV,EACzCU,IAAkB,CACrB,IAAMpC,EAAYW,EACdC,EAAUwB,EAAgBtB,EAAmBC,EAC7C3D,EAAa4D,EAAAA,CAAcrC,EAAQC,IAEvCoD,EAAMK,KAAKrC,EAAAA,CAKb,IAFA,IAAIsC,GAAQ,EACRC,EAAW7B,IACN8B,EAAI,EAAGA,EAAIf,EAAM3D,OAAQ0E,IAAK,CACrC,IAAMC,EAAO1C,EAAgBiC,EAAOP,EAAMe,IACtCC,EAAOF,IACTD,EAAOE,EACPD,EAAWE,EAAAA,CAGf,OAAOH,CAAAA,CAGT,SAASI,EACLrE,EACAuD,GAAAA,IADC/C,EAAAA,EAAAA,GAAkBC,EAAAA,EAAAA,GAIrB,MAAO,CAFmB0B,KAAK0B,OAAOpD,EAAmB,GAAO8C,EAAS,GAC/CpB,KAAK0B,OAAOrD,EAAmB,GAAO+C,EAAS,ICjG3E,SAOgBe,EACZzF,EAA2BE,EAC3BwF,EAAyBjE,EAAgBC,EAAegD,EACxDvD,EAAuCK,EACvCsC,EAAqB6B,EACrBC,GAaF,IAAK,IAfFC,EAAAA,EAAAA,GAAUC,EAAAA,EAAAA,GAIPvE,EAA0BvB,EAAavD,MAAtCsJ,EAAAA,EAAAA,GAAYC,EAAAA,EAAAA,GAEbvB,EAAwBvE,EAAYzD,MAAMwJ,MAAM,EAAG,GAAlDC,EAAAA,EAAAA,GAAWC,EAAAA,EAAAA,GAEZC,GACFvJ,EAAAA,EAAAA,SAAWqD,EAAAA,CAAcgG,EAAWC,EAAU,EAAGxF,IAK/C0F,EAAW,IAAIC,aAAaV,EAAejF,EAAgB,GAAG4F,KAAK,GAChEtF,EAAI,EAAGA,EAAIyE,EAAgB9E,OAAQK,IAG1C,IAFA,IAAMuF,EAAavF,EAAIN,EAAgB,EACjCoC,EAAO2C,EAAgBzE,GACpBwF,EAAK,EAAGA,EAAK9F,EAAe8F,IAAM,CACzC,IAAMxE,EAAWc,EAAKK,UAAUqD,GAC1BC,EAASF,EAAkB,EAALC,EAC5BJ,EAASK,GAAUzE,EAASoB,MAC5BgD,EAASK,EAAS,GAAKzE,EAASsB,SAAShE,EACzC8G,EAASK,EAAS,GAAKzE,EAASsB,SAASvB,CAAAA,CAIvC,MACFV,EAAS,CAACG,EAAQC,GAAAA,CAASmE,EAAUC,GAAUtE,GAD5CoD,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GAGT8B,GAAcC,EAAAA,EAAAA,QAAUP,EAAAA,CAAWT,EAAcjF,EAAe,IAE1DkB,EAAoBL,EAAAA,IAARmD,EAAQnD,EAAAA,KAE1BqF,EAAAA,CACJC,cAAe,CAAC,eAAgB,cAAe,SAC/CC,YAAa,CAAChB,EAAYC,GAC1BgB,SAAU,gyCAsCDnF,EAAAA,KAASgD,EAAAA,KAAWH,EAAAA,0EAEpBC,EAAAA,KAASC,EAAAA,KAAWF,EAAAA,2FAILkB,EAAAA,mGAGEjF,EAAAA,6PAOEmD,EAAAA,4DACgBrC,EAAS,2DACTC,EAAQ,oGAG9BG,EAAAA,KAASgD,EAAAA,KAAWH,EAAAA,6FAEpBC,EAAAA,KAASC,EAAAA,KAAWF,EAAAA,wXAYlBiB,EAAAA,ifAqB1B,OADqBsB,EAAAA,EAAAA,WACDC,cAChBL,EAAAA,CAAU7G,EAAcoG,EAAmBO,GAAAA,CCxHjD,SAASQ,IACP,MAAwB,WAAjBC,EAAAA,EAAAA,aAAAA,CAGT,SAAsBC,EAClBrH,EAA2BE,EAA0BqE,EACrD9C,EAAgBC,EAAegD,EAC/BvD,EAAuCK,EAAkB8F,EACzDxD,EAAiByD,EACjB3B,GAAAA,IAFCC,EAAAA,EAAAA,GAAUC,EAAAA,EAAAA,GAAAA,YAAAA,IAAAA,IAA8CwB,EAAAA,SAAAA,IAAAA,IACzDxD,EAAAA,QAAAA,IAAAA,IAAiByD,EAAAA,SAAAA,IAAAA,IACjB3B,EAAAA,IAAAA,EAAAA,UAAAA,OAAAA,GAAAA,WAAAA,IAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,OAAAA,EAAAA,MAAAA,SAAAA,GAAAA,OAAAA,EAAAA,OAAAA,KAAAA,EAAAA,OAEIF,EAAkBnB,EAAMiD,QAAO,YAAQ,SAAKnE,OAASiE,CAAAA,IAIvDH,KACIM,GAAsBvK,EAAAA,EAAAA,OAAQ,WAClC,IAAMwK,EAAkBjC,EACpBzF,EAAcE,EAAawF,EAAiBjE,EAAQC,EAAOgD,EAAAA,CAC1DmB,EAAUC,GAAUtE,EAASsC,EAAayD,EAC3C3B,GACE+B,GAAcC,EAAAA,EAAAA,UAAYC,qBAC5BH,EAAgBI,OAAQJ,EAAgBjL,MACxCiL,EAAgBK,OAEpB,OAAOrC,EAAgBpG,KACnB,SAAC0I,EAAG1C,GAAM,OD8F6BqB,SCrI7C3G,EAA2BsF,GAC7B,OAAOpI,EAAAA,EAAAA,OACH,WAAM,OAACC,EAAAA,EAAAA,OAAQ8K,EAAAA,EAAAA,OACXjI,GAAc3C,EAAAA,EAAAA,QAAUiI,IAAK,YAoCnB4C,CAAsBP,EAAarC,EAAAA,GAAAA,IAAAA,CAAAA,EAIxC6C,QAAQC,IAAIX,EAAoBnI,KAAI,YAAQ,SAAK+I,MAAAA,OAAAA,CAAAA,EAAAA,GAAAA,KAAAA,EAAAA,OAD5DC,EACK/G,EAAAA,OAGLkG,EAAoBc,SAAQ,YAAK,SAAEnI,SAAAA,IAAAA,CAAAA,EAAAA,GAAAA,KAAAA,EAET,SAAMJ,EAAaqI,QAAAA,KAAAA,EACrB,OADlBG,EAAoBjH,EAAAA,OAAAA,CAAAA,EACIrB,EAAYmI,QAAAA,KAAAA,EAApCI,EAAkBlH,EAAAA,OAExB+G,EFyCJ,SACItI,EAA0BE,EAC1BwF,EAAyBjE,EAAgBC,EAAegD,EACxDvD,EAAuCK,EACvCsC,EAAqBU,GAAAA,IADpBqB,EAAAA,EAAAA,GAAUC,EAAAA,EAAAA,QAAAA,IAAAA,IACUtB,EAAAA,GAUvB,IATA,IAAMkE,EACFhD,EAAgBpG,KAAI,YAAK,WAAIqJ,WAAWlH,EAASC,GAAO6E,KAAK,MAErD1E,EAAoBL,EAAAA,IAARmD,EAAQnD,EAAAA,KAE1BD,EACFD,EAAS,CAACG,EAAQC,GAAAA,CAASmE,EAAUC,GAAUtE,GAD5CoD,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GAERhB,EACL2B,EAAoB,CAACK,EAAUC,GAAUpB,GAAAA,GAClCzD,EAAI,EAAGA,EAAIQ,EAAQR,GAAK,EAC/B,IAAK,IAAI2H,EAAI,EAAGA,EAAIlH,EAAOkH,GAAK,EAAG,CACjC,IAAMC,EAAI5H,EAAIS,EAAQkH,EAEtB,GAAa,IADA5I,EAAa6I,GACV,CACd,IAAMzD,EAAOd,EAAyB,CACjCtC,EAAG4G,EAAGrJ,EAAG0B,GAAIf,EAAawF,EAAiBlB,EAAAA,CAC3C3C,EAAM8C,GAAAA,CAAQC,EAAQC,GAAShB,EAAAA,CAAoBpC,EAAQC,GAC5DgD,EAAQZ,GACRsB,GAAQ,IACVsD,EAAWtD,GAAMyD,GAAK,IAM9B,OAAOH,CAAAA,CEvEqBI,CACtBN,EAAmBC,EAAiB/C,EAAiBjE,EAAQC,EAC7DgD,EAAAA,CAASmB,EAAUC,GAAUtE,EAASsC,GAAAA,EAAAA,MAAAA,EAAAA,KAAAA,EAG5C,MAAO,CAAP,EAAOwE,EAAwBhJ,KAC3B,SAAC+I,EAAMpH,GAAM,OAAEoH,KAAAA,EAAMtF,KAAM2C,EAAgBzE,GAAIS,MAAAA,EAAOD,OAAAA,EAAAA,KAAAA,GAAAA,GAAAA,CAG5D,SAAsBsH,EAClB/I,EAA2BE,EAC3B8I,EAA+BzE,EAAe9C,EAAgBC,EAC9DgD,EAAgBvD,EAAuCK,EACvD8F,EAAoBxD,EAAiByD,EACrC3B,GAAAA,IAFiBC,EAAAA,EAAAA,GAAUC,EAAAA,EAAAA,GAAAA,YAAAA,IAAAA,IAC3BwB,EAAAA,SAAAA,IAAAA,IAAoBxD,EAAAA,QAAAA,IAAAA,IAAiByD,EAAAA,SAAAA,IAAAA,IACrC3B,EAAAA,IAAAA,EAAAA,UAAAA,OAAAA,GAAAA,WAAAA,IAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,OAAAA,EAAAA,MAAAA,SAAAA,GAAAA,OAAAA,EAAAA,OAAAA,KAAAA,EAAAA,OACIF,EAAkBnB,EAAMiD,QAAO,YAAQ,SAAKnE,OAASiE,CAAAA,IAIvDH,KACI8B,GAAoB/L,EAAAA,EAAAA,OAAQ,WAChC,IAAMwK,EAAkBjC,EACpBzF,EAAcE,EAAawF,EAAiBjE,EAAQC,EAAOgD,EAAAA,CAC1DmB,EAAUC,GAAUtE,EAASsC,EAAayD,EAC3C3B,GACE+B,GAAcC,EAAAA,EAAAA,UAAYC,qBAC9BH,EAAgBI,OAAQJ,EAAgBjL,MACxCiL,EAAgBK,OAElB,OAAOrC,EAAgBpG,KACnB,SAAC0I,EAAG1C,GACA,OA5Ed,SACItF,EAA2BkJ,EAAwB5D,GACrD,OAAOpI,EAAAA,EAAAA,OACH,WAAM,iBAAOmB,EAAAA,EAAAA,MAAOlB,EAAAA,EAAAA,OAAQ8K,EAAAA,EAAAA,OACxBjI,GAAc3C,EAAAA,EAAAA,QAAUiI,IAAK,UAAUrH,EAAAA,EAAAA,KAAOiL,EAAW,IAAK,MAwE1DC,CAA0BxB,EAAaqB,EAAkB1D,EAAAA,GAAAA,IAAAA,CAAAA,EAIxD6C,QAAQC,IAAIa,EAAkB3J,KAAI,YAAK,SAAE+I,MAAAA,OAAAA,CAAAA,EAAAA,GAAAA,KAAAA,EAAAA,OADpDe,EACK7H,EAAAA,OAGL0H,EAAkBV,SAAQ,YAAK,SAAEnI,SAAAA,IAAAA,CAAAA,EAAAA,GAAAA,KAAAA,EAEP,SAAMJ,EAAaqI,QAAAA,KAAAA,EACrB,OADlBG,EAAoBjH,EAAAA,OAAAA,CAAAA,EACIrB,EAAYmI,QAAAA,KAAAA,EACd,OADtBI,EAAkBlH,EAAAA,OAAAA,CAAAA,EACUyH,EAAiBX,QAAAA,KAAAA,EAA7CgB,EAAsB9H,EAAAA,OAE5B6H,EF8BJ,SACIpJ,EAA0BE,EAC1BoJ,EAA6B5D,EAAyBjE,EACtDC,EAAegD,EAAgBvD,EAC/BK,EAAkBsC,EAClBU,GAAAA,IAFgCqB,EAAAA,EAAAA,GAAUC,EAAAA,EAAAA,QAAAA,IAAAA,IAE1CtB,EAAAA,GAWF,IAVA,IAAMkE,EACFhD,EAAgBpG,KAAI,YAAK,WAAIiK,WAAW9H,EAASC,GAAO6E,MAAM,MAEtD1E,EAAoBL,EAAAA,IAARmD,EAAQnD,EAAAA,KAE1BD,EACFD,EAAS,CAACG,EAAQC,GAAAA,CAASmE,EAAUC,GAAUtE,GAD5CoD,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GAERhB,EACL2B,EAAoB,CAACK,EAAUC,GAAUpB,GAAAA,GAElCzD,EAAI,EAAGA,EAAIQ,EAAQR,GAAK,EAC/B,IAAK,IAAI2H,EAAI,EAAGA,EAAIlH,EAAOkH,GAAK,EAAG,CACjC,IAAMC,EAAI5H,EAAIS,EAAQkH,EAEtB,GAAa,IADA5I,EAAa6I,GACV,CACd,IAAMzD,EAAOd,EAAyB,CACjCtC,EAAG4G,EAAGrJ,EAAG0B,GAAIf,EAAawF,EAAiBlB,EAAAA,CAC3C3C,EAAM8C,GAAAA,CAAQC,EAAQC,GAAShB,EAAAA,CAAoBpC,EAAQC,GAC5DgD,EAAQZ,GACRsB,GAAQ,IACVsD,EAAWtD,GAAMyD,GAAKS,EAAgBT,GAAAA,CAAAA,CAM9C,OAAOH,CAAAA,CE9D2Bc,CAC5BhB,EAAmBC,EAAiBY,EACpC3D,EAAiBjE,EAAQC,EAAOgD,EAAAA,CAASmB,EAAUC,GAAUtE,EAC7DsC,GAAAA,EAAAA,MAAAA,EAAAA,KAAAA,EAGN,MAAO,CAAP,EAAOsF,EAA8B9J,KACjC,SAAC+I,EAAM/C,GAAM,OAAEvC,KAAM2C,EAAgBJ,GAAI+C,KAAAA,EAAM5G,OAAAA,EAAQC,MAAAA,EAAAA,KAAAA,GAAAA,GAAAA,CC5G7D,SAAS+H,EAAKnE,GACZ,OAAOhC,KAAKoG,MAAMpE,EAAI,GAGxB,iBAKE,WAAYqE,EAAiBC,GAC3BlL,KAAKmL,cAAgB,IAAIC,MAAMH,GAC/BjL,KAAKqL,kBAAoB,EACzBrL,KAAKkL,gBAAkBA,CAAAA,CAkE3B,OA/DSI,EAAAA,UAAAA,QAAP,SAAehI,GACbtD,KAAKmL,gBAAgBnL,KAAKqL,kBAAoB/H,EAC9CtD,KAAKuL,KAAKvL,KAAKqL,iBAAAA,EAGVC,EAAAA,UAAAA,QAAP,WACE,IAAMtH,EAAMhE,KAAKmL,cAAc,GAI/B,OAHAnL,KAAKwL,SAAS,EAAGxL,KAAKqL,oBACtBrL,KAAKyL,KAAK,GACVzL,KAAKmL,cAAcnL,KAAKqL,iBAAmB,GAAK,KACzCrH,CAAAA,EAGFsH,EAAAA,UAAAA,MAAP,WACE,OAAkC,IAA3BtL,KAAKqL,gBAAAA,EAGPC,EAAAA,UAAAA,KAAP,WACE,OAAOtL,KAAKqL,iBAAmB,GAG1BC,EAAAA,UAAAA,IAAP,WACE,OAAOtL,KAAKmL,cAAc5D,MAAM,EAAGvH,KAAKqL,iBAAmB,IAGtDC,EAAAA,UAAAA,IAAP,WACE,OAAOtL,KAAKmL,cAAc,IAGpBG,EAAAA,UAAAA,KAAR,SAAa1E,GACX,KAAOA,EAAI,GAAK5G,KAAK0L,KAAKX,EAAKnE,GAAIA,IACjC5G,KAAKwL,SAAS5E,EAAGmE,EAAKnE,IACtBA,EAAImE,EAAKnE,EAAAA,EAIL0E,EAAAA,UAAAA,KAAR,SAAa1E,GACX,KAAO,EAAIA,GAAK5G,KAAKqL,kBAAkB,CACrC,IAAInB,EAAI,EAAItD,EAIZ,GAHIsD,EAAIlK,KAAKqL,kBAAoBrL,KAAK0L,KAAKxB,EAAGA,EAAI,IAChDA,KAEGlK,KAAK0L,KAAK9E,EAAGsD,GAChB,MAEFlK,KAAKwL,SAAS5E,EAAGsD,GACjBtD,EAAIsD,CAAAA,CAAAA,EAIAoB,EAAAA,UAAAA,WAAR,SAAmB/I,GACjB,OAAOvC,KAAKkL,gBAAgBlL,KAAKmL,cAAc5I,GAAAA,EAGzC+I,EAAAA,UAAAA,KAAR,SAAa/I,EAAW2H,GACtB,OAAOlK,KAAK2L,WAAWpJ,GAAKvC,KAAK2L,WAAWzB,EAAAA,EAGtCoB,EAAAA,UAAAA,SAAR,SAAiB/I,EAAW2H,GAC1B,IAAMzE,EAAIzF,KAAKmL,cAAc5I,GAC7BvC,KAAKmL,cAAc5I,GAAKvC,KAAKmL,cAAcjB,GAC3ClK,KAAKmL,cAAcjB,GAAKzE,CAAAA,EAAAA,CAAAA,CAxE5B,GCLA,SAESmG,EACLC,EAAoBlH,EAAef,EAAkBD,EACrDmI,EAA4BC,GAM9B,IALM,MAAkBA,EAAOhO,MAAxBgF,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GAEXgJ,GAAAA,EACEC,EAASrH,KAAKZ,IAAIJ,EAAWkI,EAAoB,GACjDI,EAAOtH,KAAKb,IAAIH,EAAWkI,EAAqB,EAAG/I,GAChDoJ,EAAWF,EAAQE,EAAWD,IAAQC,EAAU,CAGvD,IAFA,IAAMC,EAASxH,KAAKZ,IAAIL,EAAWmI,EAAoB,GACjDO,EAAOzH,KAAKb,IAAIJ,EAAWmI,EAAqB,EAAG9I,GAChDsJ,EAAWF,EAAQE,EAAWD,IAAQC,EAC7C,GAAIP,EAAOvI,IAAI2I,EAAUG,EAAUT,GAAclH,EAAO,CACtDqH,GAAAA,EACA,MAGJ,IAAKA,EACH,MAIJ,OAAOA,CAAAA,CC1BT,IAMMO,EP+BOC,CAAAA,CACV,OAAQ,YAAa,UAAW,YAAa,OAAQ,aACrD,WAAY,aAAc,OAAQ,iBAClC,eAAgB,cAAe,YAAa,cAC5C,eAAgB,YAAa,UAAW,aACxC,WAAY,cAAe,OAAQ,kBACnC,gBAAiB,eAAgB,aAAc,eAC/C,gBAAiB,aAAc,WAAY,cAC3C,YAAa,eOvCuC5L,KACnD,SAAC6B,GAAAA,IAACgK,EAAAA,EAAAA,GAAgBC,EAAAA,EAAAA,GACd,OAAEvK,EAASsK,GAAiBtK,EAASuK,GAAAA,IAEvCC,EACFJ,EAAqB3L,KAAI,SAAC6B,GAAqB,eAE7CmK,EACFL,EAAqB3L,KAAI,SAAC6B,GAEK,eAWnC,SAASoK,EACLC,EAAiB/M,EAAsBgD,EACvCC,GACF,MAAO,CACLnC,EAAGgD,EAAMe,KAAK0B,MAAMwG,EAAMjM,EAAId,GAAe,EAAGgD,EAAS,GACzDO,EAAGO,EAAMe,KAAK0B,MAAMwG,EAAMxJ,EAAIvD,GAAe,EAAGiD,EAAQ,IAW5D,SAAS+J,EACLC,EAAgBC,EAA0BC,EAC1CC,EAA8BhM,EAAyBpB,EACvDqN,EAA+BC,QAAAA,IAAAA,IAAAA,EAAAA,GAYjC,IAXM,MAAkBF,EAAapP,MAA9BgF,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GAMTsK,EAnCR,SACIN,EAAgBF,EAAiBM,GACnC,IAAMG,EAAWH,EAAcrP,MAAM,GAAK,EAC1C,MAAO,CACL8C,EAAGuM,EAAc5J,IAAIsJ,EAAMjM,EAAGiM,EAAMxJ,EAAG0J,GACvC1J,EAAG8J,EAAc5J,IAAIsJ,EAAMjM,EAAGiM,EAAMxJ,EAAGiK,EAAWP,GAAAA,CA+BhDQ,CAAgBR,EAJUH,EAC1BI,EAAepI,SAAU9E,EAAcgD,EAAQC,GAGAoK,GAG/CK,EADmBxJ,EAAWgJ,EAAepI,SAAUyI,GAElD/K,EAAI,EAAGA,EAAI8K,EAAkB9K,IAAK,CACzC,IAAMmL,EACFb,EAAyBY,EAAgB1N,EAAcgD,EAAQC,GAE7D2K,EAActK,EAChBqK,EAAsB7M,EAAG6M,EAAsBpK,EAAG4J,EAClD/L,GAEJsM,EAAiBxJ,EAAW,CAEtBX,EAAGoK,EAAsBpK,EAAIvD,EAC7Bc,EAAG6M,EAAsB7M,EAAId,GAAAA,CAE9BuD,EAAGqK,EAAYrK,EAAGzC,EAAG8M,EAAY9M,GAAAA,CAExC,IAAM+M,EACFf,EAAyBY,EAAgB1N,EAAcgD,EAAQC,GAC7D2B,EAAQwI,EAAa3J,IACvBoK,EAAsB/M,EAAG+M,EAAsBtK,EAAG4J,GAEtD,MAAO,CAACrI,SAAU4I,EAAgB/J,KAAM1B,EAAWkL,GAAmBvI,MAAAA,EAAAA,CASxE,SAAgBkJ,EACZC,EAAqB/B,EAAwB5K,EAC7CpB,EAAsBgO,EACtBC,GACF,IAAMlQ,EAAWiO,EAAOhO,MAAM,GACxBwP,EAAWZ,EAAmBzK,OAE9B+L,EAAgC,IAAI7C,MAAMtN,GAEnCoQ,EAA8BJ,EAAAA,KAAbK,EAAaL,EAAAA,MACrCM,EAAY3K,EAAeyK,EAAUnO,EAAcoB,GAEzD8M,EAAkBC,EAASG,IAAM,CAC/B1J,MAAOwJ,EACPzK,KAAM1B,EAAWkM,EAASG,IAC1BxJ,SAAUuJ,GAKZ,IAAK,IAAIE,EAAOf,EAAW,EAAGe,GAAQ,IAAKA,EAAM,CAC/C,IAAMC,EAAmB5B,EAAmB2B,GACtCpB,EAAmBN,EAAmB0B,GACxCL,EAAkBM,KACjBN,EAAkBf,KACrBe,EAAkBf,GAAoBH,EAClCuB,EAAML,EAAkBM,GAAmBrB,EAAkBnB,EAC7D5K,EAASpB,EAAciO,GAAAA,CAM/B,IAASM,EAAO,EAAGA,EAAOf,IAAYe,EAC9BC,EAAmB3B,EAAmB0B,GACtCpB,EAAmBP,EAAmB2B,GACxCL,EAAkBM,KACjBN,EAAkBf,KACrBe,EAAkBf,GAAoBH,EAClCuB,EAAML,EAAkBM,GAAmBrB,EAAkBnB,EAC7D5K,EAASpB,EAAcgO,IAI/B,OAAOE,CAAAA,CCjIT,SAISO,EACL3I,EAAe4I,EAA0BhM,EACzCoJ,GAAAA,IAD0CvI,EAAAA,EAAAA,EAAGzC,EAAAA,EAAAA,EAE/C,OAAOgF,EAAM6I,MAAK,SAACjM,GAAAA,IACXkM,EAAAA,EAAAA,UAAkC9C,GAAYhH,SACpD,OPwCJ,SACI+J,EAAYC,EAAYC,EAAYC,GACtC,IAAMxJ,EAAKuJ,EAAKF,EACVpJ,EAAKuJ,EAAKF,EAChB,OAAOtJ,EAAKA,EAAKC,EAAKA,CAAAA,CO5CbwJ,CACInO,EAAGyC,EAAGqL,EAAsB9N,EAAG8N,EAAsBrL,IAC5DmL,CAAAA,GAAAA,CAQR,SAASQ,EACLC,EAAuBT,EACvBR,GAUF,OATkCA,EAAkB7L,QAChD,SAACC,EAAQI,EAAmBoJ,GAAAA,IAAlBhH,EAAAA,EAAAA,SAAUF,EAAAA,EAAAA,MAKlB,OAJK6J,EACGU,EAAeT,EAAkB5J,EAAUgH,KACjDxJ,GAAUsC,GAELtC,CAAAA,GACN,GAE+B4L,EAAkB/L,MAAAA,CAM1D,IAAMiN,EAAsB,EAyD5B,SAAgBC,EACZjC,EAA8BkC,EAC9BC,EACAC,EAAwCxP,EACxCyP,EAA2BC,EAAsBC,QAAAA,IAAAA,IAAtBD,EAAAA,SAAAA,IAAAA,IAAsBC,EAAAA,IAUnD,IATA,IAAM7J,EAAAA,GAEA8J,EFrER,SACIF,EAAwB3D,EACxBC,GAMF,IALM,MAAgCA,EAAOhO,MAAtCgF,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GAAO4M,EAAAA,EAAAA,GAEhBD,EAAQ,IAAIrE,EACdvI,EAASC,EAAQ4M,GAAc,SAACnN,GAAY,SAAAkC,KAAA,IAEvCf,EAAW,EAAGA,EAAWb,IAAUa,EAC1C,IAAK,IAAID,EAAW,EAAGA,EAAWX,IAASW,EACzC,IAAK,IAAIkI,EAAa,EAAGA,EAAa+D,IAAgB/D,EAAY,CAChE,IAAMlH,EAAQoH,EAAOvI,IAAII,EAAUD,EAAUkI,GAIzClH,EAAQ8K,GAKR7D,EACIC,EAAYlH,EAAOf,EAAUD,EAAUmI,EACvCC,IACN4D,EAAME,QAAQ,CAAClL,MAAAA,EAAOjB,KAAM,CAACE,SAAAA,EAAUD,SAAAA,EAAU0K,GAAIxC,IAAAA,CAM7D,OAAO8D,CAAAA,CEwCOG,CACVL,EAAgBN,EAAqBhC,GAEnCsB,EAAmBiB,EAAYA,EAI9B7J,EAAM3D,OAASsN,IAAsBG,EAAMI,SAAS,CAEzD,IAAMjC,EAAO6B,EAAMK,UAOnB,IAAIxB,EACI3I,EAAO4I,EAFXhL,EAAeqK,EAAKpK,KAAM3D,EAAcsP,GAEMvB,EAAKpK,KAAK2K,IAD5D,CAMA,IAAM3J,EAAYmJ,EACdC,EAAMX,EAAckC,EAAetP,EAAcuP,EACjDC,GAEE5K,EAAQsK,EAAiBpJ,EAAO4I,EAAkB/J,GAExDmB,EAAMY,KAAK,CAAC/B,UAAAA,EAAWC,MAAAA,GAAAA,CAAAA,CAGzB,OAAOkB,CAAAA,CAAAA,IAAAA,EClIHoK,EAAe,EAAE,QAAS,OAAS,QAAAC,EAAAA,SAAAA,GAEzC,2BAAAvO,GAAAA,EAAA,4BA2BA,OA3B4BC,EAAAA,EAAAA,GAC1BsO,EAAAA,UAAAA,gBAAAA,SAAgB7P,GACd,OAAOd,EAAAA,EAAAA,KAAOc,EAAO4P,EAAAA,EAGvBC,EAAAA,UAAAA,kBAAAA,SAAkBnO,GAEd,MAQAA,EAAAA,GAPAX,EAOAW,EAAAA,GANAb,EAMAa,EAAAA,GALAP,EAKAO,EAAAA,GAJAZ,EAIAY,EAAAA,GAHAR,EAGAQ,EAAAA,GACF,MAAO,CACLZ,QAAAA,EACAG,aAHAS,EAAAA,GAIAR,aAAAA,EACAC,YAAAA,EACAN,QAAAA,EACAE,gBAAAA,EACAC,gBAAAA,EACAI,YATAM,EAAAA,GAAAA,EAAAA,CAAAA,CAjBmCmO,CAEb9P,GCNtB+P,EACF,0EACEC,EACF,2EC6BJ,SAAgBC,EAAahQ,GAC3B,GAAoC,uCAC/BA,aAAiBiQ,mBACY,qCAC1BjQ,aAAiBkQ,iBACU,sCAC9BlQ,aAAiBmQ,iBACpB,ODXIC,SCrB6BpQ,GAGnC,GAAI,iBAAkBA,GAAgC,IAAvBA,EAAMqQ,cAC9B,gBAAiBrQ,GAA+B,IAAtBA,EAAMsQ,YACrC,MAAO,CAACtQ,EAAMqQ,aAAcrQ,EAAMsQ,aAC7B,GAAoB,MAAhBtQ,EAAM0C,QAAiC,MAAf1C,EAAM2C,MACvC,MAAO,CAAC3C,EAAM0C,OAAQ1C,EAAM2C,OAE5B,MAAM,IAAI4N,MACN,+DAsBGC,CAA4BxQ,GAC9B,GAA2B,+BAAeA,aAAiByQ,UAChE,MAAO,CAACzQ,EAAM0C,OAAQ1C,EAAM2C,OACvB,GAC2B,sCAC9B3C,aAAiB0Q,iBACnB,OAxBJ,SAAiC1Q,GAC/B,OAAIA,EAAM2Q,aAAa,WAAa3Q,EAAM2Q,aAAa,UAI7C3Q,EAAM0C,OAAQ1C,EAAM2C,OAAAA,CAEpB3C,EAAM4Q,YAAa5Q,EAAM6Q,WAAAA,CAiB1BC,CAAwB9Q,GAC1B,GAAIA,aAAiB+Q,EAAAA,OAC1B,MAAO,CAAC/Q,EAAMtC,MAAM,GAAIsC,EAAMtC,MAAM,IAEpC,MAAM,IAAI6S,MAAM,8BAA8BvQ,EAAAA,IAAAA,CASlD,SAAgBgR,EACZC,EAAyBvR,GAC3B,OAPF,SACIwR,EAAoBxR,GACtB,OAAQwR,EAAa,GAAKxR,GAAiB,EAKvCyR,CAAuBF,EAAiBvR,GACnCuR,EAGF1M,KAAKoG,MAAMsG,EAAkBvR,GAAgBA,EAAe,EAGrE,IAAM0R,EAAqC,CACzCC,IAAK,MACLC,OAAQ,SACRC,KAAM,OACNC,KAAM,QAGFC,IAAAA,EAAAA,CAAAA,GACHL,EAAmCC,KAAM,IAC1CjP,EAACgP,EAAmCE,QAAS,GAC7ClP,EAACgP,EAAmCG,MAAO,IAC3CnP,EAACgP,EAAmCI,MAAO,KAGvCE,GAA0B,GAC1BC,GAA0B,EA2BhC,SAAgBC,GACZC,EACAnS,EACA0C,GAAAA,IAAC0P,EAAAA,EAAAA,GAAaC,EAAAA,EAAAA,GACVC,EA7BR,SACIH,GACF,GAAkC,iBAAvBA,EAAiC,CAC1C,IAAM7P,EAASyP,EAAgCI,GAO/C,OALA/R,EAAAA,KAAAA,OACsB,iBAAXkC,GACP,WAAM,wDACFiQ,OAAOC,OAAOd,GACTe,KAAK,iBAAgBN,EAAAA,GAAAA,IAC3B7P,CAAAA,CAWP,OATAlC,EAAAA,KAAAA,OACkC,iBAAvB+R,GACHA,GAAsBF,IACtBE,GAAsBH,IAC1B,WACI,4DACIA,GAAAA,QAA+BC,GAAAA,aAC5BE,CAAAA,IAERA,CAAAA,CASLO,CAA+BP,GAEnC,MAAO,CACLb,EACIc,EAAcE,EAA8BtS,GAChDsR,EACIe,EAAaC,EAA8BtS,GAAAA,CAmEnD,SAAgB2S,GACZC,EACAlQ,EACAI,EACAkD,EACA6M,GAAAA,IAHCC,EAAAA,EAAAA,GAAmBC,EAAAA,EAAAA,GACnBC,EAAAA,EAAAA,GAAwBC,EAAAA,EAAAA,GACxBC,EAAAA,EAAAA,GAAC9P,EAAAA,EAAAA,GAAMC,EAAAA,EAAAA,GAAO8P,EAAAA,EAAAA,GAACjN,EAAAA,EAAAA,GAAMkN,EAAAA,EAAAA,GAExB,YAAO,IAAP,IADEP,GAAAA,IACKpU,EAAAA,EAAAA,OAAQ,WACb,IAAI4U,EAAkCC,EAAAA,MAAAA,eAAwBV,EAAAA,CACzDI,EAAwBC,IAAAA,GAM7B,OAJIJ,IACFQ,GAAqBnS,EAAAA,EAAAA,SAAWmS,IAStC,SACIE,EACA7Q,EACAI,GAAAA,IADC0Q,EAAAA,EAAAA,GAAgBC,EAAAA,EAAAA,GAChBzN,EAAAA,EAAAA,GAAC5C,EAAAA,EAAAA,GAAMC,EAAAA,EAAAA,GAAO6P,EAAAA,EAAAA,GAAChN,EAAAA,EAAAA,GAAMkN,EAAAA,EAAAA,GAExB,OAAO3U,EAAAA,EAAAA,OAAQ,WACb,IAAMiV,GAA4BvU,EAAAA,EAAAA,YAAcoU,GAChD,OAAOI,EAAAA,EAAAA,SAAWL,EAAAA,MAAAA,cAEVI,EAAAA,CAAAA,CACEtQ,GAAQoQ,EAAiBpQ,EAAOC,EAAO,GACvC6C,GAAQuN,EAAgBvN,EAAOkN,EAAO,IACrChQ,EAAOoQ,EAAiB,IACpBA,EAAiBpQ,EAAOC,EAAO,IACnC6C,EAAOuN,EAAgB,IAAQA,EAAgBvN,EAAOkN,EAAO,MAE/D,GAAI,CAACI,EAAgBC,IAAAA,CAAkB,OAtBzCG,CACHP,EAAAA,CAAqBP,EAAmBC,GAAAA,CAAAA,CACtC3P,EAAMC,GAAAA,CAAQ6C,EAAMkN,IAAAA,GAAAA,CAwB9B,SAUgBS,GACZvT,EAAqBoC,GAAAA,IAACoR,EAAAA,EAAAA,GAASC,EAAAA,EAAAA,GAE3BjR,EAAkBwN,EAAahQ,GAA9B0C,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GACT+Q,EAAeD,EAAUD,EAE3B9N,EAAAA,CAA4B,EAAG,EAAG,EAAG,GAApC5C,EAAAA,EAAAA,GAAMC,EAAAA,EAAAA,GAAM6C,EAAAA,EAAAA,GAAMkN,EAAAA,EAAAA,GAsBvB,OAvBenQ,EAAQD,EAEVgR,GAEX5Q,EAAO,EACPC,EAAO,EACP6C,EAAOrB,KAAK0B,MAAM,IAAOyN,EAAehR,EAASC,IACjDmQ,EAAOvO,KAAK0B,MAAM,IAAOyN,EAAehR,EAASC,MAGjDG,EAAOyB,KAAK0B,MAAM,IAAQ,EAAMyN,EAAgB/Q,EAAQD,IACxDK,EAAOwB,KAAK0B,MAAM,IAAQ,EAAMyN,EAAgB/Q,EAAQD,IACxDkD,EAAO,EACPkN,EAAO,IAUDa,SAPqBxV,EAAAA,EAAAA,OAAQ,WACnC,IAAIyV,EAvIR,SAA8B5T,GAG5B,OAAOA,aAAiB+Q,EAAAA,OAAY/Q,EAAQ6T,EAAAA,QAAAA,WAAsB7T,EAAAA,CAoI9C8T,CAAc9T,GAGhC,OAFA4T,GAAcG,EAAAA,EAAAA,OAASH,EAAAA,CAAAA,CAAe9Q,EAAMC,GAAAA,CAAQ6C,EAAMkN,GAAAA,CAAQ,EAAG,KAE9DE,EAAAA,MAAAA,eAAwBY,EAAAA,CAAcJ,EAASC,GAAAA,IAGvChR,QAAS,CAACuR,IAAKlR,EAAMmR,KAAMrO,EAAMsO,MAAOpB,EAAMqB,OAAQpR,GAAAA,CAGzE,SAAsBqR,GAAkBC,GAAAA,OAAAA,EAAAA,UAAAA,OAAAA,GAAAA,WAAAA,OAAAA,EAAAA,MAAAA,SAAAA,GAEtC,MAAO,CAAP,EAAOjL,QAAQC,IAAIgL,EAAQ9T,KAAI,YAAU,SAAO+T,QAAAA,KAAAA,GAAAA,GAAAA,CA8ClD,SAAgBC,GACZ/O,EAAepD,EACfI,EACAC,EAAkB+R,GAAAA,IAFF9R,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GACvB8R,EAAAA,EAAAA,GAAuBC,EAAAA,EAAAA,GAOpBC,EApCR,SACInP,EAAeM,EAAgBD,EAAgB+O,EAAaC,GAC9D,oBADiDD,EAAAA,QAAAA,IAAAA,IAAaC,EAAAA,GAC/C,IAAXhP,GAA2B,IAAXC,GAA4B,IAAZ8O,GAA6B,IAAZC,EAC5CrP,EAEFA,EAAMjF,KAAI,YAAQ,OArB3B,SACIyD,EAAY8B,EAAgBD,EAAgB+O,EAC5CC,GACF,YAAO,IAAPC,IAF8CF,EAAAA,QAAAA,IAAAA,IAC5CC,EAAAA,GAAAA,CAEAvQ,MAAON,EAAKM,MACZD,UAAWL,EAAKK,UAAU9D,KAAI,SAAC6B,GAAAA,IAACkC,EAAAA,EAAAA,MAAOjB,EAAAA,EAAAA,KAAMmB,EAAAA,EAAAA,SAAc,OAC3BF,MAAAA,EACAjB,KAAAA,EACAmB,SAAU,CACRvB,EAAGuB,EAASvB,EAAI4C,EAASgP,EACzBrU,EAAGgE,EAAShE,EAAIsF,EAAS8O,GAAAA,IAAAA,CAWpCG,CAAU/Q,EAAM8B,EAAQD,EAAQ+O,EAASC,EAAAA,GAAAA,CAgC9DG,CAAWxP,GALV9C,EAASD,EAAQuR,IAAMvR,EAAQ0R,QAAU,GAEzCxR,EAAQF,EAAQwR,KAAOxR,EAAQyR,OAAS,GAGNzR,EAAQuR,KAAMvR,EAAQwR,MAE7D,OAAIO,EAnBN,SAAoChP,EAAeyP,GACjD,OAAIA,GAAc,EACTzP,EAEFA,EAAMjF,KAAI,YAAQ,OAhB3B,SAAmCyD,EAAYiR,GAC7C,MAAO,CACL3Q,MAAON,EAAKM,MACZD,UAAWL,EAAKK,UAAU9D,KACtB,SAAC6B,GAAAA,IAACkC,EAAAA,EAAAA,MAAOjB,EAAAA,EAAAA,KAAMmB,EAAAA,EAAAA,SAAc,OAC3BF,MAAAA,EACAjB,KAAAA,EACAmB,SAAU,CAACvB,EAAGgS,EAAa,EAAIzQ,EAASvB,EAAGzC,EAAGgE,EAAShE,GAAAA,IAAAA,CAStC0U,CAAmBlR,EAAMiR,EAAAA,GAAAA,CAgBzCE,CAAoBR,EAAahS,GAEjCgS,CAAAA,CAAAA,IC5TLS,IAA2B,EAC3BC,IAA2B,EAoD3BC,GAAsB,CAC1BC,aAAc,cACd7V,aAAc,GACd8V,WAAY,EACZC,WAAY,KAGRC,GAAAA,CAA6C,cAAe,YAC5DC,GAAAA,CACJC,YAAAA,CAAgB,EAAG,GAAI,IACvBC,SAAAA,CAAa,GAAI,KAEbC,GAAAA,CACJF,YAAAA,CAAgB,GAAM,IAAM,GAC5BC,SAAAA,CAAa,IAETE,GAAAA,CAA0C,EAAG,EAAG,GA6HtD,IAAaC,GAAAA,CACXxB,gBAAgB,EAChB3C,mBAAoB,SACpBoE,sBAAuB,GACvBC,cAAe,GACf9G,eAAgB,GAChBC,UAAW,IAGA8G,GAAAA,CAEP3B,gBAAgB,EAChB3C,mBAAoB,SACpBoE,sBAAuB,GACvBC,cAAe,GACf9G,eAAgB,GAChBC,UAAW,GACX7G,iBAAkB,GAClBzD,YAAa,IAGnB,SAASqR,GAA8BC,GAC9B,MACHA,EAAAA,sBAD0BH,EAC1BG,EAAAA,cADyCjH,EACzCiH,EAAAA,eADyDhH,EACzDgH,EAAAA,UAEJ,GAAIJ,EAAwB,GAAOA,EAAwB,EACzD,MAAM,IAAI1F,MACN,yBAAyB0F,EAAAA,mCAI/B,GAAIC,GAAiB,EACnB,MAAM,IAAI3F,MACN,yBAAyB2F,EAAAA,mBAI/B,GAAI9G,EAAiB,GAAOA,EAAiB,EAC3C,MAAM,IAAImB,MACN,0BAA0BnB,EAAAA,mCAIhC,GAAIC,GAAa,EACf,MAAM,IAAIkB,MAAM,qBAAqBlB,EAAAA,IAAAA,CAIzC,SAASiH,GACLD,GAEA,MAMEA,EAAAA,sBALFH,EAKEG,EAAAA,cAJFjH,EAIEiH,EAAAA,eAHFhH,EAGEgH,EAAAA,UAFF7N,EAEE6N,EAAAA,iBADFtR,EACEsR,EAAAA,YAEJ,GAAIJ,EAAwB,GAAOA,EAAwB,EACzD,MAAM,IAAI1F,MACN,yBAAyB0F,EAAAA,mCAI/B,GAAIC,GAAiB,EACnB,MAAM,IAAI3F,MACN,yBAAyB2F,EAAAA,mBAI/B,GAAI9G,EAAiB,GAAOA,EAAiB,EAC3C,MAAM,IAAImB,MACN,0BAA0BnB,EAAAA,mCAIhC,GAAIC,GAAa,EACf,MAAM,IAAIkB,MAAM,qBAAqBlB,EAAAA,KAGvC,GAAI7G,EAAmB,GAAKA,EAAmB,EAC7C,MAAM,IAAI+H,MACN,4BAA4B/H,EAAAA,kCAIlC,GAAIzD,GAAe,GAAKA,EAAc,GACpC,MAAM,IAAIwL,MACN,uBAAuBxL,EAAAA,8BAAAA,CAK/B,kBAGE,WAAYwR,GACV5W,KAAK6W,UAAYD,CAAAA,CA+oBrB,OA5oBUE,EAAAA,UAAAA,6BAAR,SAAqCzW,GAO7B,MAMFL,KAAK6W,UAAUlW,QAAQN,GAC3B,MAAO,CACL0W,cAAe,EAAfA,aACA/V,cAAAA,EAAAA,cACAG,QAAAA,EAAAA,QACAC,gBAAAA,EAAAA,gBACAC,gBAAAA,EAAAA,gBAAAA,EAIIyV,EAAAA,UAAAA,oCAAR,SAA4CzW,GAQpC,MAOFL,KAAK6W,UAAUlW,QAAQN,GAC3B,MAAO,CACL0W,cAAe,EAAfA,aACAC,kBAAmB,EAAnBA,aACAhW,cAAAA,EAAAA,cACAG,QAAAA,EAAAA,QACAC,gBAAAA,EAAAA,gBACAC,gBAAAA,EAAAA,gBAAAA,EAIIyV,EAAAA,UAAAA,iDAAR,SAAyDzW,GAUjD,MAQFL,KAAK6W,UAAUlW,QAAQN,GAC3B,MAAO,CACL0W,cAAe,EAAfA,aACAvV,YAAAA,EAAAA,YACAR,cAAAA,EAAAA,cACAG,QAAAA,EAAAA,QACAC,gBAAAA,EAAAA,gBACAC,gBAAAA,EAAAA,gBACAE,aAAAA,EAAAA,aAAAA,EAuCJuV,EAAAA,UAAAA,wBAAAA,SACIzW,EAAqB6R,EACrBoE,GAFJ,wBAEIA,EAAAA,IASI,MAAkBjG,EAAahQ,GAA9B0C,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GACTiU,EAAmChF,GACrCC,EAAoBlS,KAAK6W,UAAU9W,aAAc,CAACgD,EAAQC,IACxDH,EACF+Q,GAAevT,EAAO4W,GADnBjD,EAAAA,EAAAA,QAASlR,EAAAA,EAAAA,QAGViD,GAMFvH,EAAAA,EAAAA,OAAQ,WACJ,MAMF+B,EAAK2W,6BAA6BlD,GALpC+C,EAAAA,EAAAA,cACA/V,EAAAA,EAAAA,cACAG,EAAAA,EAAAA,QACAC,EAAAA,EAAAA,gBACAC,EAAAA,EAAAA,gBAGIwB,EAAgCmR,EAAQjW,MAAvCoZ,EAAAA,EAAAA,GAAeC,EAAAA,EAAAA,GAEhBC,EAAsB3E,GACxBqE,EAAAA,CAAgBhU,EAAQC,GAAAA,CAASmU,EAAeC,GAAAA,CAAAA,CAC9CtU,EAAQuR,IAAKvR,EAAQ0R,QAAS,CAAC1R,EAAQwR,KAAMxR,EAAQyR,QACvDkB,IAEJ,MAAO,CACLnU,aAAcjD,GACVqV,EAAAA,EAAAA,SAAW2D,GAAsBf,GACrCtV,cAAAA,EACAG,QAAAA,EACAC,gBAAAA,EACAC,gBAAAA,EAAAA,IA3BFC,EAAAA,EAAAA,aACAN,EAAAA,EAAAA,cACAG,EAAAA,EAAAA,QACAC,EAAAA,EAAAA,gBACAC,EAAAA,EAAAA,gBA2BF,OADA2S,EAAQtS,UAAAA,CAENJ,aAAAA,EACAN,cAAAA,EACAG,QAAAA,EACAC,gBAAAA,EACAC,gBAAAA,EACAyB,QAAAA,EACAmU,iCAAAA,EAAAA,EA6BEH,EAAAA,UAAAA,cAAN,SACIzW,EACAqW,GAAAA,YAAAA,IAAAA,IAAAA,EAAAA,IAAAA,EAAAA,UAAAA,OAAAA,GAAAA,WAAAA,IAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,OAAAA,EAAAA,MAAAA,SAAAA,GAAAA,OAAAA,EAAAA,OAAAA,KAAAA,EAoBa,OAhBfD,GAFAC,EAAAA,EAAAA,EAAAA,CAAAA,EAAaL,IAA4BK,IAInCjU,EASFzC,KAAKsX,wBACDjX,EAAOqW,EAAOxE,mBAAoBwE,EAAOJ,uBAT/ChV,EAAAA,EAAAA,aACAN,EAAAA,EAAAA,cACAG,EAAAA,EAAAA,QACAC,EAAAA,EAAAA,gBACAC,EAAAA,EAAAA,gBACAyB,EAAAA,EAAAA,QACAmU,EAAAA,EAAAA,iCAKIpU,EAAkBvB,EAAavD,MAA9BgF,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GAAAA,CAAAA,EAEM1B,EAAaqI,QAAAA,KAAAA,EAGZ,OAHhBtH,EAAS0D,EAAAA,OACfzE,EAAaI,UAAAA,CAAAA,EAEe+S,GAAkB,CACzCzT,EAAeG,EAASC,EAAiBC,KAAAA,KAAAA,EAkB9C,OAnBMkW,EAAgBxR,EAAAA,OAEfyR,EACHD,EAAAA,GADcE,EACdF,EAAAA,GAD0BG,EAC1BH,EAAAA,GAD+CI,EAC/CJ,EAAAA,GAOJ1R,EAAQ+O,GALJ/O,EAAQuJ,EACRoI,EAAWC,EAAYC,EAAqBC,EAC5C3X,KAAK6W,UAAU9W,aAAc2W,EAAOH,cACpCG,EAAOjH,eAAgBiH,EAAOhH,WAAAA,CAGtB3M,EAAQC,GAAQiU,EAAkCnU,EAC1D4S,IAEJ1U,EAAcU,UACdP,EAAQO,UACRN,EAAgBM,UAChBL,EAAgBK,UAAAA,CAAAA,EAAAA,CAERqB,OAAAA,EAAQC,MAAAA,EAAO2G,KAAMtH,EAAQuV,SAAU/R,IAAAA,GAAAA,GAAAA,EA0B3CiR,EAAAA,UAAAA,mBAAN,SACIzW,EACAqW,GAAAA,YAAAA,IAAAA,IAAAA,EAAAA,IAAAA,EAAAA,UAAAA,OAAAA,GAAAA,WAAAA,IAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,KAAAA,OAAAA,EAAAA,MAAAA,SAAAA,GAAAA,OAAAA,EAAAA,OAAAA,KAAAA,EAwDoB,OApDtBC,GADAD,EAAAA,EAAAA,EAAAA,CAAAA,EAAaF,IAA2CE,IAElDjU,EAAkB4N,EAAahQ,GAA9B0C,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GACTiU,EAAmChF,GACrCyE,EAAOxE,mBAAoBlS,KAAK6W,UAAU9W,aAAAA,CACzCgD,EAAQC,IAEPH,EACF+Q,GAAevT,EAAO4W,GADnBjD,EAAAA,EAAAA,QAASlR,EAAAA,EAAAA,QAEViD,GAOFvH,EAAAA,EAAAA,OAAQ,WACJ,IAaFqZ,EAbEpV,EAOFlC,EAAKuX,iDAAiD9D,GANxD+C,EAAAA,EAAAA,cACAvV,EAAAA,EAAAA,YACAR,EAAAA,EAAAA,cACAG,EAAAA,EAAAA,QACAC,EAAAA,EAAAA,gBACAC,EAAAA,EAAAA,gBAEIgW,EAAsB3E,GACxBqE,EAAAA,CAAgBhU,EAAQC,GAAQiU,EAAAA,CAAAA,CAC9BnU,EAAQuR,IAAKvR,EAAQ0R,QAAS,CAAC1R,EAAQwR,KAAMxR,EAAQyR,QACvDkB,IAeJ,OANEoC,EAAoBrW,EAAAA,CAOpBF,aAJmBjD,GACjBqV,EAAAA,EAAAA,SAAW2D,GAAsBX,EAAOJ,uBAI1C9U,YAAaqW,EACbE,iBAAkB/W,EAClBgX,WAAY7W,EACZ8W,mBAAoB7W,EACpB8W,mBAAoB7W,EAAAA,IAvCtBC,EAAAA,EAAAA,aACAE,EAAAA,EAAAA,YACAuW,EAAAA,EAAAA,iBACAC,EAAAA,EAAAA,WACAC,EAAAA,EAAAA,mBACAC,EAAAA,EAAAA,mBAAAA,CAAAA,EAsC0BzD,GAAkB,CACzCsD,EAAkBC,EAAYC,EAAoBC,KAAAA,KAAAA,EAajC,OAdhBX,EAAgBtE,EAAAA,OAEfuE,EACHD,EAAAA,GADcE,EACdF,EAAAA,GAD0BG,EAC1BH,EAAAA,GAD+CI,EAC/CJ,EAAAA,GAOJ1R,EAAQ+O,GALJ/O,EAAQuJ,EACRoI,EAAWC,EAAYC,EAAqBC,EAC5C3X,KAAK6W,UAAU9W,aAAc2W,EAAOH,cACpCG,EAAOjH,eAAgBiH,EAAOhH,WAAAA,CAGtB3M,EAAQC,GAAQiU,EAAkCnU,EAC1D4S,IAAAA,CAAAA,EAEwB/M,EACxBrH,EAAcE,EAAaqE,EAAO9C,EAAQC,EAC1ChD,KAAK6W,UAAU9W,aAAckX,EAAkCnU,EAC/D4T,EAAOjH,eAAgBiH,EAAOtR,YAAasR,EAAO7N,iBAClD6N,EAAOH,gBAAAA,KAAAA,EAUX,OAdM4B,EAAgBlF,EAAAA,OAMtBe,EAAQtS,UACRJ,EAAaI,UACbF,EAAYE,UACZqW,EAAiBrW,UACjBsW,EAAWtW,UACXuW,EAAmBvW,UACnBwW,EAAmBxW,UAAAA,CAAAA,EAEZyW,GAAAA,GAAAA,GAAAA,EAuCTrB,EAAAA,UAAAA,6BAAAA,SACIzW,EAAqB6R,EACrBoE,GAFJ,wBAEIA,EAAAA,IASI,MAAkBjG,EAAahQ,GAA9B0C,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GACTiU,EAAmChF,GACrCC,EAAoBlS,KAAK6W,UAAU9W,aAAc,CAACgD,EAAQC,IACxDH,EAGF+Q,GAAevT,EAAO4W,GAFxBjD,EAAAA,EAAAA,QACAlR,EAAAA,EAAAA,QAGIiD,GAMFvH,EAAAA,EAAAA,OAAQ,WACJ,MAOF+B,EAAK6X,oCAAoCpE,GAN3C+C,EAAAA,EAAAA,cACAC,EAAAA,EAAAA,kBACAhW,EAAAA,EAAAA,cACAG,EAAAA,EAAAA,QACAC,EAAAA,EAAAA,gBACAC,EAAAA,EAAAA,gBAGIwB,EAAgCmR,EAAQjW,MAAvCoZ,EAAAA,EAAAA,GAAeC,EAAAA,EAAAA,GAEhBC,EAAsB3E,GACxBqE,EAAAA,CAAgBhU,EAAQC,GAAAA,CAASmU,EAAeC,GAAAA,CAAAA,CAC9CtU,EAAQuR,IAAKvR,EAAQ0R,QAAS,CAAC1R,EAAQwR,KAAMxR,EAAQyR,QACvDkB,IAEE4C,EAAyB3F,GAC3BsE,EAAAA,CAAoBjU,EAAQC,GAAAA,CAASmU,EAAeC,GAAAA,CAAAA,CAClDtU,EAAQuR,IAAKvR,EAAQ0R,QAAS,CAAC1R,EAAQwR,KAAMxR,EAAQyR,QACvDkB,IAGJ,MAAO,CACLnL,iBACI1L,EAHFP,GAAaqV,EAAAA,EAAAA,SAAW2D,GAAsBf,GAGP+B,GACzCrX,cAAAA,EACAG,QAAAA,EACAC,gBAAAA,EACAC,gBAAAA,EAAAA,IAlCFiJ,EAAAA,EAAAA,iBACAtJ,EAAAA,EAAAA,cACAG,EAAAA,EAAAA,QACAC,EAAAA,EAAAA,gBACAC,EAAAA,EAAAA,gBAkCF,OADA2S,EAAQtS,UAAAA,CAEN4I,iBAAAA,EACAtJ,cAAAA,EACAG,QAAAA,EACAC,gBAAAA,EACAC,gBAAAA,EACAyB,QAAAA,EACAmU,iCAAAA,EAAAA,EA8BEH,EAAAA,UAAAA,mBAAN,SACIzW,EACAqW,GAAAA,YAAAA,IAAAA,IAAAA,EAAAA,IAAAA,EAAAA,UAAAA,OAAAA,GAAAA,WAAAA,IAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,OAAAA,EAAAA,MAAAA,SAAAA,GAAAA,OAAAA,EAAAA,OAAAA,KAAAA,EAkBW,OAdbD,GAFAC,EAAAA,EAAAA,EAAAA,CAAAA,EAAaL,IAA4BK,IAGnCjU,EASFzC,KAAKsY,6BACDjY,EAAOqW,EAAOxE,mBAAoBwE,EAAOJ,uBAT/ChM,EAAAA,EAAAA,iBACAtJ,EAAAA,EAAAA,cACAG,EAAAA,EAAAA,QACAC,EAAAA,EAAAA,gBACAC,EAAAA,EAAAA,gBACAyB,EAAAA,EAAAA,QACAmU,EAAAA,EAAAA,iCAKIpU,EAAkByH,EAAiBvM,MAAlCgF,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GAAAA,CAAAA,EACIsH,EAAiBX,QAAAA,KAAAA,EAGd,OAHhBA,EAAO5D,EAAAA,OACbuE,EAAiB5I,UAAAA,CAAAA,EAEW+S,GAAkB,CACzCzT,EAAeG,EAASC,EAAiBC,KAAAA,KAAAA,EAkB9C,OAnBMkW,EAAgBxR,EAAAA,OAEfyR,EACHD,EAAAA,GADcE,EACdF,EAAAA,GAD0BG,EAC1BH,EAAAA,GAD+CI,EAC/CJ,EAAAA,GAOJ1R,EAAQ+O,GALJ/O,EAAQuJ,EACRoI,EAAWC,EAAYC,EAAqBC,EAC5C3X,KAAK6W,UAAU9W,aAAc2W,EAAOH,cACpCG,EAAOjH,eAAgBiH,EAAOhH,WAAAA,CAGtB3M,EAAQC,GAAQiU,EAAkCnU,EAC1D4S,IAEJ1U,EAAcU,UACdP,EAAQO,UACRN,EAAgBM,UAChBL,EAAgBK,UAAAA,CAAAA,EAAAA,CAERqB,OAAAA,EAAQC,MAAAA,EAAO2G,KAAAA,EAAMiO,SAAU/R,IAAAA,GAAAA,GAAAA,EA0BnCiR,EAAAA,UAAAA,wBAAN,SACIzW,EACAqW,GAAAA,YAAAA,IAAAA,IAAAA,EAAAA,IAAAA,EAAAA,UAAAA,OAAAA,GAAAA,WAAAA,IAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,KAAAA,OAAAA,EAAAA,MAAAA,SAAAA,GAAAA,OAAAA,EAAAA,OAAAA,KAAAA,EA0DoB,OAtDtBC,GAFAD,EAAAA,EAAAA,EAAAA,CAAAA,EAAaF,IAA2CE,IAGlDjU,EAAkB4N,EAAahQ,GAA9B0C,EAAAA,EAAAA,GAAQC,EAAAA,EAAAA,GACTiU,EAAmChF,GACrCyE,EAAOxE,mBAAoBlS,KAAK6W,UAAU9W,aAAAA,CACzCgD,EAAQC,IACPH,EACF+Q,GAAevT,EAAO4W,GADnBjD,EAAAA,EAAAA,QAASlR,EAAAA,EAAAA,QAEViD,GAQFvH,EAAAA,EAAAA,OAAQ,WACJ,MAQF+B,EAAKuX,iDAAiD9D,GAPxD+C,EAAAA,EAAAA,cACAvV,EAAAA,EAAAA,YACAR,EAAAA,EAAAA,cACAG,EAAAA,EAAAA,QACAC,EAAAA,EAAAA,gBACAC,EAAAA,EAAAA,gBACAE,EAAAA,EAAAA,aAII8V,EAAsB3E,GACxBqE,EAAAA,CAAgBhU,EAAQC,GAAQiU,EAAAA,CAAAA,CAC9BnU,EAAQuR,IAAKvR,EAAQ0R,QAAS,CAAC1R,EAAQwR,KAAMxR,EAAQyR,QACvDkB,IAGE8C,EAA+B7F,GACjCnR,EAAAA,CAAewB,EAAQC,GAAQiU,EAAAA,CAAAA,CAC7BnU,EAAQuR,IAAKvR,EAAQ0R,QAAS,CAAC1R,EAAQwR,KAAMxR,EAAQyR,QACvDkB,IAEEoC,EAAoBrW,EAK1B,MAAO,CACLF,aALmBjD,GACnBqV,EAAAA,EAAAA,SAAW2D,GAAsBX,EAAOJ,uBAKxC9U,YAAaqW,EACbE,iBAAkB/W,EAClBgX,WAAY7W,EACZ8W,mBAAoB7W,EACpB8W,mBAAoB7W,EACpBiJ,iBAREzK,EAA2B0Y,GAAAA,IAlC/BjX,EAAAA,EAAAA,aACAE,EAAAA,EAAAA,YACAuW,EAAAA,EAAAA,iBACAC,EAAAA,EAAAA,WACAC,EAAAA,EAAAA,mBACAC,EAAAA,EAAAA,mBACA5N,EAAAA,EAAAA,iBAAAA,CAAAA,EAwC0BmK,GAAkB,CACzCsD,EAAkBC,EAAYC,EAAoBC,KAAAA,KAAAA,EAajC,OAdhBX,EAAgBtE,EAAAA,OAEfuE,EACHD,EAAAA,GADcE,EACdF,EAAAA,GAD0BG,EAC1BH,EAAAA,GAD+CI,EAC/CJ,EAAAA,GAOJ1R,EAAQ+O,GALJ/O,EAAQuJ,EACRoI,EAAWC,EAAYC,EAAqBC,EAC5C3X,KAAK6W,UAAU9W,aAAc2W,EAAOH,cACpCG,EAAOjH,eAAgBiH,EAAOhH,WAAAA,CAGtB3M,EAAQC,GAAQiU,EAAkCnU,EAC1D4S,IAAAA,CAAAA,EAEwBrL,EACxB/I,EAAcE,EAAa8I,EAAkBzE,EAAO9C,EAAQC,EAC5DhD,KAAK6W,UAAU9W,aAAckX,EAAkCnU,EAC/D4T,EAAOjH,eAAgBiH,EAAOtR,YAAasR,EAAO7N,iBAClD6N,EAAOH,gBAAAA,KAAAA,EAWX,OAfM4B,EAAgBlF,EAAAA,OAMtBe,EAAQtS,UACRJ,EAAaI,UACbF,EAAYE,UACZqW,EAAiBrW,UACjBsW,EAAWtW,UACXuW,EAAmBvW,UACnBwW,EAAmBxW,UACnB4I,EAAiB5I,UAAAA,CAAAA,EAEVyW,GAAAA,GAAAA,GAAAA,EAGFrB,EAAAA,UAAAA,QAAP,WACE9W,KAAK6W,UAAUnV,SAAAA,EAAAA,CAAAA,CAjpBnB,GAwpBA,SAAe8W,GAAc9B,GAAAA,OAAAA,EAAAA,UAAAA,OAAAA,GAAAA,WAAAA,IAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,OAAAA,EAAAA,MAAAA,SAAAA,GAAAA,OAAAA,EAAAA,OAAAA,KAAAA,EAI3B,GAHM3W,EAAe2W,EAAO3W,aACtB8V,EAAaa,EAAOb,WACpBC,EAAaY,EAAOZ,WAChB,MAAN2C,EACF,MAAM,IAAI7H,MACN,kJAMa,OADb8H,EF/7BR,SACI1S,EAAgB8P,EAAoBD,GACtC,IAAM8C,EAAAA,CAAkCC,EAAK,MAAOC,IAAM,MAAOC,GAAM,OACjErI,EAAY,eAAezK,EAAAA,QAEjC,OAAmB,IAAf6P,EACKzF,EAAqB,SAASuI,EAAM7C,GAAAA,IAAiBrF,EAErDL,EAAqB,QAAQyF,EAAAA,IAAc8C,EAAM7C,GAAAA,IACpDrF,CAAAA,CEs7BMsI,CAAoBhZ,EAAc+V,EAAYD,GAAAA,CAAAA,GACjCmD,EAAAA,EAAAA,IAAsBtC,EAAOuC,UAAYP,IAAAA,KAAAA,EAElE,OAFMQ,EAAazW,EAAAA,OACb0W,EAAY,IAAItX,EAAUqX,EAAYnZ,GAAAA,CAAAA,EACrC,IAAI+W,GAAQqC,IAAAA,GAAAA,GAAAA,CAMrB,SAAeC,GAAW1C,GAAAA,OAAAA,EAAAA,UAAAA,OAAAA,GAAAA,WAAAA,IAAAA,EAAAA,EAAAA,EAAAA,EAAAA,EAAAA,OAAAA,EAAAA,MAAAA,SAAAA,GAAAA,OAAAA,EAAAA,OAAAA,KAAAA,EAGxB,GAFM3W,EAAe2W,EAAO3W,aACtB8V,EAAaa,EAAOb,WAChB,MAAN4C,EACF,MAAM,IAAI7H,MACN,kJAMa,OADb8H,EF99BR,SAAmC1S,EAAgB6P,GACjD,IAAMpF,EAAY,eAAezK,EAAAA,QAEjC,OAAmB,IAAf6P,EACK1F,EAAoB,SAAWM,EAE/BN,EAAoB,QAAQ0F,EAAAA,IAAgBpF,CAAAA,CEw9BzC4I,CAAmBtZ,EAAc8V,GAAAA,CAAAA,GACpBmD,EAAAA,EAAAA,IAAsBtC,EAAOuC,UAAYP,IAAAA,KAAAA,EAElE,OAFMQ,EAAazW,EAAAA,OACb6W,EAAS,IAAIpJ,EAAOgJ,EAAYnZ,GAAAA,CAAAA,EAC/B,IAAI+W,GAAQwC,IAAAA,GAAAA,GAAAA,CAerB,SAAsBC,GAAK7C,GAAAA,YAAAA,IAAAA,IAAAA,EAAAA,IAAAA,EAAAA,UAAAA,OAAAA,GAAAA,WAAAA,OAAAA,EAAAA,MAAAA,SAAAA,GAGzB,MAA4B,cAD5BA,EAn6BF,SAA6BA,GAM3B,GAH2B,OAF3BA,EAASA,GAAUf,IAERC,eACTc,EAAOd,aAAe,eAEpBG,GAAmByD,QAAQ9C,EAAOd,cAAgB,EACpD,MAAM,IAAIhF,MACN,wBAAwB8F,EAAOd,aAAAA,sBACXG,IAK1B,GAH2B,MAAvBW,EAAO3W,eACT2W,EAAO3W,aAAe,IAEpBiW,GAAaU,EAAOd,cAAc4D,QAAQ9C,EAAO3W,cAAgB,EACnE,MAAM,IAAI6Q,MACN,wBAAwB8F,EAAO3W,aAAAA,sBACXiW,GAAaU,EAAOd,cAAAA,qBACpBc,EAAOd,aAAAA,KAMjC,GAHyB,MAArBc,EAAOZ,aACTY,EAAOZ,WAAa,GAElBK,GAAiBO,EAAOd,cAAc4D,QAAQ9C,EAAOZ,YAAc,EACrE,MAAM,IAAIlF,MACN,sBAAsB8F,EAAOZ,WAAAA,sBACTK,GAAiBO,EAAOd,cAAAA,qBACxBc,EAAOd,aAAAA,KAMjC,GAHyB,MAArBc,EAAOb,aACTa,EAAOb,WAAa,GAElBO,GAAkBoD,QAAQ9C,EAAOb,YAAc,EACjD,MAAM,IAAIjF,MACN,sBAAsB8F,EAAOb,WAAAA,sBACTO,GAAAA,qBACAM,EAAOd,aAAAA,KAGjC,OAAOc,CAAAA,CA03BE+C,CAAoB/C,IAClBd,aAAAA,CAAAA,EACFwD,GAAW1C,IACe,gBAAxBA,EAAOd,aAAAA,CAAAA,EACT4C,GAAc9B,IAAAA,CAAAA,EAEd,Y","sources":["../node_modules/@tensorflow-models/body-pix/src/decode_part_map.ts","../node_modules/@tensorflow-models/body-pix/src/base_model.ts","../node_modules/@tensorflow-models/body-pix/src/mobilenet.ts","../node_modules/@tensorflow-models/body-pix/src/keypoints.ts","../node_modules/@tensorflow-models/body-pix/src/multi_person/util.ts","../node_modules/@tensorflow-models/body-pix/src/multi_person/decode_multiple_masks_cpu.ts","../node_modules/@tensorflow-models/body-pix/src/multi_person/decode_multiple_masks_webgl.ts","../node_modules/@tensorflow-models/body-pix/src/multi_person/decode_instance_masks.ts","../node_modules/@tensorflow-models/body-pix/src/multi_person/max_heap.ts","../node_modules/@tensorflow-models/body-pix/src/multi_person/build_part_with_score_queue.ts","../node_modules/@tensorflow-models/body-pix/src/multi_person/decode_pose.ts","../node_modules/@tensorflow-models/body-pix/src/multi_person/decode_multiple_poses.ts","../node_modules/@tensorflow-models/body-pix/src/resnet.ts","../node_modules/@tensorflow-models/body-pix/src/saved_models.ts","../node_modules/@tensorflow-models/body-pix/src/util.ts","../node_modules/@tensorflow-models/body-pix/src/body_pix_model.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\n\n/**\n * Takes the sigmoid of the part heatmap output and generates a 2d one-hot\n * tensor with ones where the part's score has the maximum value.\n *\n * @param partHeatmapScores\n */\nfunction toFlattenedOneHotPartMap(partHeatmapScores: tf.Tensor3D): tf.Tensor2D {\n  const numParts = partHeatmapScores.shape[2];\n  const partMapLocations = tf.argMax(partHeatmapScores, 2);\n\n  const partMapFlattened = tf.reshape(partMapLocations, [-1]);\n\n  return tf.oneHot(partMapFlattened, numParts) as tf.Tensor2D;\n}\n\nfunction clipByMask2d(image: tf.Tensor2D, mask: tf.Tensor2D): tf.Tensor2D {\n  return tf.mul(image, mask);\n}\n\n/**\n * Takes the sigmoid of the segmentation output, and generates a segmentation\n * mask with a 1 or 0 at each pixel where there is a person or not a person. The\n * segmentation threshold determines the threshold of a score for a pixel for it\n * to be considered part of a person.\n * @param segmentScores A 3d-tensor of the sigmoid of the segmentation output.\n * @param segmentationThreshold The minimum that segmentation values must have\n * to be considered part of the person.  Affects the generation of the\n * segmentation mask and the clipping of the colored part image.\n *\n * @returns A segmentation mask with a 1 or 0 at each pixel where there is a\n * person or not a person.\n */\nexport function toMaskTensor(\n    segmentScores: tf.Tensor2D, threshold: number): tf.Tensor2D {\n  return tf.tidy(\n      () =>\n          (tf.cast(tf.greater(\n              segmentScores, tf.scalar(threshold)), 'int32') as tf.Tensor2D));\n}\n\n/**\n * Takes the sigmoid of the person and part map output, and returns a 2d tensor\n * of an image with the corresponding value at each pixel corresponding to the\n * part with the highest value. These part ids are clipped by the segmentation\n * mask. Wherever the a pixel is clipped by the segmentation mask, its value\n * will set to -1, indicating that there is no part in that pixel.\n * @param segmentScores A 3d-tensor of the sigmoid of the segmentation output.\n * @param partHeatmapScores A 3d-tensor of the sigmoid of the part heatmap\n * output. The third dimension corresponds to the part.\n *\n * @returns A 2d tensor of an image with the corresponding value at each pixel\n * corresponding to the part with the highest value. These part ids are clipped\n * by the segmentation mask.  It will have values of -1 for pixels that are\n * outside of the body and do not have a corresponding part.\n */\nexport function decodePartSegmentation(\n    segmentationMask: tf.Tensor2D,\n    partHeatmapScores: tf.Tensor3D): tf.Tensor2D {\n  const [partMapHeight, partMapWidth, numParts] = partHeatmapScores.shape;\n  return tf.tidy(() => {\n    const flattenedMap = toFlattenedOneHotPartMap(partHeatmapScores);\n    const partNumbers = tf.expandDims(tf.range(0, numParts, 1, 'int32'), 1);\n\n    const partMapFlattened =\n        tf.cast(tf.matMul(flattenedMap, partNumbers as tf.Tensor2D), 'int32');\n\n    const partMap = tf.reshape(partMapFlattened, [partMapHeight, partMapWidth]);\n\n    const partMapShiftedUpForClipping = tf.add(partMap, tf.scalar(1, 'int32'));\n\n    return tf.sub(clipByMask2d(\n               partMapShiftedUpForClipping as tf.Tensor2D, segmentationMask)\n        , tf.scalar(1, 'int32'));\n  });\n}\n\nexport function decodeOnlyPartSegmentation(partHeatmapScores: tf.Tensor3D):\n    tf.Tensor2D {\n  const [partMapHeight, partMapWidth, numParts] = partHeatmapScores.shape;\n  return tf.tidy(() => {\n    const flattenedMap = toFlattenedOneHotPartMap(partHeatmapScores);\n    const partNumbers = tf.expandDims(tf.range(0, numParts, 1, 'int32'), 1);\n\n    const partMapFlattened =\n        tf.cast(tf.matMul(flattenedMap, partNumbers as tf.Tensor2D), 'int32');\n\n    return tf.reshape(partMapFlattened, [partMapHeight, partMapWidth]);\n  });\n}\n","\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfconv from '@tensorflow/tfjs-converter';\nimport * as tf from '@tensorflow/tfjs-core';\nimport {BodyPixOutputStride} from './types';\n\n/**\n * BodyPix supports using various convolution neural network models\n * (e.g. ResNet and MobileNetV1) as its underlying base model.\n * The following BaseModel interface defines a unified interface for\n * creating such BodyPix base models. Currently both MobileNet (in\n * ./mobilenet.ts) and ResNet (in ./resnet.ts) implements the BaseModel\n * interface. New base models that conform to the BaseModel interface can be\n * added to BodyPix.\n */\nexport abstract class BaseModel {\n  constructor(\n      protected readonly model: tfconv.GraphModel,\n      public readonly outputStride: BodyPixOutputStride) {\n    const inputShape =\n        this.model.inputs[0].shape as [number, number, number, number];\n    tf.util.assert(\n        (inputShape[1] === -1) && (inputShape[2] === -1),\n        () => `Input shape [${inputShape[1]}, ${inputShape[2]}] ` +\n            `must both be equal to or -1`);\n  }\n\n  abstract preprocessInput(input: tf.Tensor3D): tf.Tensor3D;\n\n  /**\n   * Predicts intermediate Tensor representations.\n   *\n   * @param input The input RGB image of the base model.\n   * A Tensor of shape: [`inputResolution`, `inputResolution`, 3].\n   *\n   * @return A dictionary of base model's intermediate predictions.\n   * The returned dictionary should contains the following elements:\n   * - heatmapScores: A Tensor3D that represents the keypoint heatmap scores.\n   * - offsets: A Tensor3D that represents the offsets.\n   * - displacementFwd: A Tensor3D that represents the forward displacement.\n   * - displacementBwd: A Tensor3D that represents the backward displacement.\n   * - segmentation: A Tensor3D that represents the segmentation of all\n   * people.\n   * - longOffsets: A Tensor3D that represents the long offsets used for\n   * instance grouping.\n   * - partHeatmaps: A Tensor3D that represents the body part segmentation.\n   */\n  predict(input: tf.Tensor3D): {\n    heatmapScores: tf.Tensor3D,\n    offsets: tf.Tensor3D,\n    displacementFwd: tf.Tensor3D,\n    displacementBwd: tf.Tensor3D,\n    segmentation: tf.Tensor3D,\n    partHeatmaps: tf.Tensor3D,\n    longOffsets: tf.Tensor3D,\n    partOffsets: tf.Tensor3D\n  } {\n    return tf.tidy(() => {\n      const asFloat = this.preprocessInput(tf.cast(input, 'float32'));\n      const asBatch = tf.expandDims(asFloat, 0);\n      const results = this.model.predict(asBatch) as tf.Tensor4D[];\n      const results3d: tf.Tensor3D[] = results.map(y => tf.squeeze(y, [0]));\n      const namedResults = this.nameOutputResults(results3d);\n\n      return {\n        heatmapScores: tf.sigmoid(namedResults.heatmap),\n        offsets: namedResults.offsets,\n        displacementFwd: namedResults.displacementFwd,\n        displacementBwd: namedResults.displacementBwd,\n        segmentation: namedResults.segmentation,\n        partHeatmaps: namedResults.partHeatmaps,\n        longOffsets: namedResults.longOffsets,\n        partOffsets: namedResults.partOffsets\n      };\n    });\n  }\n\n  // Because MobileNet and ResNet predict() methods output a different order for\n  // these values, we have a method that needs to be implemented to order them.\n  abstract nameOutputResults(results: tf.Tensor3D[]): {\n    heatmap: tf.Tensor3D,\n    offsets: tf.Tensor3D,\n    displacementFwd: tf.Tensor3D,\n    displacementBwd: tf.Tensor3D,\n    segmentation: tf.Tensor3D,\n    partHeatmaps: tf.Tensor3D,\n    longOffsets: tf.Tensor3D,\n    partOffsets: tf.Tensor3D\n  };\n\n  /**\n   * Releases the CPU and GPU memory allocated by the model.\n   */\n  dispose() {\n    this.model.dispose();\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\n\nimport {BaseModel} from './base_model';\n\nexport class MobileNet extends BaseModel {\n  preprocessInput(input: tf.Tensor3D): tf.Tensor3D {\n    // Normalize the pixels [0, 255] to be between [-1, 1].\n    return tf.tidy(() => tf.sub(tf.div(input, 127.5), 1.0));\n  }\n\n  nameOutputResults(results: tf.Tensor3D[]) {\n    const [\n      offsets,\n      segmentation,\n      partHeatmaps,\n      longOffsets,\n      heatmap,\n      displacementFwd,\n      displacementBwd,\n      partOffsets,\n  ] = results;\n    return {\n      offsets,\n      segmentation,\n      partHeatmaps,\n      longOffsets,\n      heatmap,\n      displacementFwd,\n      displacementBwd,\n      partOffsets\n    };\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nexport type Tuple<T> = [T, T];\nexport type StringTuple = Tuple<string>;\nexport type NumberTuple = Tuple<number>;\n\nexport const PART_NAMES = [\n  'nose', 'leftEye', 'rightEye', 'leftEar', 'rightEar', 'leftShoulder',\n  'rightShoulder', 'leftElbow', 'rightElbow', 'leftWrist', 'rightWrist',\n  'leftHip', 'rightHip', 'leftKnee', 'rightKnee', 'leftAnkle', 'rightAnkle'\n];\n\nexport const NUM_KEYPOINTS = PART_NAMES.length;\n\nexport interface NumberDict {\n  [jointName: string]: number;\n}\n\nexport const PART_IDS =\n    PART_NAMES.reduce((result: NumberDict, jointName, i): NumberDict => {\n      result[jointName] = i;\n      return result;\n    }, {});\n\nconst CONNECTED_PART_NAMES: StringTuple[] = [\n  ['leftHip', 'leftShoulder'], ['leftElbow', 'leftShoulder'],\n  ['leftElbow', 'leftWrist'], ['leftHip', 'leftKnee'],\n  ['leftKnee', 'leftAnkle'], ['rightHip', 'rightShoulder'],\n  ['rightElbow', 'rightShoulder'], ['rightElbow', 'rightWrist'],\n  ['rightHip', 'rightKnee'], ['rightKnee', 'rightAnkle'],\n  ['leftShoulder', 'rightShoulder'], ['leftHip', 'rightHip']\n];\n\n/*\n * Define the skeleton. This defines the parent->child relationships of our\n * tree. Arbitrarily this defines the nose as the root of the tree, however\n * since we will infer the displacement for both parent->child and\n * child->parent, we can define the tree root as any node.\n */\nexport const POSE_CHAIN: StringTuple[] = [\n  ['nose', 'leftEye'], ['leftEye', 'leftEar'], ['nose', 'rightEye'],\n  ['rightEye', 'rightEar'], ['nose', 'leftShoulder'],\n  ['leftShoulder', 'leftElbow'], ['leftElbow', 'leftWrist'],\n  ['leftShoulder', 'leftHip'], ['leftHip', 'leftKnee'],\n  ['leftKnee', 'leftAnkle'], ['nose', 'rightShoulder'],\n  ['rightShoulder', 'rightElbow'], ['rightElbow', 'rightWrist'],\n  ['rightShoulder', 'rightHip'], ['rightHip', 'rightKnee'],\n  ['rightKnee', 'rightAnkle']\n];\n\nexport const CONNECTED_PART_INDICES = CONNECTED_PART_NAMES.map(\n    ([jointNameA, jointNameB]) =>\n        ([PART_IDS[jointNameA], PART_IDS[jointNameB]]));\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NUM_KEYPOINTS} from '../keypoints';\nimport {Padding, Part, TensorBuffer3D, Vector2D} from '../types';\n\nexport function getScale(\n    [height, width]: [number, number],\n    [inputResolutionY, inputResolutionX]: [number, number],\n    padding: Padding): [number, number] {\n  const {top: padT, bottom: padB, left: padL, right: padR} = padding;\n  const scaleY = inputResolutionY / (padT + padB + height);\n  const scaleX = inputResolutionX / (padL + padR + width);\n  return [scaleX, scaleY];\n}\n\nexport function getOffsetPoint(\n    y: number, x: number, keypoint: number, offsets: TensorBuffer3D): Vector2D {\n  return {\n    y: offsets.get(y, x, keypoint),\n    x: offsets.get(y, x, keypoint + NUM_KEYPOINTS)\n  };\n}\n\nexport function getImageCoords(\n    part: Part, outputStride: number, offsets: TensorBuffer3D): Vector2D {\n  const {heatmapY, heatmapX, id: keypoint} = part;\n  const {y, x} = getOffsetPoint(heatmapY, heatmapX, keypoint, offsets);\n  return {\n    x: part.heatmapX * outputStride + x,\n    y: part.heatmapY * outputStride + y\n  };\n}\n\nexport function fillArray<T>(element: T, size: number): T[] {\n  const result: T[] = new Array(size);\n\n  for (let i = 0; i < size; i++) {\n    result[i] = element;\n  }\n\n  return result;\n}\n\nexport function clamp(a: number, min: number, max: number): number {\n  if (a < min) {\n    return min;\n  }\n  if (a > max) {\n    return max;\n  }\n  return a;\n}\n\nexport function squaredDistance(\n    y1: number, x1: number, y2: number, x2: number): number {\n  const dy = y2 - y1;\n  const dx = x2 - x1;\n  return dy * dy + dx * dx;\n}\n\nexport function addVectors(a: Vector2D, b: Vector2D): Vector2D {\n  return {x: a.x + b.x, y: a.y + b.y};\n}\n\nexport function clampVector(a: Vector2D, min: number, max: number): Vector2D {\n  return {y: clamp(a.y, min, max), x: clamp(a.x, min, max)};\n}\n","/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NUM_KEYPOINTS} from '../keypoints';\nimport {Padding, Pose} from '../types';\n\nimport {getScale} from './util';\n\ninterface Pair {\n  x: number;\n  y: number;\n}\n\nfunction computeDistance(embedding: Pair[], pose: Pose, minPartScore = 0.3) {\n  let distance = 0.0;\n  let numKpt = 0;\n  for (let p = 0; p < embedding.length; p++) {\n    if (pose.keypoints[p].score > minPartScore) {\n      numKpt += 1;\n      distance += (embedding[p].x - pose.keypoints[p].position.x) ** 2 +\n          (embedding[p].y - pose.keypoints[p].position.y) ** 2;\n    }\n  }\n  if (numKpt === 0) {\n    distance = Infinity;\n  } else {\n    distance = distance / numKpt;\n  }\n  return distance;\n}\n\nfunction convertToPositionInOuput(\n    position: Pair, [padT, padL]: [number, number],\n    [scaleX, scaleY]: [number, number], stride: number): Pair {\n  const y = Math.round(((padT + position.y + 1.0) * scaleY - 1.0) / stride);\n  const x = Math.round(((padL + position.x + 1.0) * scaleX - 1.0) / stride);\n  return {x, y};\n}\n\nfunction getEmbedding(\n    location: Pair, keypointIndex: number,\n    convertToPosition: (pair: Pair) => Pair, outputResolutionX: number,\n    longOffsets: Float32Array, refineSteps: number,\n    [height, width]: [number, number]): Pair {\n  const newLocation = convertToPosition(location);\n\n  const nn = newLocation.y * outputResolutionX + newLocation.x;\n  let dy = longOffsets[NUM_KEYPOINTS * (2 * nn) + keypointIndex];\n  let dx = longOffsets[NUM_KEYPOINTS * (2 * nn + 1) + keypointIndex];\n  let y = location.y + dy;\n  let x = location.x + dx;\n  for (let t = 0; t < refineSteps; t++) {\n    y = Math.min(y, height - 1);\n    x = Math.min(x, width - 1);\n    const newPos = convertToPosition({x, y});\n    const nn = newPos.y * outputResolutionX + newPos.x;\n    dy = longOffsets[NUM_KEYPOINTS * (2 * nn) + keypointIndex];\n    dx = longOffsets[NUM_KEYPOINTS * (2 * nn + 1) + keypointIndex];\n    y = y + dy;\n    x = x + dx;\n  }\n\n  return {x, y};\n}\n\nfunction matchEmbeddingToInstance(\n    location: Pair, longOffsets: Float32Array, poses: Pose[],\n    numKptForMatching: number, [padT, padL]: [number, number],\n    [scaleX, scaleY]: [number, number], outputResolutionX: number,\n    [height, width]: [number, number], stride: number,\n    refineSteps: number): number {\n  const embed: Pair[] = [];\n  const convertToPosition = (pair: Pair) =>\n      convertToPositionInOuput(pair, [padT, padL], [scaleX, scaleY], stride);\n\n  for (let keypointsIndex = 0; keypointsIndex < numKptForMatching;\n       keypointsIndex++) {\n    const embedding = getEmbedding(\n        location, keypointsIndex, convertToPosition, outputResolutionX,\n        longOffsets, refineSteps, [height, width]);\n\n    embed.push(embedding);\n  }\n\n  let kMin = -1;\n  let kMinDist = Infinity;\n  for (let k = 0; k < poses.length; k++) {\n    const dist = computeDistance(embed, poses[k]);\n    if (dist < kMinDist) {\n      kMin = k;\n      kMinDist = dist;\n    }\n  }\n  return kMin;\n}\n\nfunction getOutputResolution(\n    [inputResolutionY, inputResolutionX]: [number, number],\n    stride: number): [number, number] {\n  const outputResolutionX = Math.round((inputResolutionX - 1.0) / stride + 1.0);\n  const outputResolutionY = Math.round((inputResolutionY - 1.0) / stride + 1.0);\n  return [outputResolutionX, outputResolutionY];\n}\n\nexport function decodeMultipleMasksCPU(\n    segmentation: Uint8Array, longOffsets: Float32Array,\n    posesAboveScore: Pose[], height: number, width: number, stride: number,\n    [inHeight, inWidth]: [number, number], padding: Padding,\n    refineSteps: number, numKptForMatching = 5): Uint8Array[] {\n  const dataArrays =\n      posesAboveScore.map(x => new Uint8Array(height * width).fill(0));\n\n  const {top: padT, left: padL} = padding;\n\n  const [scaleX, scaleY] =\n      getScale([height, width], [inHeight, inWidth], padding);\n  const [outputResolutionX, ] =\n    getOutputResolution([inHeight, inWidth], stride);\n  for (let i = 0; i < height; i += 1) {\n    for (let j = 0; j < width; j += 1) {\n      const n = i * width + j;\n      const prob = segmentation[n];\n      if (prob === 1) {\n        const kMin = matchEmbeddingToInstance(\n            {x: j, y: i}, longOffsets, posesAboveScore, numKptForMatching,\n            [padT, padL], [scaleX, scaleY], outputResolutionX, [height, width],\n            stride, refineSteps);\n        if (kMin >= 0) {\n          dataArrays[kMin][n] = 1;\n        }\n      }\n    }\n  }\n\n  return dataArrays;\n}\n\nexport function decodeMultiplePartMasksCPU(\n    segmentation: Uint8Array, longOffsets: Float32Array,\n    partSegmentaion: Uint8Array, posesAboveScore: Pose[], height: number,\n    width: number, stride: number, [inHeight, inWidth]: [number, number],\n    padding: Padding, refineSteps: number,\n    numKptForMatching = 5): Int32Array[] {\n  const dataArrays =\n      posesAboveScore.map(x => new Int32Array(height * width).fill(-1));\n\n  const {top: padT, left: padL} = padding;\n\n  const [scaleX, scaleY] =\n      getScale([height, width], [inHeight, inWidth], padding);\n  const [outputResolutionX, ] =\n    getOutputResolution([inHeight, inWidth], stride);\n\n  for (let i = 0; i < height; i += 1) {\n    for (let j = 0; j < width; j += 1) {\n      const n = i * width + j;\n      const prob = segmentation[n];\n      if (prob === 1) {\n        const kMin = matchEmbeddingToInstance(\n            {x: j, y: i}, longOffsets, posesAboveScore, numKptForMatching,\n            [padT, padL], [scaleX, scaleY], outputResolutionX, [height, width],\n            stride, refineSteps);\n        if (kMin >= 0) {\n          dataArrays[kMin][n] = partSegmentaion[n];\n        }\n      }\n    }\n  }\n\n  return dataArrays;\n}\n","/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport * as tf_webgl from '@tensorflow/tfjs-backend-webgl';\n\nimport {NUM_KEYPOINTS} from '../keypoints';\nimport {Padding, Pose} from '../types';\nimport {getScale} from './util';\n\nexport function decodeMultipleMasksWebGl(\n    segmentation: tf.Tensor2D, longOffsets: tf.Tensor3D,\n    posesAboveScore: Pose[], height: number, width: number, stride: number,\n    [inHeight, inWidth]: [number, number], padding: Padding,\n    refineSteps: number, minKptScore: number,\n    maxNumPeople: number): tf.TensorInfo {\n  // The height/width of the image/canvas itself.\n  const [origHeight, origWidth] = segmentation.shape;\n  // The height/width of the output of the model.\n  const [outHeight, outWidth] = longOffsets.shape.slice(0, 2);\n\n  const shapedLongOffsets: tf.Tensor4D =\n      tf.reshape(longOffsets, [outHeight, outWidth, 2, NUM_KEYPOINTS]);\n\n  // Make pose tensor of shape [MAX_NUM_PEOPLE, NUM_KEYPOINTS, 3] where\n  // the last 3 coordinates correspond to the score, h and w coordinate of that\n  // keypoint.\n  const poseVals = new Float32Array(maxNumPeople * NUM_KEYPOINTS * 3).fill(0.0);\n  for (let i = 0; i < posesAboveScore.length; i++) {\n    const poseOffset = i * NUM_KEYPOINTS * 3;\n    const pose = posesAboveScore[i];\n    for (let kp = 0; kp < NUM_KEYPOINTS; kp++) {\n      const keypoint = pose.keypoints[kp];\n      const offset = poseOffset + kp * 3;\n      poseVals[offset] = keypoint.score;\n      poseVals[offset + 1] = keypoint.position.y;\n      poseVals[offset + 2] = keypoint.position.x;\n    }\n  }\n\n  const [scaleX, scaleY] =\n      getScale([height, width], [inHeight, inWidth], padding);\n\n  const posesTensor = tf.tensor(poseVals, [maxNumPeople, NUM_KEYPOINTS, 3]);\n\n  const {top: padT, left: padL} = padding;\n\n  const program: tf_webgl.GPGPUProgram = {\n    variableNames: ['segmentation', 'longOffsets', 'poses'],\n    outputShape: [origHeight, origWidth],\n    userCode: `\n    int convertToPositionInOutput(int pos, int pad, float scale, int stride) {\n      return round(((float(pos + pad) + 1.0) * scale - 1.0) / float(stride));\n    }\n\n    float convertToPositionInOutputFloat(\n        int pos, int pad, float scale, int stride) {\n      return ((float(pos + pad) + 1.0) * scale - 1.0) / float(stride);\n    }\n\n    float dist(float x1, float y1, float x2, float y2) {\n      return pow(x1 - x2, 2.0) + pow(y1 - y2, 2.0);\n    }\n\n    float sampleLongOffsets(float h, float w, int d, int k) {\n      float fh = fract(h);\n      float fw = fract(w);\n      int clH = int(ceil(h));\n      int clW = int(ceil(w));\n      int flH = int(floor(h));\n      int flW = int(floor(w));\n      float o11 = getLongOffsets(flH, flW, d, k);\n      float o12 = getLongOffsets(flH, clW, d, k);\n      float o21 = getLongOffsets(clH, flW, d, k);\n      float o22 = getLongOffsets(clH, clW, d, k);\n      float o1 = mix(o11, o12, fw);\n      float o2 = mix(o21, o22, fw);\n      return mix(o1, o2, fh);\n    }\n\n    int findNearestPose(int h, int w) {\n      float prob = getSegmentation(h, w);\n      if (prob < 1.0) {\n        return -1;\n      }\n\n      // Done(Tyler): convert from output space h/w to strided space.\n      float stridedH = convertToPositionInOutputFloat(\n        h, ${padT}, ${scaleY}, ${stride});\n      float stridedW = convertToPositionInOutputFloat(\n        w, ${padL}, ${scaleX}, ${stride});\n\n      float minDist = 1000000.0;\n      int iMin = -1;\n      for (int i = 0; i < ${maxNumPeople}; i++) {\n        float curDistSum = 0.0;\n        int numKpt = 0;\n        for (int k = 0; k < ${NUM_KEYPOINTS}; k++) {\n          float dy = sampleLongOffsets(stridedH, stridedW, 0, k);\n          float dx = sampleLongOffsets(stridedH, stridedW, 1, k);\n\n          float y = float(h) + dy;\n          float x = float(w) + dx;\n\n          for (int s = 0; s < ${refineSteps}; s++) {\n            int yRounded = round(min(y, float(${height - 1.0})));\n            int xRounded = round(min(x, float(${width - 1.0})));\n\n            float yStrided = convertToPositionInOutputFloat(\n              yRounded, ${padT}, ${scaleY}, ${stride});\n            float xStrided = convertToPositionInOutputFloat(\n              xRounded, ${padL}, ${scaleX}, ${stride});\n\n            float dy = sampleLongOffsets(yStrided, xStrided, 0, k);\n            float dx = sampleLongOffsets(yStrided, xStrided, 1, k);\n\n            y = y + dy;\n            x = x + dx;\n          }\n\n          float poseScore = getPoses(i, k, 0);\n          float poseY = getPoses(i, k, 1);\n          float poseX = getPoses(i, k, 2);\n          if (poseScore > ${minKptScore}) {\n            numKpt = numKpt + 1;\n            curDistSum = curDistSum + dist(x, y, poseX, poseY);\n          }\n        }\n        if (numKpt > 0 && curDistSum / float(numKpt) < minDist) {\n          minDist = curDistSum / float(numKpt);\n          iMin = i;\n        }\n      }\n      return iMin;\n    }\n\n    void main() {\n        ivec2 coords = getOutputCoords();\n        int nearestPose = findNearestPose(coords[0], coords[1]);\n        setOutput(float(nearestPose));\n      }\n  `\n  };\n  const webglBackend = tf.backend() as tf_webgl.MathBackendWebGL;\n  return webglBackend.compileAndRun(\n      program, [segmentation, shapedLongOffsets, posesTensor]);\n}\n","/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport {getBackend} from '@tensorflow/tfjs-core';\n\nimport {Padding, PartSegmentation, PersonSegmentation, Pose} from '../types';\n\nimport {decodeMultipleMasksCPU, decodeMultiplePartMasksCPU} from './decode_multiple_masks_cpu';\nimport {decodeMultipleMasksWebGl} from './decode_multiple_masks_webgl';\n\nexport function toPersonKSegmentation(\n    segmentation: tf.Tensor2D, k: number): tf.Tensor2D {\n  return tf.tidy(\n      () => (tf.cast(tf.equal(\n          segmentation, tf.scalar(k)), 'int32') as tf.Tensor2D));\n}\n\nexport function toPersonKPartSegmentation(\n    segmentation: tf.Tensor2D, bodyParts: tf.Tensor2D, k: number): tf.Tensor2D {\n  return tf.tidy(\n      () => tf.sub(tf.mul(tf.cast(tf.equal(\n          segmentation, tf.scalar(k)), 'int32'), tf.add(bodyParts, 1)), 1));\n}\n\nfunction isWebGlBackend() {\n  return getBackend() === 'webgl';\n}\n\nexport async function decodePersonInstanceMasks(\n    segmentation: tf.Tensor2D, longOffsets: tf.Tensor3D, poses: Pose[],\n    height: number, width: number, stride: number,\n    [inHeight, inWidth]: [number, number], padding: Padding, minPoseScore = 0.2,\n    refineSteps = 8, minKeypointScore = 0.3,\n    maxNumPeople = 10): Promise<PersonSegmentation[]> {\n  // Filter out poses with smaller score.\n  const posesAboveScore = poses.filter(pose => pose.score >= minPoseScore);\n\n  let personSegmentationsData: Uint8Array[];\n\n  if (isWebGlBackend()) {\n    const personSegmentations = tf.tidy(() => {\n      const masksTensorInfo = decodeMultipleMasksWebGl(\n          segmentation, longOffsets, posesAboveScore, height, width, stride,\n          [inHeight, inWidth], padding, refineSteps, minKeypointScore,\n          maxNumPeople);\n      const masksTensor = tf.engine().makeTensorFromDataId(\n          masksTensorInfo.dataId, masksTensorInfo.shape,\n          masksTensorInfo.dtype) as tf.Tensor2D;\n\n      return posesAboveScore.map(\n          (_, k) => toPersonKSegmentation(masksTensor, k));\n    });\n\n    personSegmentationsData =\n        (await Promise.all(personSegmentations.map(mask => mask.data())) as\n         Uint8Array[]);\n\n    personSegmentations.forEach(x => x.dispose());\n  } else {\n    const segmentationsData = await segmentation.data() as Uint8Array;\n    const longOffsetsData = await longOffsets.data() as Float32Array;\n\n    personSegmentationsData = decodeMultipleMasksCPU(\n        segmentationsData, longOffsetsData, posesAboveScore, height, width,\n        stride, [inHeight, inWidth], padding, refineSteps);\n  }\n\n  return personSegmentationsData.map(\n      (data, i) => ({data, pose: posesAboveScore[i], width, height}));\n}\n\nexport async function decodePersonInstancePartMasks(\n    segmentation: tf.Tensor2D, longOffsets: tf.Tensor3D,\n    partSegmentation: tf.Tensor2D, poses: Pose[], height: number, width: number,\n    stride: number, [inHeight, inWidth]: [number, number], padding: Padding,\n    minPoseScore = 0.2, refineSteps = 8, minKeypointScore = 0.3,\n    maxNumPeople = 10): Promise<PartSegmentation[]> {\n  const posesAboveScore = poses.filter(pose => pose.score >= minPoseScore);\n\n  let partSegmentationsByPersonData: Int32Array[];\n\n  if (isWebGlBackend()) {\n    const partSegmentations = tf.tidy(() => {\n      const masksTensorInfo = decodeMultipleMasksWebGl(\n          segmentation, longOffsets, posesAboveScore, height, width, stride,\n          [inHeight, inWidth], padding, refineSteps, minKeypointScore,\n          maxNumPeople);\n      const masksTensor = tf.engine().makeTensorFromDataId(\n        masksTensorInfo.dataId, masksTensorInfo.shape,\n        masksTensorInfo.dtype) as tf.Tensor2D;\n\n      return posesAboveScore.map(\n          (_, k) =>\n              toPersonKPartSegmentation(masksTensor, partSegmentation, k));\n    });\n\n    partSegmentationsByPersonData =\n        (await Promise.all(partSegmentations.map(x => x.data()))) as\n        Int32Array[];\n\n    partSegmentations.forEach(x => x.dispose());\n  } else {\n    const segmentationsData = await segmentation.data() as Uint8Array;\n    const longOffsetsData = await longOffsets.data() as Float32Array;\n    const partSegmentaionData = await partSegmentation.data() as Uint8Array;\n\n    partSegmentationsByPersonData = decodeMultiplePartMasksCPU(\n        segmentationsData, longOffsetsData, partSegmentaionData,\n        posesAboveScore, height, width, stride, [inHeight, inWidth], padding,\n        refineSteps);\n  }\n\n  return partSegmentationsByPersonData.map(\n      (data, k) => ({pose: posesAboveScore[k], data, height, width}));\n}\n","/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n// algorithm based on Coursera Lecture from Algorithms, Part 1:\n// https://www.coursera.org/learn/algorithms-part1/lecture/ZjoSM/heapsort\n\nfunction half(k: number) {\n  return Math.floor(k / 2);\n}\n\nexport class MaxHeap<T> {\n  private priorityQueue: T[];\n  private numberOfElements: number;\n  private getElementValue: (element: T) => number;\n\n  constructor(maxSize: number, getElementValue: (element: T) => number) {\n    this.priorityQueue = new Array(maxSize);\n    this.numberOfElements = -1;\n    this.getElementValue = getElementValue;\n  }\n\n  public enqueue(x: T): void {\n    this.priorityQueue[++this.numberOfElements] = x;\n    this.swim(this.numberOfElements);\n  }\n\n  public dequeue(): T {\n    const max = this.priorityQueue[0];\n    this.exchange(0, this.numberOfElements--);\n    this.sink(0);\n    this.priorityQueue[this.numberOfElements + 1] = null;\n    return max;\n  }\n\n  public empty(): boolean {\n    return this.numberOfElements === -1;\n  }\n\n  public size(): number {\n    return this.numberOfElements + 1;\n  }\n\n  public all(): T[] {\n    return this.priorityQueue.slice(0, this.numberOfElements + 1);\n  }\n\n  public max(): T {\n    return this.priorityQueue[0];\n  }\n\n  private swim(k: number): void {\n    while (k > 0 && this.less(half(k), k)) {\n      this.exchange(k, half(k));\n      k = half(k);\n    }\n  }\n\n  private sink(k: number): void {\n    while (2 * k <= this.numberOfElements) {\n      let j = 2 * k;\n      if (j < this.numberOfElements && this.less(j, j + 1)) {\n        j++;\n      }\n      if (!this.less(k, j)) {\n        break;\n      }\n      this.exchange(k, j);\n      k = j;\n    }\n  }\n\n  private getValueAt(i: number): number {\n    return this.getElementValue(this.priorityQueue[i]);\n  }\n\n  private less(i: number, j: number): boolean {\n    return this.getValueAt(i) < this.getValueAt(j);\n  }\n\n  private exchange(i: number, j: number): void {\n    const t = this.priorityQueue[i];\n    this.priorityQueue[i] = this.priorityQueue[j];\n    this.priorityQueue[j] = t;\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {PartWithScore, TensorBuffer3D} from '../types';\n\nimport {MaxHeap} from './max_heap';\n\nfunction scoreIsMaximumInLocalWindow(\n    keypointId: number, score: number, heatmapY: number, heatmapX: number,\n    localMaximumRadius: number, scores: TensorBuffer3D): boolean {\n  const [height, width] = scores.shape;\n\n  let localMaximum = true;\n  const yStart = Math.max(heatmapY - localMaximumRadius, 0);\n  const yEnd = Math.min(heatmapY + localMaximumRadius + 1, height);\n  for (let yCurrent = yStart; yCurrent < yEnd; ++yCurrent) {\n    const xStart = Math.max(heatmapX - localMaximumRadius, 0);\n    const xEnd = Math.min(heatmapX + localMaximumRadius + 1, width);\n    for (let xCurrent = xStart; xCurrent < xEnd; ++xCurrent) {\n      if (scores.get(yCurrent, xCurrent, keypointId) > score) {\n        localMaximum = false;\n        break;\n      }\n    }\n    if (!localMaximum) {\n      break;\n    }\n  }\n\n  return localMaximum;\n}\n\n/**\n * Builds a priority queue with part candidate positions for a specific image in\n * the batch. For this we find all local maxima in the score maps with score\n * values above a threshold. We create a single priority queue across all parts.\n */\nexport function buildPartWithScoreQueue(\n    scoreThreshold: number, localMaximumRadius: number,\n    scores: TensorBuffer3D): MaxHeap<PartWithScore> {\n  const [height, width, numKeypoints] = scores.shape;\n\n  const queue = new MaxHeap<PartWithScore>(\n      height * width * numKeypoints, ({score}) => score);\n\n  for (let heatmapY = 0; heatmapY < height; ++heatmapY) {\n    for (let heatmapX = 0; heatmapX < width; ++heatmapX) {\n      for (let keypointId = 0; keypointId < numKeypoints; ++keypointId) {\n        const score = scores.get(heatmapY, heatmapX, keypointId);\n\n        // Only consider parts with score greater or equal to threshold as\n        // root candidates.\n        if (score < scoreThreshold) {\n          continue;\n        }\n\n        // Only consider keypoints whose score is maximum in a local window.\n        if (scoreIsMaximumInLocalWindow(\n                keypointId, score, heatmapY, heatmapX, localMaximumRadius,\n                scores)) {\n          queue.enqueue({score, part: {heatmapY, heatmapX, id: keypointId}});\n        }\n      }\n    }\n  }\n\n  return queue;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NumberTuple, PART_IDS, PART_NAMES, POSE_CHAIN} from '../keypoints';\nimport {Keypoint, PartWithScore, TensorBuffer3D, Vector2D} from '../types';\n\nimport {clamp, getOffsetPoint} from './util';\nimport {addVectors, getImageCoords} from './util';\n\nconst parentChildrenTuples: NumberTuple[] = POSE_CHAIN.map(\n    ([parentJoinName, childJoinName]): NumberTuple =>\n        ([PART_IDS[parentJoinName], PART_IDS[childJoinName]]));\n\nconst parentToChildEdges: number[] =\n    parentChildrenTuples.map(([, childJointId]) => childJointId);\n\nconst childToParentEdges: number[] =\n    parentChildrenTuples.map(([\n                               parentJointId,\n                             ]) => parentJointId);\n\nfunction getDisplacement(\n    edgeId: number, point: Vector2D, displacements: TensorBuffer3D): Vector2D {\n  const numEdges = displacements.shape[2] / 2;\n  return {\n    y: displacements.get(point.y, point.x, edgeId),\n    x: displacements.get(point.y, point.x, numEdges + edgeId)\n  };\n}\n\nfunction getStridedIndexNearPoint(\n    point: Vector2D, outputStride: number, height: number,\n    width: number): Vector2D {\n  return {\n    y: clamp(Math.round(point.y / outputStride), 0, height - 1),\n    x: clamp(Math.round(point.x / outputStride), 0, width - 1)\n  };\n}\n\n/**\n * We get a new keypoint along the `edgeId` for the pose instance, assuming\n * that the position of the `idSource` part is already known. For this, we\n * follow the displacement vector from the source to target part (stored in\n * the `i`-t channel of the displacement tensor). The displaced keypoint\n * vector is refined using the offset vector by `offsetRefineStep` times.\n */\nfunction traverseToTargetKeypoint(\n    edgeId: number, sourceKeypoint: Keypoint, targetKeypointId: number,\n    scoresBuffer: TensorBuffer3D, offsets: TensorBuffer3D, outputStride: number,\n    displacements: TensorBuffer3D, offsetRefineStep = 2): Keypoint {\n  const [height, width] = scoresBuffer.shape;\n\n  // Nearest neighbor interpolation for the source->target displacements.\n  const sourceKeypointIndices = getStridedIndexNearPoint(\n      sourceKeypoint.position, outputStride, height, width);\n\n  const displacement =\n      getDisplacement(edgeId, sourceKeypointIndices, displacements);\n\n  const displacedPoint = addVectors(sourceKeypoint.position, displacement);\n  let targetKeypoint = displacedPoint;\n  for (let i = 0; i < offsetRefineStep; i++) {\n    const targetKeypointIndices =\n        getStridedIndexNearPoint(targetKeypoint, outputStride, height, width);\n\n    const offsetPoint = getOffsetPoint(\n        targetKeypointIndices.y, targetKeypointIndices.x, targetKeypointId,\n        offsets);\n\n    targetKeypoint = addVectors(\n        {\n          x: targetKeypointIndices.x * outputStride,\n          y: targetKeypointIndices.y * outputStride\n        },\n        {x: offsetPoint.x, y: offsetPoint.y});\n  }\n  const targetKeyPointIndices =\n      getStridedIndexNearPoint(targetKeypoint, outputStride, height, width);\n  const score = scoresBuffer.get(\n      targetKeyPointIndices.y, targetKeyPointIndices.x, targetKeypointId);\n\n  return {position: targetKeypoint, part: PART_NAMES[targetKeypointId], score};\n}\n\n/**\n * Follows the displacement fields to decode the full pose of the object\n * instance given the position of a part that acts as root.\n *\n * @return An array of decoded keypoints and their scores for a single pose\n */\nexport function decodePose(\n    root: PartWithScore, scores: TensorBuffer3D, offsets: TensorBuffer3D,\n    outputStride: number, displacementsFwd: TensorBuffer3D,\n    displacementsBwd: TensorBuffer3D): Keypoint[] {\n  const numParts = scores.shape[2];\n  const numEdges = parentToChildEdges.length;\n\n  const instanceKeypoints: Keypoint[] = new Array(numParts);\n  // Start a new detection instance at the position of the root.\n  const {part: rootPart, score: rootScore} = root;\n  const rootPoint = getImageCoords(rootPart, outputStride, offsets);\n\n  instanceKeypoints[rootPart.id] = {\n    score: rootScore,\n    part: PART_NAMES[rootPart.id],\n    position: rootPoint\n  };\n\n  // Decode the part positions upwards in the tree, following the backward\n  // displacements.\n  for (let edge = numEdges - 1; edge >= 0; --edge) {\n    const sourceKeypointId = parentToChildEdges[edge];\n    const targetKeypointId = childToParentEdges[edge];\n    if (instanceKeypoints[sourceKeypointId] &&\n        !instanceKeypoints[targetKeypointId]) {\n      instanceKeypoints[targetKeypointId] = traverseToTargetKeypoint(\n          edge, instanceKeypoints[sourceKeypointId], targetKeypointId, scores,\n          offsets, outputStride, displacementsBwd);\n    }\n  }\n\n  // Decode the part positions downwards in the tree, following the forward\n  // displacements.\n  for (let edge = 0; edge < numEdges; ++edge) {\n    const sourceKeypointId = childToParentEdges[edge];\n    const targetKeypointId = parentToChildEdges[edge];\n    if (instanceKeypoints[sourceKeypointId] &&\n        !instanceKeypoints[targetKeypointId]) {\n      instanceKeypoints[targetKeypointId] = traverseToTargetKeypoint(\n          edge, instanceKeypoints[sourceKeypointId], targetKeypointId, scores,\n          offsets, outputStride, displacementsFwd);\n    }\n  }\n\n  return instanceKeypoints;\n}\n","/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Keypoint, Pose, TensorBuffer3D} from '../types';\n\nimport {buildPartWithScoreQueue} from './build_part_with_score_queue';\nimport {decodePose} from './decode_pose';\nimport {getImageCoords, squaredDistance} from './util';\n\nfunction withinNmsRadiusOfCorrespondingPoint(\n    poses: Pose[], squaredNmsRadius: number, {x, y}: {x: number, y: number},\n    keypointId: number): boolean {\n  return poses.some(({keypoints}) => {\n    const correspondingKeypoint = keypoints[keypointId].position;\n    return squaredDistance(\n               y, x, correspondingKeypoint.y, correspondingKeypoint.x) <=\n        squaredNmsRadius;\n  });\n}\n\n/* Score the newly proposed object instance without taking into account\n * the scores of the parts that overlap with any previously detected\n * instance.\n */\nfunction getInstanceScore(\n    existingPoses: Pose[], squaredNmsRadius: number,\n    instanceKeypoints: Keypoint[]): number {\n  let notOverlappedKeypointScores = instanceKeypoints.reduce(\n      (result, {position, score}, keypointId): number => {\n        if (!withinNmsRadiusOfCorrespondingPoint(\n                existingPoses, squaredNmsRadius, position, keypointId)) {\n          result += score;\n        }\n        return result;\n      }, 0.0);\n\n  return notOverlappedKeypointScores /= instanceKeypoints.length;\n}\n\n// A point (y, x) is considered as root part candidate if its score is a\n// maximum in a window |y - y'| <= kLocalMaximumRadius, |x - x'| <=\n// kLocalMaximumRadius.\nconst kLocalMaximumRadius = 1;\n\n/**\n * Detects multiple poses and finds their parts from part scores and\n * displacement vectors. It returns up to `maxDetections` object instance\n * detections in decreasing root score order. It works as follows: We first\n * create a priority queue with local part score maxima above\n * `scoreThreshold`, considering all parts at the same time. Then we\n * iteratively pull the top  element of the queue (in decreasing score order)\n * and treat it as a root candidate for a new object instance. To avoid\n * duplicate detections, we reject the root candidate if it is within a disk\n * of `nmsRadius` pixels from the corresponding part of a previously detected\n * instance, which is a form of part-based non-maximum suppression (NMS). If\n * the root candidate passes the NMS check, we start a new object instance\n * detection, treating the corresponding part as root and finding the\n * positions of the remaining parts by following the displacement vectors\n * along the tree-structured part graph. We assign to the newly detected\n * instance a score equal to the sum of scores of its parts which have not\n * been claimed by a previous instance (i.e., those at least `nmsRadius`\n * pixels away from the corresponding part of all previously detected\n * instances), divided by the total number of parts `numParts`.\n *\n * @param heatmapScores 3-D tensor with shape `[height, width, numParts]`.\n * The value of heatmapScores[y, x, k]` is the score of placing the `k`-th\n * object part at position `(y, x)`.\n *\n * @param offsets 3-D tensor with shape `[height, width, numParts * 2]`.\n * The value of [offsets[y, x, k], offsets[y, x, k + numParts]]` is the\n * short range offset vector of the `k`-th  object part at heatmap\n * position `(y, x)`.\n *\n * @param displacementsFwd 3-D tensor of shape\n * `[height, width, 2 * num_edges]`, where `num_edges = num_parts - 1` is the\n * number of edges (parent-child pairs) in the tree. It contains the forward\n * displacements between consecutive part from the root towards the leaves.\n *\n * @param displacementsBwd 3-D tensor of shape\n * `[height, width, 2 * num_edges]`, where `num_edges = num_parts - 1` is the\n * number of edges (parent-child pairs) in the tree. It contains the backward\n * displacements between consecutive part from the root towards the leaves.\n *\n * @param outputStride The output stride that was used when feed-forwarding\n * through the PoseNet model.  Must be 32, 16, or 8.\n *\n * @param maxPoseDetections Maximum number of returned instance detections per\n * image.\n *\n * @param scoreThreshold Only return instance detections that have root part\n * score greater or equal to this value. Defaults to 0.5.\n *\n * @param nmsRadius Non-maximum suppression part distance. It needs to be\n * strictly positive. Two parts suppress each other if they are less than\n * `nmsRadius` pixels away. Defaults to 20.\n *\n * @return An array of poses and their scores, each containing keypoints and\n * the corresponding keypoint scores.\n */\nexport function decodeMultiplePoses(\n    scoresBuffer: TensorBuffer3D, offsetsBuffer: TensorBuffer3D,\n    displacementsFwdBuffer: TensorBuffer3D,\n    displacementsBwdBuffer: TensorBuffer3D, outputStride: number,\n    maxPoseDetections: number, scoreThreshold = 0.5, nmsRadius = 20): Pose[] {\n  const poses: Pose[] = [];\n\n  const queue = buildPartWithScoreQueue(\n      scoreThreshold, kLocalMaximumRadius, scoresBuffer);\n\n  const squaredNmsRadius = nmsRadius * nmsRadius;\n\n  // Generate at most maxDetections object instances per image in\n  // decreasing root part score order.\n  while (poses.length < maxPoseDetections && !queue.empty()) {\n    // The top element in the queue is the next root candidate.\n    const root = queue.dequeue();\n\n    // Part-based non-maximum suppression: We reject a root candidate if it\n    // is within a disk of `nmsRadius` pixels from the corresponding part of\n    // a previously detected instance.\n    const rootImageCoords =\n        getImageCoords(root.part, outputStride, offsetsBuffer);\n    if (withinNmsRadiusOfCorrespondingPoint(\n            poses, squaredNmsRadius, rootImageCoords, root.part.id)) {\n      continue;\n    }\n\n    // Start a new detection instance at the position of the root.\n    const keypoints = decodePose(\n        root, scoresBuffer, offsetsBuffer, outputStride, displacementsFwdBuffer,\n        displacementsBwdBuffer);\n\n    const score = getInstanceScore(poses, squaredNmsRadius, keypoints);\n\n    poses.push({keypoints, score});\n  }\n\n  return poses;\n}\n","/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\n\nimport {BaseModel} from './base_model';\n\nconst imageNetMean = [-123.15, -115.90, -103.06];\n\nexport class ResNet extends BaseModel {\n  preprocessInput(input: tf.Tensor3D): tf.Tensor3D {\n    return tf.add(input, imageNetMean);\n  }\n\n  nameOutputResults(results: tf.Tensor3D[]) {\n    const [\n      displacementBwd,\n      displacementFwd,\n      heatmap,\n      longOffsets,\n      offsets,\n      partHeatmaps,\n      segmentation,\n      partOffsets,\n  ] = results;\n    return {\n      offsets,\n      segmentation,\n      partHeatmaps,\n      longOffsets,\n      heatmap,\n      displacementFwd,\n      displacementBwd,\n      partOffsets\n    };\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nconst RESNET50_BASE_URL =\n    'https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/resnet50/';\nconst MOBILENET_BASE_URL =\n    'https://storage.googleapis.com/tfjs-models/savedmodel/bodypix/mobilenet/';\n\n// The BodyPix 2.0 ResNet50 models use the latest TensorFlow.js 1.0 model\n// format.\nexport function resNet50SavedModel(stride: number, quantBytes: number): string {\n  const graphJson = `model-stride${stride}.json`;\n  // quantBytes=4 corresponding to the non-quantized full-precision SavedModel.\n  if (quantBytes === 4) {\n    return RESNET50_BASE_URL + `float/` + graphJson;\n  } else {\n    return RESNET50_BASE_URL + `quant${quantBytes}/` + graphJson;\n  }\n}\n\n// The BodyPix 2.0 MobileNetV1 models use the latest TensorFlow.js 1.0 model\n// format.\nexport function mobileNetSavedModel(\n    stride: number, multiplier: number, quantBytes: number): string {\n  const toStr: {[key: number]: string} = {1.0: '100', 0.75: '075', 0.50: '050'};\n  const graphJson = `model-stride${stride}.json`;\n  // quantBytes=4 corresponding to the non-quantized full-precision SavedModel.\n  if (quantBytes === 4) {\n    return MOBILENET_BASE_URL + `float/${toStr[multiplier]}/` + graphJson;\n  } else {\n    return MOBILENET_BASE_URL + `quant${quantBytes}/${toStr[multiplier]}/` +\n        graphJson;\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\n\nimport {BodyPixInput, BodyPixOutputStride, Padding} from './types';\nimport {Pose, TensorBuffer3D} from './types';\nimport {BodyPixInternalResolution} from './types';\n\nfunction getSizeFromImageLikeElement(input: HTMLImageElement|\n                                     HTMLCanvasElement|\n                                     OffscreenCanvas): [number, number] {\n  if ('offsetHeight' in input && input.offsetHeight !== 0\n      && 'offsetWidth' in input && input.offsetWidth !== 0) {\n    return [input.offsetHeight, input.offsetWidth];\n  } else if (input.height != null && input.width != null) {\n    return [input.height, input.width];\n  } else {\n    throw new Error(\n        `HTMLImageElement must have height and width attributes set.`);\n  }\n}\n\nfunction getSizeFromVideoElement(input: HTMLVideoElement): [number, number] {\n  if (input.hasAttribute('height') && input.hasAttribute('width')) {\n    // Prioritizes user specified height and width.\n    // We can't test the .height and .width properties directly,\n    // because they evaluate to 0 if unset.\n    return [input.height, input.width];\n  } else {\n    return [input.videoHeight, input.videoWidth];\n  }\n}\n\nexport function getInputSize(input: BodyPixInput): [number, number] {\n  if ((typeof (HTMLCanvasElement) !== 'undefined' &&\n       input instanceof HTMLCanvasElement) ||\n      (typeof (OffscreenCanvas) !== 'undefined' &&\n          input instanceof OffscreenCanvas) ||\n      (typeof (HTMLImageElement) !== 'undefined' &&\n       input instanceof HTMLImageElement)) {\n    return getSizeFromImageLikeElement(input);\n  } else if (typeof (ImageData) !== 'undefined' && input instanceof ImageData) {\n    return [input.height, input.width];\n  } else if (\n      typeof (HTMLVideoElement) !== 'undefined' &&\n      input instanceof HTMLVideoElement) {\n    return getSizeFromVideoElement(input);\n  } else if (input instanceof tf.Tensor) {\n    return [input.shape[0], input.shape[1]];\n  } else {\n    throw new Error(`error: Unknown input type: ${input}.`);\n  }\n}\n\nfunction isValidInputResolution(\n    resolution: number, outputStride: number): boolean {\n  return (resolution - 1) % outputStride === 0;\n}\n\nexport function toValidInputResolution(\n    inputResolution: number, outputStride: BodyPixOutputStride): number {\n  if (isValidInputResolution(inputResolution, outputStride)) {\n    return inputResolution;\n  }\n\n  return Math.floor(inputResolution / outputStride) * outputStride + 1;\n}\n\nconst INTERNAL_RESOLUTION_STRING_OPTIONS = {\n  low: 'low',\n  medium: 'medium',\n  high: 'high',\n  full: 'full'\n};\n\nconst INTERNAL_RESOLUTION_PERCENTAGES = {\n  [INTERNAL_RESOLUTION_STRING_OPTIONS.low]: 0.25,\n  [INTERNAL_RESOLUTION_STRING_OPTIONS.medium]: 0.5,\n  [INTERNAL_RESOLUTION_STRING_OPTIONS.high]: 0.75,\n  [INTERNAL_RESOLUTION_STRING_OPTIONS.full]: 1.0\n};\n\nconst MIN_INTERNAL_RESOLUTION = 0.1;\nconst MAX_INTERNAL_RESOLUTION = 2.0;\n\nfunction toInternalResolutionPercentage(\n    internalResolution: BodyPixInternalResolution): number {\n  if (typeof internalResolution === 'string') {\n    const result = INTERNAL_RESOLUTION_PERCENTAGES[internalResolution];\n\n    tf.util.assert(\n        typeof result === 'number',\n        () => `string value of inputResolution must be one of ${\n            Object.values(INTERNAL_RESOLUTION_STRING_OPTIONS)\n                .join(',')} but was ${internalResolution}.`);\n    return result;\n  } else {\n    tf.util.assert(\n        typeof internalResolution === 'number' &&\n            internalResolution <= MAX_INTERNAL_RESOLUTION &&\n            internalResolution >= MIN_INTERNAL_RESOLUTION,\n        () =>\n            `inputResolution must be a string or number between ${\n                MIN_INTERNAL_RESOLUTION} and ${MAX_INTERNAL_RESOLUTION}, but ` +\n            `was ${internalResolution}`);\n\n    return internalResolution;\n  }\n}\n\nexport function toInputResolutionHeightAndWidth(\n    internalResolution: BodyPixInternalResolution,\n    outputStride: BodyPixOutputStride,\n    [inputHeight, inputWidth]: [number, number]): [number, number] {\n  const internalResolutionPercentage =\n      toInternalResolutionPercentage(internalResolution);\n\n  return [\n    toValidInputResolution(\n        inputHeight * internalResolutionPercentage, outputStride),\n    toValidInputResolution(\n        inputWidth * internalResolutionPercentage, outputStride)\n  ];\n}\n\nexport function toInputTensor(input: BodyPixInput) {\n  // TODO: tf.browser.fromPixels types to support OffscreenCanvas\n  // @ts-ignore\n  return input instanceof tf.Tensor ? input : tf.browser.fromPixels(input);\n}\n\nexport function resizeAndPadTo(\n    imageTensor: tf.Tensor3D, [targetH, targetW]: [number, number],\n    flipHorizontal = false): {\n  resizedAndPadded: tf.Tensor3D,\n  paddedBy: [[number, number], [number, number]]\n} {\n  const [height, width] = imageTensor.shape;\n\n  const targetAspect = targetW / targetH;\n  const aspect = width / height;\n\n  let resizeW: number;\n  let resizeH: number;\n  let padL: number;\n  let padR: number;\n  let padT: number;\n  let padB: number;\n\n  if (aspect > targetAspect) {\n    // resize to have the larger dimension match the shape.\n    resizeW = targetW;\n    resizeH = Math.ceil(resizeW / aspect);\n\n    const padHeight = targetH - resizeH;\n    padL = 0;\n    padR = 0;\n    padT = Math.floor(padHeight / 2);\n    padB = targetH - (resizeH + padT);\n  } else {\n    resizeH = targetH;\n    resizeW = Math.ceil(targetH * aspect);\n\n    const padWidth = targetW - resizeW;\n    padL = Math.floor(padWidth / 2);\n    padR = targetW - (resizeW + padL);\n    padT = 0;\n    padB = 0;\n  }\n\n  const resizedAndPadded = tf.tidy(() => {\n    // resize to have largest dimension match image\n    let resized: tf.Tensor3D;\n    if (flipHorizontal) {\n      resized = tf.image.resizeBilinear(\n          tf.reverse(imageTensor, 1), [resizeH, resizeW]);\n    } else {\n      resized = tf.image.resizeBilinear(imageTensor, [resizeH, resizeW]);\n    }\n\n    const padded = tf.pad3d(resized, [[padT, padB], [padL, padR], [0, 0]]);\n\n    return padded;\n  });\n\n  return {resizedAndPadded, paddedBy: [[padT, padB], [padL, padR]]};\n}\n\nexport function scaleAndCropToInputTensorShape(\n    tensor: tf.Tensor3D,\n    [inputTensorHeight, inputTensorWidth]: [number, number],\n    [resizedAndPaddedHeight, resizedAndPaddedWidth]: [number, number],\n    [[padT, padB], [padL, padR]]: [[number, number], [number, number]],\n    applySigmoidActivation = false): tf.Tensor3D {\n  return tf.tidy(() => {\n    let inResizedAndPadded: tf.Tensor3D = tf.image.resizeBilinear(tensor,\n        [resizedAndPaddedHeight, resizedAndPaddedWidth], true);\n\n    if (applySigmoidActivation) {\n      inResizedAndPadded = tf.sigmoid(inResizedAndPadded);\n    }\n\n    return removePaddingAndResizeBack(\n        inResizedAndPadded, [inputTensorHeight, inputTensorWidth],\n        [[padT, padB], [padL, padR]]);\n  });\n}\n\nexport function removePaddingAndResizeBack(\n    resizedAndPadded: tf.Tensor3D,\n    [originalHeight, originalWidth]: [number, number],\n    [[padT, padB], [padL, padR]]: [[number, number], [number, number]]):\n    tf.Tensor3D {\n  return tf.tidy(() => {\n    const batchedImage: tf.Tensor4D = tf.expandDims(resizedAndPadded);\n    return tf.squeeze(tf.image\n        .cropAndResize(\n            batchedImage, [[\n              padT / (originalHeight + padT + padB - 1.0),\n              padL / (originalWidth + padL + padR - 1.0),\n              (padT + originalHeight - 1.0) /\n                  (originalHeight + padT + padB - 1.0),\n              (padL + originalWidth - 1.0) / (originalWidth + padL + padR - 1.0)\n            ]],\n            [0], [originalHeight, originalWidth]), [0]);\n  });\n}\n\nexport function resize2d(\n    tensor: tf.Tensor2D, resolution: [number, number],\n    nearestNeighbor?: boolean): tf.Tensor2D {\n  return tf.tidy(() => {\n    const batchedImage: tf.Tensor4D = tf.expandDims(tensor, 2);\n    return tf.squeeze(\n        tf.image.resizeBilinear(batchedImage, resolution, nearestNeighbor));\n  });\n}\n\nexport function padAndResizeTo(\n    input: BodyPixInput, [targetH, targetW]: [number, number]):\n    {resized: tf.Tensor3D, padding: Padding} {\n  const [height, width] = getInputSize(input);\n  const targetAspect = targetW / targetH;\n  const aspect = width / height;\n  let [padT, padB, padL, padR] = [0, 0, 0, 0];\n  if (aspect < targetAspect) {\n    // pads the width\n    padT = 0;\n    padB = 0;\n    padL = Math.round(0.5 * (targetAspect * height - width));\n    padR = Math.round(0.5 * (targetAspect * height - width));\n  } else {\n    // pads the height\n    padT = Math.round(0.5 * ((1.0 / targetAspect) * width - height));\n    padB = Math.round(0.5 * ((1.0 / targetAspect) * width - height));\n    padL = 0;\n    padR = 0;\n  }\n\n  const resized: tf.Tensor3D = tf.tidy(() => {\n    let imageTensor = toInputTensor(input);\n    imageTensor = tf.pad3d(imageTensor, [[padT, padB], [padL, padR], [0, 0]]);\n\n    return tf.image.resizeBilinear(imageTensor, [targetH, targetW]);\n  });\n\n  return {resized, padding: {top: padT, left: padL, right: padR, bottom: padB}};\n}\n\nexport async function toTensorBuffers3D(tensors: tf.Tensor3D[]):\n    Promise<TensorBuffer3D[]> {\n  return Promise.all(tensors.map(tensor => tensor.buffer()));\n}\n\nexport function scalePose(\n    pose: Pose, scaleY: number, scaleX: number, offsetY = 0,\n    offsetX = 0): Pose {\n  return {\n    score: pose.score,\n    keypoints: pose.keypoints.map(({score, part, position}) => ({\n                                    score,\n                                    part,\n                                    position: {\n                                      x: position.x * scaleX + offsetX,\n                                      y: position.y * scaleY + offsetY\n                                    }\n                                  }))\n  };\n}\n\nexport function scalePoses(\n    poses: Pose[], scaleY: number, scaleX: number, offsetY = 0, offsetX = 0) {\n  if (scaleX === 1 && scaleY === 1 && offsetY === 0 && offsetX === 0) {\n    return poses;\n  }\n  return poses.map(pose => scalePose(pose, scaleY, scaleX, offsetY, offsetX));\n}\n\nexport function flipPoseHorizontal(pose: Pose, imageWidth: number): Pose {\n  return {\n    score: pose.score,\n    keypoints: pose.keypoints.map(\n        ({score, part, position}) => ({\n          score,\n          part,\n          position: {x: imageWidth - 1 - position.x, y: position.y}\n        }))\n  };\n}\n\nexport function flipPosesHorizontal(poses: Pose[], imageWidth: number) {\n  if (imageWidth <= 0) {\n    return poses;\n  }\n  return poses.map(pose => flipPoseHorizontal(pose, imageWidth));\n}\n\nexport function scaleAndFlipPoses(\n    poses: Pose[], [height, width]: [number, number],\n    [inputResolutionHeight, inputResolutionWidth]: [number, number],\n    padding: Padding, flipHorizontal: boolean): Pose[] {\n  const scaleY =\n      (height + padding.top + padding.bottom) / (inputResolutionHeight);\n  const scaleX =\n      (width + padding.left + padding.right) / (inputResolutionWidth);\n\n  const scaledPoses =\n      scalePoses(poses, scaleY, scaleX, -padding.top, -padding.left);\n\n  if (flipHorizontal) {\n    return flipPosesHorizontal(scaledPoses, width);\n  } else {\n    return scaledPoses;\n  }\n}\n","\n/**\n * @license\n * Copyright 2019 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tfconv from '@tensorflow/tfjs-converter';\nimport * as tf from '@tensorflow/tfjs-core';\n\nimport {BaseModel} from './base_model';\nimport {decodeOnlyPartSegmentation, decodePartSegmentation, toMaskTensor} from './decode_part_map';\nimport {MobileNet} from './mobilenet';\nimport {decodePersonInstanceMasks, decodePersonInstancePartMasks} from './multi_person/decode_instance_masks';\nimport {decodeMultiplePoses} from './multi_person/decode_multiple_poses';\nimport {ResNet} from './resnet';\nimport {mobileNetSavedModel, resNet50SavedModel} from './saved_models';\nimport {BodyPixArchitecture, BodyPixInput, BodyPixInternalResolution, BodyPixMultiplier, BodyPixOutputStride, BodyPixQuantBytes, Padding} from './types';\nimport {PartSegmentation, PersonSegmentation, SemanticPartSegmentation, SemanticPersonSegmentation} from './types';\nimport {getInputSize, padAndResizeTo, scaleAndCropToInputTensorShape, scaleAndFlipPoses, toInputResolutionHeightAndWidth, toTensorBuffers3D} from './util';\n\nconst APPLY_SIGMOID_ACTIVATION = true;\nconst FLIP_POSES_AFTER_SCALING = false;\n\n/**\n * BodyPix model loading is configurable using the following config dictionary.\n *\n * `architecture`: BodyPixArchitecture. It determines which BodyPix architecture\n * to load. The supported architectures are: MobileNetV1 and ResNet50.\n *\n * `outputStride`: Specifies the output stride of the BodyPix model.\n * The smaller the value, the larger the output resolution, and more accurate\n * the model at the cost of speed. Set this to a larger value to increase speed\n * at the cost of accuracy. Stride 32 is supported for ResNet and\n * stride 8,16,32 are supported for various MobileNetV1 models.\n *\n * `multiplier`: An optional number with values: 1.01, 1.0, 0.75, or\n * 0.50. The value is used only by MobileNet architecture. It is the float\n * multiplier for the depth (number of channels) for all convolution ops.\n * The larger the value, the larger the size of the layers, and more accurate\n * the model at the cost of speed. Set this to a smaller value to increase speed\n * at the cost of accuracy.\n *\n * `modelUrl`: An optional string that specifies custom url of the model. This\n * is useful for area/countries that don't have access to the model hosted on\n * GCP.\n *\n * `quantBytes`: An optional number with values: 1, 2, or 4.  This parameter\n * affects weight quantization in the models. The available options are\n * 1 byte, 2 bytes, and 4 bytes. The higher the value, the larger the model size\n * and thus the longer the loading time, the lower the value, the shorter the\n * loading time but lower the accuracy.\n */\nexport interface ModelConfig {\n  architecture: BodyPixArchitecture;\n  outputStride: BodyPixOutputStride;\n  multiplier?: BodyPixMultiplier;\n  modelUrl?: string;\n  quantBytes?: BodyPixQuantBytes;\n}\n\n// The default configuration for loading MobileNetV1 based BodyPix.\n//\n// (And for references, the default configuration for loading ResNet\n// based PoseNet is also included).\n//\n// ```\n// const RESNET_CONFIG = {\n//   architecture: 'ResNet50',\n//   outputStride: 32,\n//   quantBytes: 4,\n// } as ModelConfig;\n// ```\n\nconst MOBILENET_V1_CONFIG = {\n  architecture: 'MobileNetV1',\n  outputStride: 16,\n  quantBytes: 4,\n  multiplier: 0.75,\n} as ModelConfig;\n\nconst VALID_ARCHITECTURE: BodyPixArchitecture[] = ['MobileNetV1', 'ResNet50'];\nconst VALID_STRIDE: {[id: string]: BodyPixOutputStride[]} = {\n  'MobileNetV1': [8, 16, 32],\n  'ResNet50': [32, 16]\n};\nconst VALID_MULTIPLIER: {[id: string]: BodyPixMultiplier[]} = {\n  'MobileNetV1': [0.50, 0.75, 1.0],\n  'ResNet50': [1.0]\n};\nconst VALID_QUANT_BYTES: BodyPixQuantBytes[] = [1, 2, 4];\n\nfunction validateModelConfig(config: ModelConfig): ModelConfig {\n  config = config || MOBILENET_V1_CONFIG;\n\n  if (config.architecture == null) {\n    config.architecture = 'MobileNetV1';\n  }\n  if (VALID_ARCHITECTURE.indexOf(config.architecture) < 0) {\n    throw new Error(\n        `Invalid architecture ${config.architecture}. ` +\n        `Should be one of ${VALID_ARCHITECTURE}`);\n  }\n  if (config.outputStride == null) {\n    config.outputStride = 16;\n  }\n  if (VALID_STRIDE[config.architecture].indexOf(config.outputStride) < 0) {\n    throw new Error(\n        `Invalid outputStride ${config.outputStride}. ` +\n        `Should be one of ${VALID_STRIDE[config.architecture]} ` +\n        `for architecture ${config.architecture}.`);\n  }\n\n  if (config.multiplier == null) {\n    config.multiplier = 1.0;\n  }\n  if (VALID_MULTIPLIER[config.architecture].indexOf(config.multiplier) < 0) {\n    throw new Error(\n        `Invalid multiplier ${config.multiplier}. ` +\n        `Should be one of ${VALID_MULTIPLIER[config.architecture]} ` +\n        `for architecture ${config.architecture}.`);\n  }\n\n  if (config.quantBytes == null) {\n    config.quantBytes = 4;\n  }\n  if (VALID_QUANT_BYTES.indexOf(config.quantBytes) < 0) {\n    throw new Error(\n        `Invalid quantBytes ${config.quantBytes}. ` +\n        `Should be one of ${VALID_QUANT_BYTES} ` +\n        `for architecture ${config.architecture}.`);\n  }\n\n  return config;\n}\n\n/**\n * BodyPix inference is configurable using the following config dictionary.\n *\n * `flipHorizontal`: If the left-right keypoint of poses/part segmentation\n * should be flipped/mirrored horizontally. This should be set to true for\n * videos where the video is by default flipped horizontally (i.e. a webcam),\n * and you want the person & body part segmentation to be returned in the proper\n * orientation.\n *\n * `internalResolution`: Defaults to 'medium'. The internal resolution\n * percentage that the input is resized to before inference. The larger the\n * internalResolution the more accurate the model at the cost of slower\n * prediction times. Available values are 'low', 'medium', 'high', 'full', or a\n * percentage value between 0 and 1. The values 'low', 'medium', 'high', and\n * 'full' map to 0.25, 0.5, 0.75, and 1.0 correspondingly.\n *\n * `segmentationThreshold`: The minimum that segmentation values must\n * have to be considered part of the person. Affects the generation of the\n * segmentation mask. More specifically, it is the threshold used to binarize\n * the intermediate person segmentation probability. The probability of each\n * pixel belongs to a person is in range [0, 1]. If the probability is greater\n * than the `segmentationThreshold`, it will be set to 1 otherwise 0.\n *\n */\nexport interface InferenceConfig {\n  flipHorizontal?: boolean;\n  internalResolution?: BodyPixInternalResolution;\n  segmentationThreshold?: number;\n}\n\n/**\n * Person Inference Config\n *\n * `maxDetections`: Defaults to 10. Maximum number of person pose detections per\n * image.\n *\n * `scoreThreshold`: Defaults to 0.4. Only return person pose that have root\n * part score greater or equal to this value.\n *\n * `nmsRadius`: Defaults to 20. Non-maximum suppression part distance in pixels.\n * It needs to be strictly positive. Two pose keypoints suppress each other if\n * they are less than `nmsRadius` pixels away.\n */\nexport interface PersonInferenceConfig extends InferenceConfig {\n  maxDetections?: number;\n  scoreThreshold?: number;\n  nmsRadius?: number;\n}\n\n/**\n * Multiple Person Instance Inference Config\n *\n * `maxDetections`: Defaults to 10. Maximum number of returned instance\n * segmentation and pose detections per image.\n *\n * `scoreThreshold`: Defaults to 0.4. Only returns and uses person\n * poses for instance segmentation assignment when the pose has root part score\n * greater or equal to this value.\n *\n * `nmsRadius`: Defaults to 20. Non-maximum suppression part distance in pixels.\n * It needs to be strictly positive. Two parts suppress each other if they are\n * less than `nmsRadius` pixels away.\n *\n * `minKeypointScore`: Default to 0.3. Keypoints above the score are used\n * for matching and assigning segmentation mask to each person.\n *\n * `refineSteps`: Default to 10. The number of refinement steps used when\n * assigning the instance segmentation. It needs to be strictly positive. The\n * larger the higher the accuracy and slower the inference.\n *\n */\nexport interface MultiPersonInstanceInferenceConfig extends InferenceConfig {\n  maxDetections?: number;\n  scoreThreshold?: number;\n  nmsRadius?: number;\n  minKeypointScore?: number;\n  refineSteps?: number;\n}\n\nexport const PERSON_INFERENCE_CONFIG: PersonInferenceConfig = {\n  flipHorizontal: false,\n  internalResolution: 'medium',\n  segmentationThreshold: 0.7,\n  maxDetections: 10,\n  scoreThreshold: 0.4,\n  nmsRadius: 20,\n};\n\nexport const MULTI_PERSON_INSTANCE_INFERENCE_CONFIG:\n    MultiPersonInstanceInferenceConfig = {\n      flipHorizontal: false,\n      internalResolution: 'medium',\n      segmentationThreshold: 0.7,\n      maxDetections: 10,\n      scoreThreshold: 0.4,\n      nmsRadius: 20,\n      minKeypointScore: 0.3,\n      refineSteps: 10\n    };\n\nfunction validatePersonInferenceConfig(config: PersonInferenceConfig) {\n  const {segmentationThreshold, maxDetections, scoreThreshold, nmsRadius} =\n      config;\n\n  if (segmentationThreshold < 0.0 || segmentationThreshold > 1.0) {\n    throw new Error(\n        `segmentationThreshold ${segmentationThreshold}. ` +\n        `Should be in range [0.0, 1.0]`);\n  }\n\n  if (maxDetections <= 0) {\n    throw new Error(\n        `Invalid maxDetections ${maxDetections}. ` +\n        `Should be > 0`);\n  }\n\n  if (scoreThreshold < 0.0 || scoreThreshold > 1.0) {\n    throw new Error(\n        `Invalid scoreThreshold ${scoreThreshold}. ` +\n        `Should be in range [0.0, 1.0]`);\n  }\n\n  if (nmsRadius <= 0) {\n    throw new Error(`Invalid nmsRadius ${nmsRadius}.`);\n  }\n}\n\nfunction validateMultiPersonInstanceInferenceConfig(\n    config: MultiPersonInstanceInferenceConfig) {\n  const {\n    segmentationThreshold,\n    maxDetections,\n    scoreThreshold,\n    nmsRadius,\n    minKeypointScore,\n    refineSteps\n  } = config;\n\n  if (segmentationThreshold < 0.0 || segmentationThreshold > 1.0) {\n    throw new Error(\n        `segmentationThreshold ${segmentationThreshold}. ` +\n        `Should be in range [0.0, 1.0]`);\n  }\n\n  if (maxDetections <= 0) {\n    throw new Error(\n        `Invalid maxDetections ${maxDetections}. ` +\n        `Should be > 0`);\n  }\n\n  if (scoreThreshold < 0.0 || scoreThreshold > 1.0) {\n    throw new Error(\n        `Invalid scoreThreshold ${scoreThreshold}. ` +\n        `Should be in range [0.0, 1.0]`);\n  }\n\n  if (nmsRadius <= 0) {\n    throw new Error(`Invalid nmsRadius ${nmsRadius}.`);\n  }\n\n  if (minKeypointScore < 0 || minKeypointScore > 1) {\n    throw new Error(\n        `Invalid minKeypointScore ${minKeypointScore}.` +\n        `Should be in range [0.0, 1.0]`);\n  }\n\n  if (refineSteps <= 0 || refineSteps > 20) {\n    throw new Error(\n        `Invalid refineSteps ${refineSteps}.` +\n        `Should be in range [1, 20]`);\n  }\n}\n\nexport class BodyPix {\n  baseModel: BaseModel;\n\n  constructor(net: BaseModel) {\n    this.baseModel = net;\n  }\n\n  private predictForPersonSegmentation(input: tf.Tensor3D): {\n    segmentLogits: tf.Tensor3D,\n    heatmapScores: tf.Tensor3D,\n    offsets: tf.Tensor3D,\n    displacementFwd: tf.Tensor3D,\n    displacementBwd: tf.Tensor3D,\n  } {\n    const {\n      segmentation,\n      heatmapScores,\n      offsets,\n      displacementFwd,\n      displacementBwd,\n    } = this.baseModel.predict(input);\n    return {\n      segmentLogits: segmentation,\n      heatmapScores,\n      offsets,\n      displacementFwd,\n      displacementBwd,\n    };\n  }\n\n  private predictForPersonSegmentationAndPart(input: tf.Tensor3D): {\n    segmentLogits: tf.Tensor3D,\n    partHeatmapLogits: tf.Tensor3D,\n    heatmapScores: tf.Tensor3D,\n    offsets: tf.Tensor3D,\n    displacementFwd: tf.Tensor3D,\n    displacementBwd: tf.Tensor3D,\n  } {\n    const {\n      segmentation,\n      partHeatmaps,\n      heatmapScores,\n      offsets,\n      displacementFwd,\n      displacementBwd\n    } = this.baseModel.predict(input);\n    return {\n      segmentLogits: segmentation,\n      partHeatmapLogits: partHeatmaps,\n      heatmapScores,\n      offsets,\n      displacementFwd,\n      displacementBwd,\n    };\n  }\n\n  private predictForMultiPersonInstanceSegmentationAndPart(input: tf.Tensor3D):\n      {\n        segmentLogits: tf.Tensor3D,\n        longOffsets: tf.Tensor3D,\n        heatmapScores: tf.Tensor3D,\n        offsets: tf.Tensor3D,\n        displacementFwd: tf.Tensor3D,\n        displacementBwd: tf.Tensor3D,\n        partHeatmaps: tf.Tensor3D\n      } {\n    const {\n      segmentation,\n      longOffsets,\n      heatmapScores,\n      offsets,\n      displacementFwd,\n      displacementBwd,\n      partHeatmaps,\n    } = this.baseModel.predict(input);\n    return {\n      segmentLogits: segmentation,\n      longOffsets,\n      heatmapScores,\n      offsets,\n      displacementFwd,\n      displacementBwd,\n      partHeatmaps\n    };\n  }\n\n  /**\n   * Given an image with people, returns a dictionary of all intermediate\n   * tensors including: 1) a binary array with 1 for the pixels that are part of\n   * the person, and 0 otherwise, 2) heatmapScores, 3) offsets, and 4) paddings.\n   *\n   * @param input ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement)\n   * The input image to feed through the network.\n   *\n   * @param internalResolution Defaults to 'medium'. The internal resolution\n   * that the input is resized to before inference. The larger the\n   * internalResolution the more accurate the model at the cost of slower\n   * prediction times. Available values are 'low', 'medium', 'high', 'full', or\n   * a percentage value between 0 and 1. The values 'low', 'medium', 'high', and\n   * 'full' map to 0.25, 0.5, 0.75, and 1.0 correspondingly.\n   *\n   * @param segmentationThreshold The minimum that segmentation values must have\n   * to be considered part of the person. Affects the generation of the\n   * segmentation mask.\n   *\n   * @return A dictionary containing `segmentation`, `heatmapScores`, `offsets`,\n   * and `padding`:\n   * - `segmentation`: A 2d Tensor with 1 for the pixels that are part of the\n   * person, and 0 otherwise. The width and height correspond to the same\n   * dimensions of the input image.\n   * - `heatmapScores`: A 3d Tensor of the keypoint heatmaps used by\n   * pose estimation decoding.\n   * - `offsets`: A 3d Tensor of the keypoint offsets used by pose\n   * estimation decoding.\n   * - `displacementFwd`: A 3d Tensor of the keypoint forward displacement used\n   * by pose estimation decoding.\n   * - `displacementBwd`: A 3d Tensor of the keypoint backward displacement used\n   * by pose estimation decoding.\n   * - `padding`: The padding (unit pixels) being applied to the input image\n   * before it is fed into the model.\n   */\n  segmentPersonActivation(\n      input: BodyPixInput, internalResolution: BodyPixInternalResolution,\n      segmentationThreshold = 0.5): {\n    segmentation: tf.Tensor2D,\n    heatmapScores: tf.Tensor3D,\n    offsets: tf.Tensor3D,\n    displacementFwd: tf.Tensor3D,\n    displacementBwd: tf.Tensor3D,\n    padding: Padding,\n    internalResolutionHeightAndWidth: [number, number]\n  } {\n    const [height, width] = getInputSize(input);\n    const internalResolutionHeightAndWidth = toInputResolutionHeightAndWidth(\n        internalResolution, this.baseModel.outputStride, [height, width]);\n    const {resized, padding} =\n        padAndResizeTo(input, internalResolutionHeightAndWidth);\n\n    const {\n      segmentation,\n      heatmapScores,\n      offsets,\n      displacementFwd,\n      displacementBwd\n    } = tf.tidy(() => {\n      const {\n        segmentLogits,\n        heatmapScores,\n        offsets,\n        displacementFwd,\n        displacementBwd\n      } = this.predictForPersonSegmentation(resized);\n\n      const [resizedHeight, resizedWidth] = resized.shape;\n\n      const scaledSegmentScores = scaleAndCropToInputTensorShape(\n          segmentLogits, [height, width], [resizedHeight, resizedWidth],\n          [[padding.top, padding.bottom], [padding.left, padding.right]],\n          APPLY_SIGMOID_ACTIVATION);\n\n      return {\n        segmentation: toMaskTensor(\n            tf.squeeze(scaledSegmentScores), segmentationThreshold),\n        heatmapScores,\n        offsets,\n        displacementFwd,\n        displacementBwd,\n      };\n    });\n    resized.dispose();\n    return {\n      segmentation,\n      heatmapScores,\n      offsets,\n      displacementFwd,\n      displacementBwd,\n      padding,\n      internalResolutionHeightAndWidth\n    };\n  }\n\n  /**\n   * Given an image with many people, returns a PersonSegmentation dictionary\n   * that contains the segmentation mask for all people and a single pose.\n   *\n   * Note: The segmentation mask returned by this method covers all people but\n   * the pose works well for one person. If you want to estimate instance-level\n   * multiple person segmentation & pose for each person, use\n   * `segmentMultiPerson` instead.\n   *\n   * @param input ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement)\n   * The input image to feed through the network.\n   *\n   * @param config PersonInferenceConfig object that contains\n   * parameters for the BodyPix inference using person decoding.\n   *\n   * @return A SemanticPersonSegmentation dictionary that contains height,\n   * width, the flattened binary segmentation mask and the poses for all people.\n   * The width and height correspond to the same dimensions of the input image.\n   * - `height`: The height of the segmentation data in pixel unit.\n   * - `width`: The width of the segmentation data in pixel unit.\n   * - `data`: The flattened Uint8Array of segmentation data. 1 means the pixel\n   * belongs to a person and 0 means the pixel doesn't belong to a person. The\n   * size of the array is equal to `height` x `width` in row-major order.\n   * - `allPoses`: The 2d poses of all people.\n   */\n  async segmentPerson(\n      input: BodyPixInput,\n      config: PersonInferenceConfig = PERSON_INFERENCE_CONFIG):\n      Promise<SemanticPersonSegmentation> {\n    config = {...PERSON_INFERENCE_CONFIG, ...config};\n\n    validatePersonInferenceConfig(config);\n\n    const {\n      segmentation,\n      heatmapScores,\n      offsets,\n      displacementFwd,\n      displacementBwd,\n      padding,\n      internalResolutionHeightAndWidth\n    } =\n        this.segmentPersonActivation(\n            input, config.internalResolution, config.segmentationThreshold);\n\n    const [height, width] = segmentation.shape;\n\n    const result = await segmentation.data() as Uint8Array;\n    segmentation.dispose();\n\n    const tensorBuffers = await toTensorBuffers3D(\n        [heatmapScores, offsets, displacementFwd, displacementBwd]);\n    const [scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf] =\n        tensorBuffers;\n\n    let poses = decodeMultiplePoses(\n        scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf,\n        this.baseModel.outputStride, config.maxDetections,\n        config.scoreThreshold, config.nmsRadius);\n\n    poses = scaleAndFlipPoses(\n        poses, [height, width], internalResolutionHeightAndWidth, padding,\n        FLIP_POSES_AFTER_SCALING);\n\n    heatmapScores.dispose();\n    offsets.dispose();\n    displacementFwd.dispose();\n    displacementBwd.dispose();\n\n    return {height, width, data: result, allPoses: poses};\n  }\n\n  /**\n   * Given an image with multiple people, returns an *array* of\n   * PersonSegmentation object. Each element in the array corresponding to one\n   * of the people in the input image. In other words, it predicts\n   * instance-level multiple person segmentation & pose for each person.\n   *\n   * The model does standard ImageNet pre-processing before inferring through\n   * the model. The image pixels should have values [0-255].\n   *\n   * @param input\n   * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement) The input\n   * image to feed through the network.\n   *\n   * @param config MultiPersonInferenceConfig object that contains\n   * parameters for the BodyPix inference using multi-person decoding.\n   *\n   * @return An array of PersonSegmentation object, each containing a width,\n   * height, a binary array (1 for the pixels that are part of the\n   * person, and 0 otherwise) and 2D pose. The array size corresponds to the\n   * number of pixels in the image. The width and height correspond to the\n   * dimensions of the image the binary array is shaped to, which are the same\n   * dimensions of the input image.\n   */\n  async segmentMultiPerson(\n      input: BodyPixInput,\n      config: MultiPersonInstanceInferenceConfig =\n          MULTI_PERSON_INSTANCE_INFERENCE_CONFIG):\n      Promise<PersonSegmentation[]> {\n    config = {...MULTI_PERSON_INSTANCE_INFERENCE_CONFIG, ...config};\n    validateMultiPersonInstanceInferenceConfig(config);\n    const [height, width] = getInputSize(input);\n    const internalResolutionHeightAndWidth = toInputResolutionHeightAndWidth(\n        config.internalResolution, this.baseModel.outputStride,\n        [height, width]);\n\n    const {resized, padding} =\n        padAndResizeTo(input, internalResolutionHeightAndWidth);\n    const {\n      segmentation,\n      longOffsets,\n      heatmapScoresRaw,\n      offsetsRaw,\n      displacementFwdRaw,\n      displacementBwdRaw,\n    } = tf.tidy(() => {\n      const {\n        segmentLogits,\n        longOffsets,\n        heatmapScores,\n        offsets,\n        displacementFwd,\n        displacementBwd,\n      } = this.predictForMultiPersonInstanceSegmentationAndPart(resized);\n      const scaledSegmentScores = scaleAndCropToInputTensorShape(\n          segmentLogits, [height, width], internalResolutionHeightAndWidth,\n          [[padding.top, padding.bottom], [padding.left, padding.right]],\n          APPLY_SIGMOID_ACTIVATION);\n      const longOffsetsResized = false;\n      let scaledLongOffsets;\n      if (longOffsetsResized) {\n        scaledLongOffsets = scaleAndCropToInputTensorShape(\n            longOffsets, [height, width], internalResolutionHeightAndWidth,\n            [[padding.top, padding.bottom], [padding.left, padding.right]],\n            APPLY_SIGMOID_ACTIVATION);\n      } else {\n        scaledLongOffsets = longOffsets;\n      }\n\n      const segmentation = toMaskTensor(\n          tf.squeeze(scaledSegmentScores), config.segmentationThreshold);\n\n      return {\n        segmentation,\n        longOffsets: scaledLongOffsets,\n        heatmapScoresRaw: heatmapScores,\n        offsetsRaw: offsets,\n        displacementFwdRaw: displacementFwd,\n        displacementBwdRaw: displacementBwd,\n      };\n    });\n\n    const tensorBuffers = await toTensorBuffers3D(\n        [heatmapScoresRaw, offsetsRaw, displacementFwdRaw, displacementBwdRaw]);\n    const [scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf] =\n        tensorBuffers;\n\n    let poses = decodeMultiplePoses(\n        scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf,\n        this.baseModel.outputStride, config.maxDetections,\n        config.scoreThreshold, config.nmsRadius);\n\n    poses = scaleAndFlipPoses(\n        poses, [height, width], internalResolutionHeightAndWidth, padding,\n        FLIP_POSES_AFTER_SCALING);\n\n    const instanceMasks = await decodePersonInstanceMasks(\n        segmentation, longOffsets, poses, height, width,\n        this.baseModel.outputStride, internalResolutionHeightAndWidth, padding,\n        config.scoreThreshold, config.refineSteps, config.minKeypointScore,\n        config.maxDetections);\n\n    resized.dispose();\n    segmentation.dispose();\n    longOffsets.dispose();\n    heatmapScoresRaw.dispose();\n    offsetsRaw.dispose();\n    displacementFwdRaw.dispose();\n    displacementBwdRaw.dispose();\n\n    return instanceMasks;\n  }\n\n  /**\n   * Given an image with many people, returns a dictionary containing: height,\n   * width, a tensor with a part id from 0-24 for the pixels that are\n   * part of a corresponding body part, and -1 otherwise. This does standard\n   * ImageNet pre-processing before inferring through the model.  The image\n   * should pixels should have values [0-255].\n   *\n   * @param input ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement)\n   * The input image to feed through the network.\n   *\n   * @param internalResolution Defaults to 'medium'. The internal resolution\n   * percentage that the input is resized to before inference. The larger the\n   * internalResolution the more accurate the model at the cost of slower\n   * prediction times. Available values are 'low', 'medium', 'high', 'full', or\n   * a percentage value between 0 and 1. The values 'low', 'medium', 'high', and\n   * 'full' map to 0.25, 0.5, 0.75, and 1.0 correspondingly.\n   *\n   * @param segmentationThreshold The minimum that segmentation values must have\n   * to be considered part of the person.  Affects the clipping of the colored\n   * part image.\n   *\n   * @return  A dictionary containing `partSegmentation`, `heatmapScores`,\n   * `offsets`, and `padding`:\n   * - `partSegmentation`: A 2d Tensor with a part id from 0-24 for\n   * the pixels that are part of a corresponding body part, and -1 otherwise.\n   * - `heatmapScores`: A 3d Tensor of the keypoint heatmaps used by\n   * single-person pose estimation decoding.\n   * - `offsets`: A 3d Tensor of the keypoint offsets used by single-person pose\n   * estimation decoding.\n   * - `displacementFwd`: A 3d Tensor of the keypoint forward displacement\n   * used by pose estimation decoding.\n   * - `displacementBwd`: A 3d Tensor of the keypoint backward displacement used\n   * by pose estimation decoding.\n   * - `padding`: The padding (unit pixels) being applied to the input image\n   * before it is fed into the model.\n   */\n  segmentPersonPartsActivation(\n      input: BodyPixInput, internalResolution: BodyPixInternalResolution,\n      segmentationThreshold = 0.5): {\n    partSegmentation: tf.Tensor2D,\n    heatmapScores: tf.Tensor3D,\n    offsets: tf.Tensor3D,\n    displacementFwd: tf.Tensor3D,\n    displacementBwd: tf.Tensor3D,\n    padding: Padding,\n    internalResolutionHeightAndWidth: [number, number]\n  } {\n    const [height, width] = getInputSize(input);\n    const internalResolutionHeightAndWidth = toInputResolutionHeightAndWidth(\n        internalResolution, this.baseModel.outputStride, [height, width]);\n    const {\n      resized,\n      padding,\n    } = padAndResizeTo(input, internalResolutionHeightAndWidth);\n\n    const {\n      partSegmentation,\n      heatmapScores,\n      offsets,\n      displacementFwd,\n      displacementBwd\n    } = tf.tidy(() => {\n      const {\n        segmentLogits,\n        partHeatmapLogits,\n        heatmapScores,\n        offsets,\n        displacementFwd,\n        displacementBwd\n      } = this.predictForPersonSegmentationAndPart(resized);\n\n      const [resizedHeight, resizedWidth] = resized.shape;\n\n      const scaledSegmentScores = scaleAndCropToInputTensorShape(\n          segmentLogits, [height, width], [resizedHeight, resizedWidth],\n          [[padding.top, padding.bottom], [padding.left, padding.right]],\n          APPLY_SIGMOID_ACTIVATION);\n\n      const scaledPartHeatmapScore = scaleAndCropToInputTensorShape(\n          partHeatmapLogits, [height, width], [resizedHeight, resizedWidth],\n          [[padding.top, padding.bottom], [padding.left, padding.right]],\n          APPLY_SIGMOID_ACTIVATION);\n      const segmentation =\n          toMaskTensor(tf.squeeze(scaledSegmentScores), segmentationThreshold);\n      return {\n        partSegmentation:\n            decodePartSegmentation(segmentation, scaledPartHeatmapScore),\n        heatmapScores,\n        offsets,\n        displacementFwd,\n        displacementBwd,\n      };\n    });\n    resized.dispose();\n    return {\n      partSegmentation,\n      heatmapScores,\n      offsets,\n      displacementFwd,\n      displacementBwd,\n      padding,\n      internalResolutionHeightAndWidth\n    };\n  }\n\n  /**\n   * Given an image with many people, returns a PartSegmentation dictionary that\n   * contains the body part segmentation mask for all people and a single pose.\n   *\n   * Note: The body part segmentation mask returned by this method covers all\n   * people but the pose works well when there is one person. If you want to\n   * estimate instance-level multiple person body part segmentation & pose for\n   * each person, use `segmentMultiPersonParts` instead.\n   *\n   * @param input ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement)\n   * The input image to feed through the network.\n   *\n   * @param config PersonInferenceConfig object that contains\n   * parameters for the BodyPix inference using single person decoding.\n   *\n   * @return A SemanticPartSegmentation dictionary that contains height, width,\n   * the flattened binary segmentation mask and the pose for the person. The\n   * width and height correspond to the same dimensions of the input image.\n   * - `height`: The height of the person part segmentation data in pixel unit.\n   * - `width`: The width of the person part segmentation data in pixel unit.\n   * - `data`: The flattened Int32Array of person part segmentation data with a\n   * part id from 0-24 for the pixels that are part of a corresponding body\n   * part, and -1 otherwise. The size of the array is equal to `height` x\n   * `width` in row-major order.\n   * - `allPoses`: The 2d poses of all people.\n   */\n  async segmentPersonParts(\n      input: BodyPixInput,\n      config: PersonInferenceConfig = PERSON_INFERENCE_CONFIG):\n      Promise<SemanticPartSegmentation> {\n    config = {...PERSON_INFERENCE_CONFIG, ...config};\n\n    validatePersonInferenceConfig(config);\n    const {\n      partSegmentation,\n      heatmapScores,\n      offsets,\n      displacementFwd,\n      displacementBwd,\n      padding,\n      internalResolutionHeightAndWidth\n    } =\n        this.segmentPersonPartsActivation(\n            input, config.internalResolution, config.segmentationThreshold);\n\n    const [height, width] = partSegmentation.shape;\n    const data = await partSegmentation.data() as Int32Array;\n    partSegmentation.dispose();\n\n    const tensorBuffers = await toTensorBuffers3D(\n        [heatmapScores, offsets, displacementFwd, displacementBwd]);\n    const [scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf] =\n        tensorBuffers;\n\n    let poses = decodeMultiplePoses(\n        scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf,\n        this.baseModel.outputStride, config.maxDetections,\n        config.scoreThreshold, config.nmsRadius);\n\n    poses = scaleAndFlipPoses(\n        poses, [height, width], internalResolutionHeightAndWidth, padding,\n        FLIP_POSES_AFTER_SCALING);\n\n    heatmapScores.dispose();\n    offsets.dispose();\n    displacementFwd.dispose();\n    displacementBwd.dispose();\n\n    return {height, width, data, allPoses: poses};\n  }\n\n  /**\n   * Given an image with multiple people, returns an *array* of PartSegmentation\n   * object. Each element in the array corresponding to one\n   * of the people in the input image. In other words, it predicts\n   * instance-level multiple person body part segmentation & pose for each\n   * person.\n   *\n   * This does standard ImageNet pre-processing before inferring through\n   * the model. The image pixels should have values [0-255].\n   *\n   * @param input\n   * ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement) The input\n   * image to feed through the network.\n   *\n   * @param config MultiPersonInferenceConfig object that contains\n   * parameters for the BodyPix inference using multi-person decoding.\n   *\n   * @return An array of PartSegmentation object, each containing a width,\n   * height, a flattened array (with part id from 0-24 for the pixels that are\n   * part of a corresponding body part, and -1 otherwise) and 2D pose. The width\n   * and height correspond to the dimensions of the image. Each flattened part\n   * segmentation array size is equal to `height` x `width`.\n   */\n  async segmentMultiPersonParts(\n      input: BodyPixInput,\n      config: MultiPersonInstanceInferenceConfig =\n          MULTI_PERSON_INSTANCE_INFERENCE_CONFIG): Promise<PartSegmentation[]> {\n    config = {...MULTI_PERSON_INSTANCE_INFERENCE_CONFIG, ...config};\n\n    validateMultiPersonInstanceInferenceConfig(config);\n    const [height, width] = getInputSize(input);\n    const internalResolutionHeightAndWidth = toInputResolutionHeightAndWidth(\n        config.internalResolution, this.baseModel.outputStride,\n        [height, width]);\n    const {resized, padding} =\n        padAndResizeTo(input, internalResolutionHeightAndWidth);\n    const {\n      segmentation,\n      longOffsets,\n      heatmapScoresRaw,\n      offsetsRaw,\n      displacementFwdRaw,\n      displacementBwdRaw,\n      partSegmentation,\n    } = tf.tidy(() => {\n      const {\n        segmentLogits,\n        longOffsets,\n        heatmapScores,\n        offsets,\n        displacementFwd,\n        displacementBwd,\n        partHeatmaps\n      } = this.predictForMultiPersonInstanceSegmentationAndPart(resized);\n\n      // decoding with scaling.\n      const scaledSegmentScores = scaleAndCropToInputTensorShape(\n          segmentLogits, [height, width], internalResolutionHeightAndWidth,\n          [[padding.top, padding.bottom], [padding.left, padding.right]],\n          APPLY_SIGMOID_ACTIVATION);\n\n      // decoding with scaling.\n      const scaledPartSegmentationScores = scaleAndCropToInputTensorShape(\n          partHeatmaps, [height, width], internalResolutionHeightAndWidth,\n          [[padding.top, padding.bottom], [padding.left, padding.right]],\n          APPLY_SIGMOID_ACTIVATION);\n\n      const scaledLongOffsets = longOffsets;\n      const segmentation = toMaskTensor(\n        tf.squeeze(scaledSegmentScores), config.segmentationThreshold);\n      const partSegmentation =\n          decodeOnlyPartSegmentation(scaledPartSegmentationScores);\n      return {\n        segmentation,\n        longOffsets: scaledLongOffsets,\n        heatmapScoresRaw: heatmapScores,\n        offsetsRaw: offsets,\n        displacementFwdRaw: displacementFwd,\n        displacementBwdRaw: displacementBwd,\n        partSegmentation\n      };\n    });\n\n    const tensorBuffers = await toTensorBuffers3D(\n        [heatmapScoresRaw, offsetsRaw, displacementFwdRaw, displacementBwdRaw]);\n    const [scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf] =\n        tensorBuffers;\n\n    let poses = decodeMultiplePoses(\n        scoresBuf, offsetsBuf, displacementsFwdBuf, displacementsBwdBuf,\n        this.baseModel.outputStride, config.maxDetections,\n        config.scoreThreshold, config.nmsRadius);\n\n    poses = scaleAndFlipPoses(\n        poses, [height, width], internalResolutionHeightAndWidth, padding,\n        FLIP_POSES_AFTER_SCALING);\n\n    const instanceMasks = await decodePersonInstancePartMasks(\n        segmentation, longOffsets, partSegmentation, poses, height, width,\n        this.baseModel.outputStride, internalResolutionHeightAndWidth, padding,\n        config.scoreThreshold, config.refineSteps, config.minKeypointScore,\n        config.maxDetections);\n\n    resized.dispose();\n    segmentation.dispose();\n    longOffsets.dispose();\n    heatmapScoresRaw.dispose();\n    offsetsRaw.dispose();\n    displacementFwdRaw.dispose();\n    displacementBwdRaw.dispose();\n    partSegmentation.dispose();\n\n    return instanceMasks;\n  }\n\n  public dispose() {\n    this.baseModel.dispose();\n  }\n}\n\n/**\n * Loads the MobileNet BodyPix model.\n */\nasync function loadMobileNet(config: ModelConfig): Promise<BodyPix> {\n  const outputStride = config.outputStride;\n  const quantBytes = config.quantBytes;\n  const multiplier = config.multiplier;\n  if (tf == null) {\n    throw new Error(\n        `Cannot find TensorFlow.js. If you are using a <script> tag, please ` +\n        `also include @tensorflow/tfjs on the page before using this\n        model.`);\n  }\n\n  const url = mobileNetSavedModel(outputStride, multiplier, quantBytes);\n  const graphModel = await tfconv.loadGraphModel(config.modelUrl || url);\n  const mobilenet = new MobileNet(graphModel, outputStride);\n  return new BodyPix(mobilenet);\n}\n\n/**\n * Loads the ResNet BodyPix model.\n */\nasync function loadResNet(config: ModelConfig): Promise<BodyPix> {\n  const outputStride = config.outputStride;\n  const quantBytes = config.quantBytes;\n  if (tf == null) {\n    throw new Error(\n        `Cannot find TensorFlow.js. If you are using a <script> tag, please ` +\n        `also include @tensorflow/tfjs on the page before using this\n        model.`);\n  }\n\n  const url = resNet50SavedModel(outputStride, quantBytes);\n  const graphModel = await tfconv.loadGraphModel(config.modelUrl || url);\n  const resnet = new ResNet(graphModel, outputStride);\n  return new BodyPix(resnet);\n}\n\n/**\n * Loads the BodyPix model instance from a checkpoint, with the ResNet\n * or MobileNet architecture. The model to be loaded is configurable using the\n * config dictionary ModelConfig. Please find more details in the\n * documentation of the ModelConfig.\n *\n * @param config ModelConfig dictionary that contains parameters for\n * the BodyPix loading process. Please find more details of each parameters\n * in the documentation of the ModelConfig interface. The predefined\n * `MOBILENET_V1_CONFIG` and `RESNET_CONFIG` can also be used as references\n * for defining your customized config.\n */\nexport async function load(config: ModelConfig = MOBILENET_V1_CONFIG):\n    Promise<BodyPix> {\n  config = validateModelConfig(config);\n  if (config.architecture === 'ResNet50') {\n    return loadResNet(config);\n  } else if (config.architecture === 'MobileNetV1') {\n    return loadMobileNet(config);\n  } else {\n    return null;\n  }\n}\n"],"names":["toFlattenedOneHotPartMap","partHeatmapScores","numParts","shape","partMapLocations","tf.argMax","partMapFlattened","tf.reshape","tf.oneHot","toMaskTensor","segmentScores","threshold","tf.tidy","tf.cast","tf.greater","tf.scalar","decodePartSegmentation","segmentationMask","partMapHeight","partMapWidth","flattenedMap","partNumbers","tf.expandDims","tf.range","tf.matMul","partMap","partMapShiftedUpForClipping","tf.add","tf.sub","image","mask","tf.mul","clipByMask2d","decodeOnlyPartSegmentation","model","outputStride","this","inputShape","inputs","tf.util","BaseModel","input","asFloat","_this","preprocessInput","asBatch","results3d","predict","map","y","namedResults","nameOutputResults","heatmapScores","tf.sigmoid","heatmap","offsets","displacementFwd","displacementBwd","segmentation","partHeatmaps","longOffsets","partOffsets","dispose","e","__extends","MobileNet","tf.div","results","PART_NAMES","NUM_KEYPOINTS","length","PART_IDS","reduce","result","jointName","i","CONNECTED_PART_NAMES","_a","jointNameA","jointNameB","getScale","_b","padding","height","width","inputResolutionY","inputResolutionX","padT","padB","getOffsetPoint","x","keypoint","get","getImageCoords","part","heatmapX","heatmapY","clamp","a","min","max","addVectors","b","computeDistance","embedding","pose","minPartScore","distance","numKpt","p","keypoints","score","Math","position","Infinity","getEmbedding","location","keypointIndex","convertToPosition","outputResolutionX","refineSteps","newLocation","nn","dy","dx","t","newPos","nn_1","matchEmbeddingToInstance","poses","numKptForMatching","_c","stride","padL","scaleX","scaleY","embed","pair","round","convertToPositionInOuput","keypointsIndex","push","kMin","kMinDist","k","dist","getOutputResolution","decodeMultipleMasksWebGl","posesAboveScore","minKptScore","maxNumPeople","inHeight","inWidth","origHeight","origWidth","slice","outHeight","outWidth","shapedLongOffsets","poseVals","Float32Array","fill","poseOffset","kp","offset","posesTensor","tf.tensor","program","variableNames","outputShape","userCode","tf.backend","compileAndRun","isWebGlBackend","getBackend","decodePersonInstanceMasks","minPoseScore","minKeypointScore","filter","personSegmentations","masksTensorInfo","masksTensor","tf.engine","makeTensorFromDataId","dataId","dtype","_","tf.equal","toPersonKSegmentation","Promise","all","data","personSegmentationsData","forEach","segmentationsData","longOffsetsData","dataArrays","Uint8Array","j","n","decodeMultipleMasksCPU","decodePersonInstancePartMasks","partSegmentation","partSegmentations","bodyParts","toPersonKPartSegmentation","partSegmentationsByPersonData","partSegmentaionData","partSegmentaion","Int32Array","decodeMultiplePartMasksCPU","half","floor","maxSize","getElementValue","priorityQueue","Array","numberOfElements","MaxHeap","swim","exchange","sink","less","getValueAt","scoreIsMaximumInLocalWindow","keypointId","localMaximumRadius","scores","localMaximum","yStart","yEnd","yCurrent","xStart","xEnd","xCurrent","parentChildrenTuples","POSE_CHAIN","parentJoinName","childJoinName","parentToChildEdges","childToParentEdges","getStridedIndexNearPoint","point","traverseToTargetKeypoint","edgeId","sourceKeypoint","targetKeypointId","scoresBuffer","displacements","offsetRefineStep","displacement","numEdges","getDisplacement","targetKeypoint","targetKeypointIndices","offsetPoint","targetKeyPointIndices","decodePose","root","displacementsFwd","displacementsBwd","instanceKeypoints","rootPart","rootScore","rootPoint","id","edge","sourceKeypointId","withinNmsRadiusOfCorrespondingPoint","squaredNmsRadius","some","correspondingKeypoint","y1","x1","y2","x2","squaredDistance","getInstanceScore","existingPoses","kLocalMaximumRadius","decodeMultiplePoses","offsetsBuffer","displacementsFwdBuffer","displacementsBwdBuffer","maxPoseDetections","scoreThreshold","nmsRadius","queue","numKeypoints","enqueue","buildPartWithScoreQueue","empty","dequeue","imageNetMean","ResNet","RESNET50_BASE_URL","MOBILENET_BASE_URL","getInputSize","HTMLCanvasElement","OffscreenCanvas","HTMLImageElement","graphJson","offsetHeight","offsetWidth","Error","getSizeFromImageLikeElement","ImageData","HTMLVideoElement","hasAttribute","videoHeight","videoWidth","getSizeFromVideoElement","tf.Tensor","toValidInputResolution","inputResolution","resolution","isValidInputResolution","INTERNAL_RESOLUTION_STRING_OPTIONS","low","medium","high","full","INTERNAL_RESOLUTION_PERCENTAGES","MIN_INTERNAL_RESOLUTION","MAX_INTERNAL_RESOLUTION","toInputResolutionHeightAndWidth","internalResolution","inputHeight","inputWidth","internalResolutionPercentage","Object","values","join","toInternalResolutionPercentage","scaleAndCropToInputTensorShape","tensor","applySigmoidActivation","inputTensorHeight","inputTensorWidth","resizedAndPaddedHeight","resizedAndPaddedWidth","_d","_e","padR","inResizedAndPadded","tf.image","resizedAndPadded","originalHeight","originalWidth","batchedImage","tf.squeeze","removePaddingAndResizeBack","padAndResizeTo","targetH","targetW","targetAspect","resized","imageTensor","tf.browser","toInputTensor","tf.pad3d","top","left","right","bottom","toTensorBuffers3D","tensors","buffer","scaleAndFlipPoses","flipHorizontal","inputResolutionHeight","inputResolutionWidth","scaledPoses","offsetY","offsetX","r","scalePose","scalePoses","imageWidth","flipPoseHorizontal","flipPosesHorizontal","APPLY_SIGMOID_ACTIVATION","FLIP_POSES_AFTER_SCALING","MOBILENET_V1_CONFIG","architecture","quantBytes","multiplier","VALID_ARCHITECTURE","VALID_STRIDE","MobileNetV1","ResNet50","VALID_MULTIPLIER","VALID_QUANT_BYTES","PERSON_INFERENCE_CONFIG","segmentationThreshold","maxDetections","MULTI_PERSON_INSTANCE_INFERENCE_CONFIG","validatePersonInferenceConfig","config","validateMultiPersonInstanceInferenceConfig","net","baseModel","BodyPix","segmentLogits","partHeatmapLogits","internalResolutionHeightAndWidth","predictForPersonSegmentation","resizedHeight","resizedWidth","scaledSegmentScores","segmentPersonActivation","tensorBuffers","scoresBuf","offsetsBuf","displacementsFwdBuf","displacementsBwdBuf","allPoses","scaledLongOffsets","predictForMultiPersonInstanceSegmentationAndPart","heatmapScoresRaw","offsetsRaw","displacementFwdRaw","displacementBwdRaw","instanceMasks","predictForPersonSegmentationAndPart","scaledPartHeatmapScore","segmentPersonPartsActivation","scaledPartSegmentationScores","loadMobileNet","tf","url","toStr","1","0.75","0.5","mobileNetSavedModel","tfconv.loadGraphModel","modelUrl","graphModel","mobilenet","loadResNet","resNet50SavedModel","resnet","load","indexOf","validateModelConfig"],"sourceRoot":""}