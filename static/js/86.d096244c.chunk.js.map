{"version":3,"file":"static/js/86.d096244c.chunk.js","mappings":"iNAEaA,EAAoB,WAS7B,aAA8B,IAAlBC,EAAW,uDAAG,GAAC,oBAP3BC,QAAyB,GAAG,KAC5BC,UAAI,OAEJC,OAAiB,EAAE,KACnBC,aAAuB,IAAK,KAC5BC,eAAS,EAGLC,KAAKH,OAASH,EACd,IAAK,IAAIO,EAAI,EAAGA,EAAI,IAAKA,EAAG,CACxB,IAAMC,EAASC,EAAAA,IAAYA,EAAAA,IAA2B,EAAhBC,KAAKC,SAAgB,IAE3DL,KAAKL,QAAQW,KAAKJ,EACtB,CACAF,KAAKJ,KAAOO,EAAAA,IAAYA,EAAAA,IAA2B,EAAhBC,KAAKC,SAAgB,IACxDL,KAAKD,UAAYI,EAAAA,IAAAA,KAAcH,KAAKF,aACxC,CAgFA,OAhFC,iCACD,SAAkBS,GAId,OAFWA,EAAEC,IAAIR,KAAKL,QAAQ,IACzBc,IAAIT,KAAKJ,KAElB,GAAC,uBACD,SAAkBW,GAKd,OAHWA,EAAEG,SAASF,IAAIR,KAAKL,QAAQ,IAClCc,IAAIF,EAAEC,IAAIR,KAAKL,QAAQ,KACvBc,IAAIT,KAAKJ,KAElB,GAAC,uBACD,SAAkBW,GAMd,OAJWA,EAAEI,IAAIR,EAAAA,IAAU,IAAIK,IAAIR,KAAKL,QAAQ,IAC3Cc,IAAIF,EAAEG,SAASF,IAAIR,KAAKL,QAAQ,KAChCc,IAAIF,EAAEC,IAAIR,KAAKL,QAAQ,KACvBc,IAAIT,KAAKJ,KAElB,GAAC,uBACD,SAAkBW,GAOd,OALWA,EAAEI,IAAIR,EAAAA,IAAU,IAAIK,IAAIR,KAAKL,QAAQ,IAC3Cc,IAAIF,EAAEI,IAAIR,EAAAA,IAAU,IAAIK,IAAIR,KAAKL,QAAQ,KACzCc,IAAIF,EAAEG,SAASF,IAAIR,KAAKL,QAAQ,KAChCc,IAAIF,EAAEC,IAAIR,KAAKL,QAAQ,KACvBc,IAAIT,KAAKJ,KAElB,GAAC,uBACD,SAAkBW,GAQd,OANWA,EAAEI,IAAIR,EAAAA,IAAU,IAAIK,IAAIR,KAAKL,QAAQ,IAC3Cc,IAAIF,EAAEI,IAAIR,EAAAA,IAAU,IAAIK,IAAIR,KAAKL,QAAQ,KACzCc,IAAIF,EAAEI,IAAIR,EAAAA,IAAU,IAAIK,IAAIR,KAAKL,QAAQ,KACzCc,IAAIF,EAAEG,SAASF,IAAIR,KAAKL,QAAQ,KAChCc,IAAIF,EAAEC,IAAIR,KAAKL,QAAQ,KACvBc,IAAIT,KAAKJ,KAElB,GAAC,2BACD,SAAsBW,GAClB,OAAoB,IAAhBP,KAAKH,OAAuBG,KAAKY,UAAUL,GAC3B,IAAhBP,KAAKH,OAAuBG,KAAKa,UAAUN,GAC3B,IAAhBP,KAAKH,OAAuBG,KAAKc,UAAUP,GAC3B,IAAhBP,KAAKH,OAAuBG,KAAKe,UAAUR,IAC3CP,KAAKH,OAAuBG,KAAKgB,UAAUT,GAEnD,GAAC,kBACD,SAAYU,EAA0BC,GAClC,OAAOD,EAAKE,IAAID,GAAOR,SAASU,MACpC,GAAC,8DACD,WAAqBC,GAAc,qFAMlB,OALPC,EAAKnB,EAAAA,KAAQ,WACf,OAAO,EAAKoB,cAAcpB,EAAAA,IAAYkB,GAC1C,IAEIG,EAAMF,EAAGG,WACbH,EAAGI,UAAU,kBACNF,GAAG,2CACb,mDATA,IASA,mBACD,SAAaG,EAAgBC,GAAkB,IAAD,OAE1CzB,EAAAA,KAAQ,WACJ,IAAM0B,EAAK1B,EAAAA,IAAYwB,GACjBL,EAAKnB,EAAAA,IAAYyB,GACvB,EAAK7B,UAAU+B,UAAS,kBAAW,EAAKC,KAAK,EAAKR,cAAcM,GAAKP,EAAG,GAC5E,GAMJ,KAOA,EAlG6B,GCFpBU,EAAkB,WAK3B,cAAgB,oBAHhBC,EAAY,EAAE,KACdrC,KAAe,CAIf,CA6BC,OA7BA,+BACD,SAAeW,GAEX,IADA,IAAMiB,EAAM,GACJvB,EAAI,EAAGA,EAAIM,EAAE2B,SAAUjC,EAC3BuB,EAAIlB,KAAKN,KAAKmC,aAAa5B,EAAEN,KAEjC,OAAOuB,CACX,GAAC,0BACD,SAAqBjB,GACjB,OAAOP,KAAKiC,EAAI1B,EAAIP,KAAKJ,IAC7B,GAAC,iBACD,SAAWwC,EAAkBC,GAGzB,IAFA,IAAIC,EAAO,EACPC,EAAO,EACFtC,EAAI,EAAGA,EAAImC,EAAMF,SAAUjC,EAChCqC,GAAQF,EAAMnC,GACdsC,GAAQF,EAAMpC,GAOlB,IALA,IAAIuC,EAAQF,EAAOF,EAAMF,OACrBO,EAAQF,EAAOH,EAAMF,OAErBQ,EAAM,EACNC,EAAM,EACD1C,EAAI,EAAGA,EAAImC,EAAMF,SAAUjC,EAChCyC,IAAQN,EAAMnC,GAAKuC,IAAUH,EAAMpC,GAAKwC,GACxCE,IAAQP,EAAMnC,GAAKuC,IAAUJ,EAAMnC,GAAKuC,GAE5CxC,KAAKiC,EAAIS,EAAMC,EACf3C,KAAKJ,KAAO6C,EAAQzC,KAAKiC,EAAIO,CACjC,KAAC,EApC0B,GCAlBI,EAAoB,WAO7B,cAAe,oBALfC,aAAuB,IAAK,KAC5BC,MAAgBC,OAAOC,iBAAiB,KACxC9C,OAAiB,EAAE,KACnBN,KAAe,CAIf,CAuBC,OAvBA,+BACD,SAAeW,GAEX,IADA,IAAMiB,EAAM,GACJvB,EAAI,EAAGA,EAAIM,EAAE2B,SAAUjC,EAC3BuB,EAAIlB,KAAKN,KAAKmC,aAAa5B,EAAEN,KAEjC,OAAOuB,CACX,GAAC,0BACD,SAAqBjB,GACjB,OAAOP,KAAKE,OAASK,EAAIP,KAAKJ,IAClC,GAAC,mBACD,SAAawC,EAAkBC,GAE3B,IAAK,IAAIpC,EAAI,EAAGA,EAAImC,EAAMF,SAAUjC,EAAG,CACnC,IAAIM,EAAI6B,EAAMnC,GACVgD,EAAIZ,EAAMpC,GACViD,EAAalD,KAAKE,OAASK,EAAIP,KAAKJ,KACxCI,KAAK8C,MAAQG,EAAIC,EAEjBlD,KAAKE,OAASF,KAAKE,OAAUF,KAAK8C,MAAQvC,EAAKP,KAAK6C,aACpD7C,KAAKJ,KAAOI,KAAKJ,KAAQI,KAAK8C,MAAS9C,KAAK6C,YAEhD,CACJ,KAAC,EAhC4B,G,WCCpBM,EAAgB,SAAC9B,GAC1B,IAEkB,EAFd+B,EAAqB,GACrBC,EAAmBC,EAAUjC,GAAM,UACzBA,GAAI,IAAlB,2BAAoB,CAAC,IAAZkC,EAAC,QAAYH,EAAS9C,MAAOiD,EAAIF,EAAO,KAAOA,EAAO,GAAKA,EAAO,IAAO,CAAC,+BACnF,OAAOD,CACX,EASaE,EAAY,SAACE,GACtB,IACwB,EADpBC,EAAcV,OAAOW,UAAeC,EAAcZ,OAAOa,UAAU,UACzDJ,GAAU,IAAxB,2BAA0B,CAAC,IAAlBD,EAAC,QAAsBE,EAAMF,IAAKE,EAAMF,GAASI,EAAMJ,IAAKI,EAAMJ,EAAK,CAAC,+BACjF,MAAO,CAACE,EAAKE,EACjB,ECXaE,EAAS,yCAAG,WAAOC,GAAgB,wFAOtCvD,EAAI4C,EAAc,CAAC,EAAE,EAAE,IACvBF,EAAIE,EAAc,CAAC,GAAG,KAAK,KAE3BlC,EAAOkC,EAAc,CAAC,EAAE,EAAE,KAIrB,IAAInB,GACZ+B,IAAIxD,EAAG0C,GAKJe,EAAO,IAAIpB,EACT3C,EAAI,EAAE,KAAD,OAAEA,EAAI,KAAK,iBACH,GAAjB+D,EAAKC,MAAM1D,EAAG0C,GACXhD,EAAI,MAAS,EAAC,kCACG+D,EAAKE,QAAQjD,GAAM,KAAD,GAA3B,iBAHahB,EAAC,uBAWvBkE,EAAK,IAAI1E,EAAqB,GAC5BQ,EAAI,EAAE,KAAD,QAAEA,EAAI,KAAI,iBACJ,GAAfkE,EAAGF,MAAM1D,EAAG0C,GACThD,EAAI,MAAQ,EAAC,kCACIkE,EAAGD,QAAQjD,GAAM,KAAD,GAAzB,iBAHYhB,EAAC,yCAOZkE,EAAGD,QAAQjD,GAAM,KAAD,GAAzB,mDAEV,gBA1CqB,qC","sources":["njslab/Env/NJSLabSandboxData/Definition/ModelRegression/PolynomialRegression.ts","njslab/Env/NJSLabSandboxData/Definition/ModelRegression/JSLinearRegression.ts","njslab/Env/NJSLabSandboxData/Definition/ModelRegression/JSLinearRegressionGD.ts","njslab/Env/NJSLabSandboxData/Definition/ModelRegression/Utility.ts","njslab/Env/NJSLabSandboxData/Definition/TFjs/Lesson0Normal.ts"],"sourcesContent":["import * as tf from '@tensorflow/tfjs';\r\n\r\nexport class PolynomialRegression {\r\n\r\n    weights: tf.Variable[] = [];\r\n    bias: tf.Variable;\r\n\r\n    degree: number = 3;\r\n    leraningRate: number = 0.02;\r\n    optimizer: tf.AdamOptimizer;\r\n\r\n    constructor(dim: number = 0) {\r\n        this.degree = dim;\r\n        for (let i = 0; i < 5; ++i) {\r\n            const weight = tf.variable(tf.scalar((Math.random() * 2) - 1));\r\n            // weight.print();\r\n            this.weights.push(weight);\r\n        }\r\n        this.bias = tf.variable(tf.scalar((Math.random() * 2) - 1));\r\n        this.optimizer = tf.train.adam(this.leraningRate);\r\n    }\r\n    private predict1d(x: tf.Tensor<tf.Rank>): tf.Tensor<tf.Rank> {\r\n        // y = ax^3 + bx^2 + cx + d\r\n        const ys = x.mul(this.weights[0])\r\n            .add(this.bias);\r\n        return ys;\r\n    }\r\n    private predict2d(x: tf.Tensor<tf.Rank>): tf.Tensor<tf.Rank> {\r\n        // y = ax^3 + bx^2 + cx + d\r\n        const ys = x.square().mul(this.weights[1])\r\n            .add(x.mul(this.weights[0]))\r\n            .add(this.bias);\r\n        return ys;\r\n    }\r\n    private predict3d(x: tf.Tensor<tf.Rank>): tf.Tensor<tf.Rank> {\r\n        // y = ax^3 + bx^2 + cx + d\r\n        const ys = x.pow(tf.scalar(3)).mul(this.weights[2])\r\n            .add(x.square().mul(this.weights[1]))\r\n            .add(x.mul(this.weights[0]))\r\n            .add(this.bias);\r\n        return ys;\r\n    }\r\n    private predict4d(x: tf.Tensor<tf.Rank>): tf.Tensor<tf.Rank> {\r\n        // y = ax^3 + bx^2 + cx + d\r\n        const ys = x.pow(tf.scalar(4)).mul(this.weights[3])\r\n            .add(x.pow(tf.scalar(3)).mul(this.weights[2]))\r\n            .add(x.square().mul(this.weights[1]))\r\n            .add(x.mul(this.weights[0]))\r\n            .add(this.bias);\r\n        return ys;\r\n    }\r\n    private predict5d(x: tf.Tensor<tf.Rank>): tf.Tensor<tf.Rank> {\r\n        // y = ax^3 + bx^2 + cx + d\r\n        const ys = x.pow(tf.scalar(5)).mul(this.weights[4])\r\n            .add(x.pow(tf.scalar(4)).mul(this.weights[3]))\r\n            .add(x.pow(tf.scalar(3)).mul(this.weights[2]))\r\n            .add(x.square().mul(this.weights[1]))\r\n            .add(x.mul(this.weights[0]))\r\n            .add(this.bias);\r\n        return ys;\r\n    }\r\n    private predictResult(x: tf.Tensor<tf.Rank>): tf.Tensor<tf.Rank> {\r\n        if (this.degree === 5) { return this.predict5d(x); }\r\n        if (this.degree === 4) { return this.predict4d(x); }\r\n        if (this.degree === 3) { return this.predict3d(x); }\r\n        if (this.degree === 2) { return this.predict2d(x); }\r\n        if (this.degree === 1) { return this.predict1d(x); }\r\n        return this.predict1d(x);\r\n    }\r\n    public loss(pred: tf.Tensor<tf.Rank>, label: tf.Tensor<tf.Rank>): tf.Tensor<tf.Rank> {\r\n        return pred.sub(label).square().mean();\r\n    }\r\n    public async predict(data: number[]) {\r\n        const ys = tf.tidy(() => {\r\n            return this.predictResult(tf.tensor1d(data));\r\n        });\r\n\r\n        let out = ys.dataSync();\r\n        ys.dispose();\r\n        return out;\r\n    }\r\n    public train(xVal: number[], yVal: number[] ) {\r\n\r\n        tf.tidy(() => {\r\n            const xs = tf.tensor1d(xVal);\r\n            const ys = tf.tensor1d(yVal);\r\n            this.optimizer.minimize((): any => this.loss(this.predictResult(xs), ys));\r\n        });\r\n\r\n        // console.log(tf.memory().numTensors);\r\n        // console.log('b:', this.bias, ', w:', this.weights);\r\n        // this.bias.print();\r\n        // this.weights.print();\r\n    }\r\n    // public train(x: tf.Tensor, y: tf.Tensor) {\r\n    //     tf.tidy((): any => {\r\n    //         return this.optimizer.minimize((): any => {\r\n    //             return this.loss(this.predict(x), y);\r\n    //         });\r\n    //     });\r\n    // }\r\n}","export class JSLinearRegression  {\r\n\r\n    a: number = 1;\r\n    bias: number = 0;\r\n\r\n    constructor( ) {\r\n\r\n    }\r\n    public predict(x: number[]) {\r\n        const out = [];\r\n        for(let i = 0; i < x.length; ++i) {\r\n            out.push(this.predictByNum(x[i]));\r\n        }\r\n        return out;\r\n    }\r\n    private predictByNum(x: number) {\r\n        return this.a * x + this.bias;\r\n    }\r\n    public fit(xList: number[] , yList: number[]) {\r\n        let xSum = 0;\r\n        let ySum = 0;\r\n        for (let i = 0; i < xList.length; ++i) {\r\n            xSum += xList[i];\r\n            ySum += yList[i];\r\n        }\r\n        let xMean = xSum / xList.length;\r\n        let yMean = ySum / xList.length;\r\n\r\n        let num = 0;\r\n        let den = 0;\r\n        for (let i = 0; i < xList.length; ++i) {\r\n            num += (xList[i] - xMean) * (yList[i] - yMean);\r\n            den += (xList[i] - xMean) * (xList[i] - xMean);\r\n        }\r\n        this.a = num / den;\r\n        this.bias = yMean - this.a * xMean;\r\n    }\r\n}","export class JSLinearRegressionGD {\r\n\r\n    learningRate: number = 0.02;\r\n    error: number = Number.MAX_SAFE_INTEGER;\r\n    weight: number = 1;\r\n    bias: number = 0;\r\n\r\n    constructor() {\r\n\r\n    }\r\n    public predict(x: number[]) {\r\n        const out = [];\r\n        for(let i = 0; i < x.length; ++i) {\r\n            out.push(this.predictByNum(x[i]));\r\n        }\r\n        return out;\r\n    }\r\n    private predictByNum(x: number) {\r\n        return this.weight * x + this.bias;\r\n    }\r\n    public train(xList: number[] , yList: number[]) {\r\n\r\n        for (let i = 0; i < xList.length; ++i) {\r\n            let x = xList[i];\r\n            let y = yList[i];\r\n            let hypothesis = this.weight * x + this.bias;\r\n            this.error = y - hypothesis;\r\n\r\n            this.weight = this.weight + (this.error * x) * this.learningRate;\r\n            this.bias = this.bias + (this.error) * this.learningRate;\r\n\r\n        }\r\n    }\r\n}","\r\nexport const getNormalized = (data: number[]) => {\r\n    let valueOut: number[] = [];\r\n    let domain: number[] = getDomain(data);\r\n    for (let d of data) { valueOut.push(((d - domain[0]) / (domain[1] - domain[0]))); }\r\n    return valueOut;\r\n}\r\nexport const remaps = (CValue: number[], OldMin: number, OldMax: number, NewMin: number, NewMax: number) => {\r\n    let temp: number[] = [];\r\n    for (let d of CValue) { temp.push(remap(d, OldMin, OldMax, NewMin, NewMax)); }\r\n    return temp;\r\n}\r\nexport const remap = (CValue: number, OldMin: number, OldMax: number, NewMin: number, NewMax: number) => {\r\n    return (((CValue - OldMin) * (NewMax - NewMin)) / (OldMax - OldMin)) + NewMin;\r\n}\r\nexport const getDomain = (doubleList: number[]) => {\r\n    let Min: number = Number.MAX_VALUE; let Max: number = Number.MIN_VALUE;\r\n    for (let d of doubleList) { if (Min > d) { Min = d; } if (Max < d) { Max = d; } }\r\n    return [Min, Max];\r\n}","import * as tf from '@tensorflow/tfjs';\r\nimport * as tfvis from '@tensorflow/tfjs-vis';\r\n\r\nimport { PolynomialRegression } from '../ModelRegression/PolynomialRegression';\r\nimport { JSLinearRegression } from '../ModelRegression/JSLinearRegression';\r\nimport { JSLinearRegressionGD } from '../ModelRegression/JSLinearRegressionGD';\r\nimport { getNormalized } from '../ModelRegression/Utility';\r\n\r\nexport const execution = async (div: HTMLElement) =>{\r\n\r\n//     console.log('from lesson 01 ',tf, tfvis);\r\n\r\n    // const x = [1, 3, 5];\r\n    // const y = [2, 6, 9];\r\n\r\n    const x = getNormalized([1,3,5]);\r\n    const y = getNormalized([10,11.5,12]);\r\n\r\n    const pred = getNormalized([1,3,5]);\r\n//     console.log('pred:' , pred);\r\n\r\n//     console.log(\"===============================================\");\r\n    const ln = new JSLinearRegression();\r\n    ln.fit(x, y);\r\n//     console.log('LinearRegression: ',ln.predict(pred));\r\n\r\n\r\n//     console.log(\"===============================================\");\r\n    const lnGD = new JSLinearRegressionGD();\r\n    for(let i = 0; i < 10000; ++i) {\r\n        lnGD.train(x, y);\r\n        if(i % 1000 === 0) {\r\n            let out = await lnGD.predict(pred);\r\n        //     console.log(`GD ${i} ,${out}, ${lnGD.error}`);\r\n        }\r\n    }\r\n//     console.log('LinearRegressionGD: ',lnGD.predict(pred));\r\n\r\n\r\n//     console.log(\"===============================================\");\r\n    const lg = new PolynomialRegression(1);\r\n    for(let i = 0; i < 2000; ++i) {\r\n        lg.train(x, y);\r\n        if(i % 400 === 0) {\r\n            let out = await lg.predict(pred);\r\n        //     console.log(out);\r\n        }\r\n    }\r\n    let out = await lg.predict(pred);\r\n//     console.log(`PolynomialRegression 1D ,${out}`);\r\n}\r\n"],"names":["PolynomialRegression","dim","weights","bias","degree","leraningRate","optimizer","this","i","weight","tf","Math","random","push","x","mul","add","square","pow","predict5d","predict4d","predict3d","predict2d","predict1d","pred","label","sub","mean","data","ys","predictResult","out","dataSync","dispose","xVal","yVal","xs","minimize","loss","JSLinearRegression","a","length","predictByNum","xList","yList","xSum","ySum","xMean","yMean","num","den","JSLinearRegressionGD","learningRate","error","Number","MAX_SAFE_INTEGER","y","hypothesis","getNormalized","valueOut","domain","getDomain","d","doubleList","Min","MAX_VALUE","Max","MIN_VALUE","execution","div","fit","lnGD","train","predict","lg"],"sourceRoot":""}